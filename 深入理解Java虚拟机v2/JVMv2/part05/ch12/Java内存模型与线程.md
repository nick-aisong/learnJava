Java内存模型与线程
========
并发处理的广泛应用是使得Amdahl定律代替摩尔定律成为计算机性能发展源动力的根
本原因，也是人类“压榨”计算机运算能力的最有力武器

(Amdahl定律通过系统中并行化与串行化的比重来描述多处理器系统能获得的运算加速能
力，摩尔定律则用于描述处理器晶体管数量与运行效率之间的发展关系。这两个定律的更替
代表了近年来硬件发展从追求处理器频率到追求多核心并行处理的发展过程)

##### 12.1 概述
多任务处理在现代计算机操作系统中几乎已是一项必备的功能了。在许多情况下，让计
算机同时去做几件事情，不仅是因为计算机的运算能力强大了，还有一个很重要的原因是计
算机的运算速度与它的存储和通信子系统速度的差距太大，大量的时间都花费在磁盘I/O、
网络通信或者数据库访问上。如果不希望处理器在大部分时间里都处于等待其他资源的状
态，就必须使用一些手段去把处理器的运算能力“压榨”出来，否则就会造成很大的浪费，而
让计算机同时处理几项任务则是最容易想到、也被证明是非常有效的“压榨”手段

除了充分利用计算机处理器的能力外，一个服务端同时对多个客户端提供服务则是另一
个更具体的并发应用场景。衡量一个服务性能的高低好坏，每秒事务处理数（Transactions
Per Second,TPS）是最重要的指标之一，它代表着一秒内服务端平均能响应的请求总数，而
TPS值与程序的并发能力又有非常密切的关系。对于计算量相同的任务，程序线程并发协调
得越有条不紊，效率自然就会越高；反之，线程之间频繁阻塞甚至死锁，将会大大降低程序
的并发能力

服务端是Java语言最擅长的领域之一，这个领域的应用占了Java应用中最大的一块份
额，不过如何写好并发应用程序却又是服务端程序开发的难点之一，处理好并发方面的问
题通常需要更多的编码经验来支持。幸好Java语言和虚拟机提供了许多工具，把并发编程的
门槛降低了不少。并且各种中间件服务器、各类框架都努力地替程序员处理尽可能多的线程
并发细节，使得程序员在编码时能更关注业务逻辑，而不是花费大部分时间去关注此服务会
同时被多少人调用、如何协调硬件资源。无论语言、中间件和框架如何先进，开发人员都不
能期望它们能独立完成所有并发处理的事情，了解并发的内幕也是成为一个高级程序员不可
缺少的课程

(必须以代码的总体规模来衡量，服务端应用不能与JavaCard、移动终端这些领域去比绝对数量)

“高效并发”是本书讲解Java虚拟机的最后一部分，将会向读者介绍虚拟机如何实现多线
程、多线程之间由于共享和竞争数据而导致的一系列问题及解决方案

##### 12.2 硬件的效率与一致性
在正式讲解Java虚拟机并发相关的知识之前，我们先花费一点时间去了解一下物理计算
机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发
的处理方案对于虚拟机的实现也有相当大的参考意义

“让计算机并发执行若干个运算任务”与“更充分地利用计算机处理器的效能”之间的因果
关系，看起来顺理成章，实际上它们之间的关系并没有想象中的那么简单，其中一个重要的
复杂性来源是绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内
存交互，如读取运算数据、存储运算结果等，这个I/O操作是很难消除的（无法仅靠寄存器
来完成所有运算任务）。由于计算机的存储设备与处理器的运算速度有几个数量级的差距，
所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存
（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运
算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存
读写了

基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统
带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处
理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main
Memory），如图12-1所示。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导
致各自的缓存数据不一致，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为
准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根
据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及
Dragon Protocol等。在本章中将会多次提到的“内存模型”一词，可以理解为在特定的操作协
议下，对特定的内存或高速缓存进行读写访问的过程抽象。不同架构的物理机器可以拥有不
一样的内存模型，而Java虚拟机也有自己的内存模型，并且这里介绍的内存访问操作与硬件
的缓存访问操作具有很高的可比性

除了增加高速缓存之外，为了使得处理器内部的运算单元能尽量被充分利用，处理器可
能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，处理器会在计算之后将乱序
执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算
的先后顺序与输入代码中的顺序一致，因此，如果存在一个计算任务依赖另外一个计算任务
的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类
似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Reorder）优化

##### 12.3 Java内存模型
Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model,JMM）来屏蔽掉各
种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访
问效果。在此之前，主流程序语言（如C/C++等）直接使用物理硬件和操作系统的内存模
型，因此，会由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正
常，而在另外一套平台上并发访问却经常出错，因此在某些场景就必须针对不同的平台来编
写程序

(本书中的Java内存模型都特指目前正在使用的，即在JDK 1.2之后建立起来并在JDK 1.5中
 完备过的内存模型)

定义Java内存模型并非一件容易的事情，这个模型必须定义得足够严谨，才能让Java的
并发内存访问操作不会产生歧义；但是，也必须定义得足够宽松，使得虚拟机的实现有足够
的自由空间去利用硬件的各种特性（寄存器、高速缓存和指令集中某些特有的指令）来获取
更好的执行速度。经过长时间的验证和修补，在JDK 1.5（实现了JSR-133）发布后，Java内
存模型已经成熟和完善起来了

(JSR-133：Java Memory Model and Thread Specification Revision（Java内存模型和线程规范
 修订）)

###### 12.3.1 主内存与工作内存
Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储
到内存和从内存中取出变量这样的底层细节。此处的变量（Variables）与Java编程中所说的
变量有所区别，它包括了实例字段、静态字段和构成数组对象的元素，但不包括局部变量与
方法参数，因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。为了获得较
好的执行效能，Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内
存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施

(此处请读者注意区分概念：如果局部变量是一个reference类型，它引用的对象在Java堆中
 可被各个线程共享，但是reference本身在Java栈的局部变量表中，它是线程私有的)

Java内存模型规定了所有的变量都存储在主内存（Main Memory）中（此处的主内存与
介绍物理硬件时的主内存名字一样，两者也可以互相类比，但此处仅是虚拟机内存的一部
分）。每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类
比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的
所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。
不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主
内存来完成，线程、主内存、工作内存三者的交互关系如图12-2所示

(有不少读者会对这段描述中的“拷贝副本”提出疑问，如“假设线程中访问一个10MB的对
象，也会把这10MB的内存复制一份拷贝出来吗？”，事实上并不会如此，这个对象的引用、
对象中某个在线程访问到的字段是有可能存在拷贝的，但不会有虚拟机实现成把整个对象拷
贝A一次)

(根据Java虚拟机规范的规定，volatile变量依然有工作内存的拷贝，但是由于它特殊的操作
顺序性规定（后文会讲到），所以看起来如同直接在主内存中读写访问一般，因此这里的描
述对于volatile也并不存在例外)

这里所讲的主内存、工作内存与本书第2章所讲的Java内存区域中的Java堆、栈、方法区
等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起
来，那从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据
部分，而工作内存则对应于虚拟机栈中的部分区域。从更低层次上说，主内存就直接对应
于物理硬件的内存，而为了获取更好的运行速度，虚拟机（甚至是硬件系统本身的优化措
施）可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是
工作内存

(除了实例数据，Java堆还保存了对象的其他信息，对于HotSpot虚拟机来讲，有Mark
 Word（存储对象哈希码、GC标志、GC年龄、同步锁等信息）、Klass Point（指向存储类型
 元数据的指针）及一些用于字节对齐补白的填充数据（如果实例数据刚好满足8字节对齐的
 话，则可以不存在补白）)

###### 12.3.2 内存间交互操作
关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内
存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下8种操作来
完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的（对于double
和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外，这个问题
在12.3.4节再讲）

(基于理解难度和严谨性考虑，最新的JSR-133文档中，已经放弃采用这8种操作去定义Java
内存模型的访问协议了（仅是描述方式改变了，Java内存模型并没有改变）)

lock（锁定）：作用于主内存的变量，它把一个变量标识为一条线程独占的状态

unlock（解锁）：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放
后的变量才可以被其他线程锁定

read（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内
存中，以便随后的load动作使用

load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工
作内存的变量副本中

use（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引
擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作

assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内
存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作

store（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传送到主内存
中，以便随后的write操作使用

write（写入）：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入
主内存的变量中

如果要把一个变量从主内存复制到工作内存，那就要顺序地执行read和load操作，如果
要把变量从工作内存同步回主内存，就要顺序地执行store和write操作。注意，Java内存模型
只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read与load之
间、store与write之间是可插入其他指令的，如对主内存中的变量a、b进行访问时，一种可能
出现顺序是read a、read b、load b、load a。除此之外，Java内存模型还规定了在执行上述8种
基本操作时必须满足如下规则：

不允许read和load、store和write操作之一单独出现，即不允许一个变量从主内存读取了
但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现

不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该
变化同步回主内存

不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步
回主内存中

一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化
（load或assign）的变量，换句话说，就是对一个变量实施use、store操作之前，必须先执行
过了assign和load操作

一个变量在同一个时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线
程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁

如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这
个变量前，需要重新执行load或assign操作初始化变量的值

如果一个变量事先没有被lock操作锁定，那就不允许对它执行unlock操作，也不允许去
unlock一个被其他线程锁定住的变量

对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、write操
作）

这8种内存访问操作以及上述规则限定，再加上稍后介绍的对volatile的一些特殊规定，
就已经完全确定了Java程序中哪些内存访问操作在并发下是安全的。由于这种定义相当严谨
但又十分烦琐，实践起来很麻烦，所以在12.3.6节中笔者将介绍这种定义的一个等效判断原
则——先行发生原则，用来确定一个访问在并发环境下是否安全

###### 12.3.3 对于volatile型变量的特殊规则
关键字volatile可以说是Java虚拟机提供的最轻量级的同步机制，但是它并不容易完全被
正确、完整地理解，以至于许多程序员都习惯不去使用它，遇到需要处理多线程数据竞争问
题的时候一律使用synchronized来进行同步。了解volatile变量的语义对后面了解多线程操作的
其他特性很有意义，在本节中我们将多花费一些时间去弄清楚volatile的语义到底是什么

Java内存模型对volatile专门定义了一些特殊的访问规则，在介绍这些比较拗口的规则定
义之前，笔者先用不那么正式但通俗易懂的语言来介绍一下这个关键字的作用

当一个变量定义为volatile之后，它将具备两种特性，第一是保证此变量对所有线程的可
见性，这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以
立即得知的。而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来
完成，例如，线程A修改一个普通变量的值，然后向主内存进行回写，另外一条线程B在线
程A回写完成了之后再从主内存进行读取操作，新变量值才会对线程B可见

关于volatile变量的可见性，经常会被开发人员误解，认为以下描述成立：“volatile变量
对所有线程是立即可见的，对volatile变量所有的写操作都能立刻反应到其他线程之中，换句
话说，volatile变量在各个线程中是一致的，所以基于volatile变量的运算在并发下是安全
的”。这句话的论据部分并没有错，但是其论据并不能得出“基于volatile变量的运算在并发下
是安全的”这个结论。volatile变量在各个线程的工作内存中不存在一致性问题（在各个线程
的工作内存中，volatile变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执
行引擎看不到不一致的情况，因此可以认为不存在一致性问题），但是Java里面的运算并非
原子操作，导致volatile变量的运算在并发下一样是不安全的，我们可以通过一段简单的演示
来说明原因，请看代码清单12-1中演示的例子
```java
//代码清单12-1 volatile的运算
/**
 * volatile变量自增运算测试
 * 
 * @author zzm
 */
public class VolatileTest {

    public static volatile int race = 0;

    public static void increase() {
        race++;
    }

    private static final int THREADS_COUNT = 20;

    public static void main(String[] args) {
        Thread[] threads = new Thread[THREADS_COUNT];
        for (int i = 0; i < THREADS_COUNT; i++) {
            threads[i] = new Thread(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i < 10000; i++) {
                        increase();
                    }
                }
            });
            threads[i].start();
        }

        // 等待所有累加线程都结束
        while (Thread.activeCount() > 1)
            Thread.yield();

        System.out.println(race);
    }
}
```
这段代码发起了20个线程，每个线程对race变量进行10000次自增操作，如果这段代码能
够正确并发的话，最后输出的结果应该是200000。读者运行完这段代码之后，并不会获得期
望的结果，而且会发现每次运行程序，输出的结果都不一样，都是一个小于200000的数字，
这是为什么呢？

问题就出现在自增运算“race++”之中，我们用Javap反编译这段代码后会得到代码清单
12-2，发现只有一行代码的increase()方法在Class文件中是由4条字节码指令构成的（return
指令不是由race++产生的，这条指令可以不计算），从字节码层面上很容易就分析出并发失
败的原因了：当getstatic指令把race的值取到操作栈顶时，volatile关键字保证了race的值在此
时是正确的，但是在执行iconst_1、iadd这些指令的时候，其他线程可能已经把race的值加大
了，而在操作栈顶的值就变成了过期的数据，所以putstatic指令执行后就可能把较小的race值
同步回主内存之中
```java
//代码清单12-2 VolatileTest的字节码
public static void increase();
Code:
Stack=2,Locals=0,Args_size=0
0:getstatic#13;//Field race:I
3:iconst_1
4:iadd
5:putstatic#13;//Field race:I
8:return
LineNumberTable:
line 14:0
line 15:8
```
客观地说，笔者在此使用字节码来分析并发问题，仍然是不严谨的，因为即使编译出来
只有一条字节码指令，也并不意味执行这条指令就是一个原子操作。一条字节码指令在解释
执行时，解释器将要运行许多行代码才能实现它的语义，如果是编译执行，一条字节码指令
也可能转化成若干条本地机器码指令，此处使用-XX：+PrintAssembly参数输出反汇编来分析
会更加严谨一些，但考虑到读者阅读的方便，并且字节码已经能说明问题，所以此处使用字
节码来分析

由于volatile变量只能保证可见性，在不符合以下两条规则的运算场景中，我们仍然要通
过加锁（使用synchronized或java.util.concurrent中的原子类）来保证原子性

运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值

变量不需要与其他的状态变量共同参与不变约束

而在像如下的代码清单12-3所示的这类场景就很适合使用volatile变量来控制并发，当
shutdown()方法被调用时，能保证所有线程中执行的doWork()方法都立即停下来
```java
//代码清单12-3 volatile的使用场景
volatile boolean shutdownRequested;
public void shutdown(){
    shutdownRequested = true;
}
public void doWork(){
    while(!shutdownRequested){
        //do stuff
    }
}
```
使用volatile变量的第二个语义是禁止指令重排序优化，普通的变量仅仅会保证在该方法
的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的
顺序与程序代码中的执行顺序一致。因为在一个线程的方法执行过程中无法感知到这点，这
也就是Java内存模型中描述的所谓的“线程内表现为串行的语义”（Within-Thread As-If-Serial
Semantics）

上面的描述仍然不太容易理解，我们还是继续通过一个例子来看看为何指令重排序会干
扰程序的并发执行，演示程序如代码清单12-4所示
```java
//代码清单12-4 指令重排序
Map configOptions;
char[] configText;
//此变量必须定义为volatile
volatile boolean initialized = false;

//假设以下代码在线程A中执行
//模拟读取配置信息，当读取完成后将initialized设置为true以通知其他线程配置可用
configOptions = new HashMap();
configText = readConfigFile(fileName);
processConfigOptions(configText, configOptions);
initialized = true;

//假设以下代码在线程B中执行
//等待initialized为true，代表线程A已经把配置信息初始化完成
while(!initialized){
    sleep();
}
//使用线程A中初始化好的配置信息
doSomethingWithConfig();
```
代码清单12-4中的程序是一段伪代码，其中描述的场景十分常见，只是我们在处理配置
文件时一般不会出现并发而已。如果定义initialized变量时没有使用volatile修饰，就可能会由
于指令重排序的优化，导致位于线程A中最后一句的代码“initialized = true”被提前执行（这里
虽然使用Java作为伪代码，但所指的重排序优化是机器级的优化操作，提前执行是指这句话
对应的汇编代码被提前执行），这样在线程B中使用配置信息的代码就可能出现错误，而
volatile关键字则可以避免此类情况的发生

(volatile屏蔽指令重排序的语义在JDK 1.5中才被完全修复，此前的JDK中即使将变量声明
为volatile也仍然不能完全避免重排序所导致的问题（主要是volatile变量前后的代码仍然存在
重排序问题），这点也是在JDK 1.5之前的Java中无法安全地使用DCL（双锁检测）来实现单
例模式的原因)

指令重排序是并发编程中最容易让开发人员产生疑惑的地方，除了上面伪代码的例子之
外，笔者再举一个可以实际操作运行的例子来分析volatile关键字是如何禁止指令重排序优化
的。代码清单12-5是一段标准的DCL单例代码，可以观察加入volatile和未加入volatile关键字
时所生成汇编代码的差别（如何获得JIT的汇编代码，请参考4.2.7节）
```java
//代码清单12-5 DCL单例模式
public class Singleton {

    private volatile static Singleton instance;

    public static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }

    public static void main(String[] args) {
            Singleton.getInstance();
    }
}
```
编译后，这段代码对instance变量赋值部分如代码清单12-6所示
```java
//代码清单12-6
0x01a3de0f:mov$0x3375cdb0, %esi;……beb0cd75 33 ;{oop('Singleton')}
0x01a3de14:mov%eax, 0x150(%esi);……89865001 0000
0x01a3de1a:shr$0x9, %esi;……c1ee09
0x01a3de1d:movb$0x0, 0x1104800(%esi);……c6860048 100100
0x01a3de24:lock addl$0x0, (%esp);……f0830424 00 ;*putstatic instance ;-
Singleton:getInstance@24
```
通过对比就会发现，关键变化在于有volatile修饰的变量，赋值后（前面
mov%eax，0x150（%esi）这句便是赋值操作）多执行了一个“lock addl ＄0x0，（%esp）”操
作，这个操作相当于一个内存屏障（Memory Barrier或Memory Fence，指重排序时不能把后
面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；
但如果有两个或更多CPU访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来
保证一致性了。这句指令中的“addl ＄0x0，（%esp）”（把ESP寄存器的值加0）显然是一个
空操作（采用这个空操作而不是空操作指令nop是因为IA32手册规定lock前缀不允许配合nop
指令使用），关键在于lock前缀，查询IA32手册，它的作用是使得本CPU的Cache写入了内
存，该写入动作也会引起别的CPU或者别的内核无效化（Invalidate）其Cache，这种操作相
当于对Cache中的变量做了一次前面介绍Java内存模式中所说的“store和write”操作。所以通
过这样一个空操作，可让前面volatile变量的修改对其他CPU立即可见

(Doug Lea列出了各种处理器架构下的内存屏障指令：
http://g.oswego.edu/dl/jmm/cookbook.html)

在本节的最后，我们回头看一下Java内存模型中对volatile变量定义的特殊规则。假定T
表示一个线程，V和W分别表示两个volatile型变量，那么在进行read、load、use、assign、
store和write操作时需要满足如下规则：

只有当线程T对变量V执行的前一个动作是load的时候，线程T才能对变量V执行use动
作；并且，只有当线程T对变量V执行的后一个动作是use的时候，线程T才能对变量V执行
load动作。线程T对变量V的use动作可以认为是和线程T对变量V的load、read动作相关联，必
须连续一起出现（这条规则要求在工作内存中，每次使用V前都必须先从主内存刷新最新的
值，用于保证能看见其他线程对变量V所做的修改后的值）

只有当线程T对变量V执行的前一个动作是assign的时候，线程T才能对变量V执行store动
作；并且，只有当线程T对变量V执行的后一个动作是store的时候，线程T才能对变量V执行
assign动作。线程T对变量V的assign动作可以认为是和线程T对变量V的store、write动作相关
联，必须连续一起出现（这条规则要求在工作内存中，每次修改V后都必须立刻同步回主内
存中，用于保证其他线程可以看到自己对变量V所做的修改）

假定动作A是线程T对变量V实施的use或assign动作，假定动作F是和动作A相关联的load
或store动作，假定动作P是和动作F相应的对变量V的read或write动作；类似的，假定动作B是
线程T对变量W实施的use或assign动作，假定动作G是和动作B相关联的load或store动作，假
定动作Q是和动作G相应的对变量W的read或write动作。如果A先于B，那么P先于Q（这条规
则要求volatile修饰的变量不会被指令重排序优化，保证代码的执行顺序与程序的顺序相
同）

###### 12.3.4 对于long和double型变量的特殊规则
Java内存模型要求lock、unlock、read、load、assign、use、store、write这8个操作都具有
原子性，但是对于64位的数据类型（long和double），在模型中特别定义了一条相对宽松的
规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进
行，即允许虚拟机实现选择可以不保证64位数据类型的load、store、read和write这4个操作的
原子性，这点就是所谓的long和double的非原子性协定（Nonatomic Treatment ofdouble and
long Variables）

如果有多个线程共享一个并未声明为volatile的long或double类型的变量，并且同时对它
们进行读取和修改操作，那么某些线程可能会读取到一个既非原值，也不是其他线程修改值
的代表了“半个变量”的数值

不过这种读取到“半个变量”的情况非常罕见（在目前商用Java虚拟机中不会出现），因
为Java内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作，但允许虚拟机
选择把这些操作实现为具有原子性的操作，而且还“强烈建议”虚拟机这样实现。在实际开发
中，目前各种平台下的商用虚拟机几乎都选择把64位数据的读写操作作为原子操作来对待，
因此我们在编写代码时一般不需要把用到的long和double变量专门声明为volatile

###### 12.3.5 原子性、可见性与有序性
介绍完Java内存模型的相关操作和规则，我们再整体回顾一下这个模型的特征。Java内
存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这3个特征来建立的，我们
逐个来看一下哪些操作实现了这3个特性

原子性（Atomicity）：由Java内存模型来直接保证的原子性变量操作包括read、load、
assign、use、store和write，我们大致可以认为基本数据类型的访问读写是具备原子性的（例
外就是long和double的非原子性协定，读者只要知道这件事情就可以了，无须太过在意这些
几乎不会发生的例外情况）

如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了
lock和unlock操作来满足这种需求，尽管虚拟机未把lock和unlock操作直接开放给用户使用，
但是却提供了更高层次的字节码指令monitorenter和monitorexit来隐式地使用这两个操作，这
两个字节码指令反映到Java代码中就是同步块——synchronized关键字，因此在synchronized块
之间的操作也具备原子性

可见性（Visibility）：可见性是指当一个线程修改了共享变量的值，其他线程能够立即
得知这个修改。上文在讲解volatile变量的时候我们已详细讨论过这一点。Java内存模型是通
过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作
为传递媒介的方式来实现可见性的，无论是普通变量还是volatile变量都是如此，普通变量与
volatile变量的区别是，volatile的特殊规则保证了新值能立即同步到主内存，以及每次使用前
立即从主内存刷新。因此，可以说volatile保证了多线程操作时变量的可见性，而普通变量则
不能保证这一点

除了volatile之外，Java还有两个关键字能实现可见性，即synchronized和final。同步块的
可见性是由“对一个变量执行unlock操作之前，必须先把此变量同步回主内存中（执行store、
write操作）”这条规则获得的，而final关键字的可见性是指：被final修饰的字段在构造器中一
旦初始化完成，并且构造器没有把“this”的引用传递出去（this引用逃逸是一件很危险的事
情，其他线程有可能通过这个引用访问到“初始化了一半”的对象），那在其他线程中就能看
见final字段的值。如代码清单12-7所示，变量i与j都具备可见性，它们无须同步就能被其他
线程正确访问
```java
//代码清单12-7 final与可见性
public static final int i;
public final int j;
static {
    i = 0;
    //do something
}
{
    //也可以选择在构造函数中初始化
    j = 0;
    //do something
}
```
有序性（Ordering）：Java内存模型的有序性在前面讲解volatile时也详细地讨论过
了，Java程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有的操作都是有
序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表
现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象
和“工作内存与主内存同步延迟”现象

Java语言提供了volatile和synchronized两个关键字来保证线程之间操作的有序性，volatile
关键字本身就包含了禁止指令重排序的语义，而synchronized则是由“一个变量在同一个时刻
只允许一条线程对其进行lock操作”这条规则获得的，这条规则决定了持有同一个锁的两个同
步块只能串行地进入

介绍完并发中3种重要的特性后，读者有没有发现synchronized关键字在需要这3种特性的
时候都可以作为其中一种的解决方案？看起来很“万能”吧。的确，大部分的并发控制操作都
能使用synchronized来完成。synchronized的“万能”也间接造就了它被程序员滥用的局面，
越“万能”的并发控制，通常会伴随着越大的性能影响，这点我们将在第13章讲解虚拟机锁优
化时再介绍

###### 12.3.6 先行发生原则
如果Java内存模型中所有的有序性都仅仅靠volatile和synchronized来完成，那么有一些操
作将会变得很烦琐，但是我们在编写Java并发代码的时候并没有感觉到这一点，这是因为
Java语言中有一个“先行发生”（happens-before）的原则。这个原则非常重要，它是判断数据
是否存在竞争、线程是否安全的主要依据，依靠这个原则，我们可以通过几条规则一揽子地
解决并发环境下两个操作之间是否可能存在冲突的所有问题

现在就来看看“先行发生”原则指的是什么。先行发生是Java内存模型中定义的两项操作
之间的偏序关系，如果说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产
生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了
方法等。这句话不难理解，但它意味着什么呢？我们可以举个例子来说明一下，如代码清单
12-8中所示的这3句伪代码
```java
//代码清单12-8 先行发生原则示例1
//以下操作在线程A中执行
i = 1;
//以下操作在线程B中执行
j = i;
//以下操作在线程C中执行
i = 2;
```
假设线程A中的操作“i=1”先行发生于线程B的操作“j=i”，那么可以确定在线程B的操作
执行后，变量j的值一定等于1，得出这个结论的依据有两个：一是根据先行发生原
则，“i=1”的结果可以被观察到；二是线程C还没“登场”，线程A操作结束之后没有其他线程
会修改变量i的值。现在再来考虑线程C，我们依然保持线程A和线程B之间的先行发生关
系，而线程C出现在线程A和线程B的操作之间，但是线程C与线程B没有先行发生关系，那j
的值会是多少呢？答案是不确定！1和2都有可能，因为线程C对变量i的影响可能会被线程B
观察到，也可能不会，这时候线程B就存在读取到过期数据的风险，不具备多线程安全性

下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器
协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从
下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序

程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面
的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，
因为要考虑分支、循环等结构

管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock
操作。这里必须强调的是同一个锁，而“后面”是指时间上的先后顺序

volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面
对这个变量的读操作，这里的“后面”同样是指时间上的先后顺序

线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每
一个动作

线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的
终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测
到线程已经终止执行

线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被
中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有
中断发生

对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发
生于它的finalize()方法的开始

传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就
可以得出操作A先行发生于操作C的结论

Java语言无须任何同步手段保障就能成立的先行发生规则就只有上面这些了，笔者演示
一下如何使用这些规则去判定操作间是否具备顺序性，对于读写共享变量的操作来说，就是
线程是否安全，读者还可以从下面这个例子中感受一下“时间上的先后顺序”与“先行发生”之
间有什么不同。演示例子如代码清单12-9所示
```java
//代码清单12-9 先行发生原则示例2
private int value = 0;
pubilc void setValue(int value){
    this.value = value;
}
public int getValue(){
    return value;
}
```
代码清单12-9中显示的是一组再普通不过的getter/setter方法，假设存在线程A和B，线程
A先（时间上的先后）调用了“setValue(1)”，然后线程B调用了同一个对象
的“getValue()”，那么线程B收到的返回值是什么？

我们依次分析一下先行发生原则中的各项规则，由于两个方法分别由线程A和线程B调
用，不在一个线程中，所以程序次序规则在这里不适用；由于没有同步块，自然就不会发生
lock和unlock操作，所以管程锁定规则不适用；由于value变量没有被volatile关键字修饰，所
以volatile变量规则不适用；后面的线程启动、终止、中断规则和对象终结规则也和这里完全
没有关系。因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，因此我们
可以判定尽管线程A在操作时间上先于线程B，但是无法确定线程B中“getValue（）”方法的
返回结果，换句话说，这里面的操作不是线程安全的

那怎么修复这个问题呢？我们至少有两种比较简单的方案可以选择：要么把getter/setter
方法都定义为synchronized方法，这样就可以套用管程锁定规则；要么把value定义为volatile
变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景，这样
就可以套用volatile变量规则来实现先行发生关系

通过上面的例子，我们可以得出结论：一个操作“时间上的先发生”不代表这个操作会
是“先行发生”，那如果一个操作“先行发生”是否就能推导出这个操作必定是“时间上的先发
生”呢？很遗憾，这个推论也是不成立的，一个典型的例子就是多次提到的“指令重排序”，
演示例子如代码清单12-10所示
```java
//代码清单12-10 先行发生原则示例3
//以下操作在同一个线程中执行
int i = 1;
int j = 2;
```
代码清单12-10的两条赋值语句在同一个线程之中，根据程序次序规则，“int i=1”的操作
先行发生于“int j=2”，但是“int j=2”的代码完全可能先被处理器执行，这并不影响先行发生原
则的正确性，因为我们在这条线程之中没有办法感知到这点

上面两个例子综合起来证明了一个结论：时间先后顺序与先行发生原则之间基本没有太
大的关系，所以我们衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以先行发
生原则为准

##### 12.4 Java与线程
并发不一定要依赖多线程（如PHP中很常见的多进程并发），但是在Java里面谈论并
发，大多数都与线程脱不开关系。既然我们这本书探讨的话题是Java虚拟机的特性，那讲到
Java线程，我们就从Java线程在虚拟机中的实现开始讲起

###### 12.4.1 线程的实现
我们知道，线程是比进程更轻量级的调度执行单位，线程的引入，可以把一个进程的资
源分配和执行调度分开，各个线程既可以共享进程资源（内存地址、文件I/O等），又可以
独立调度（线程是CPU调度的基本单位）

实现线程主要有3种方式：使用内核线程实现、使用用户线程实现和使用用户线程加轻
量级进程混合实现

1. 使用内核线程实现

内核线程（Kernel-Level Thread,KLT）就是直接由操作系统内核（Kernel，下称内核）支
持的线程，这种线程由内核来完成线程切换，内核通过操纵调度器（Scheduler）对线程进行
调度，并负责将线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身，
这样操作系统就有能力同时处理多件事情，支持多线程的内核就叫做多线程内核（MultiThreads Kernel）

程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进
程（Light Weight Process,LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻
量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量
级进程与内核线程之间1:1的关系称为一对一的线程模型，如图12-3所示

由于内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即使有一个轻量级
进程在系统调用中阻塞了，也不会影响整个进程继续工作，但是轻量级进程具有它的局限
性：首先，由于是基于内核线程实现的，所以各种线程操作，如创建、析构及同步，都需要
进行系统调用。而系统调用的代价相对较高，需要在用户态（User Mode）和内核态（Kernel
Mode）中来回切换。其次，每个轻量级进程都需要有一个内核线程的支持，因此轻量级进
程要消耗一定的内核资源（如内核线程的栈空间），因此一个系统支持轻量级进程的数量是
有限的

2. 使用用户线程实现

从广义上来讲，一个线程只要不是内核线程，就可以认为是用户线程（User
Thread,UT），因此，从这个定义上来讲，轻量级进程也属于用户线程，但轻量级进程的实
现始终是建立在内核之上的，许多操作都要进行系统调用，效率会受到限制

而狭义上的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知线程存
在的实现。用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。
如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，
也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这
种进程与用户线程之间1：N的关系称为一对多的线程模型，如图12-4所示

使用用户线程的优势在于不需要系统内核支援，劣势也在于没有系统内核的支援，所有
的线程操作都需要用户程序自己处理。线程的创建、切换和调度都是需要考虑的问题，而且
由于操作系统只把处理器资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何
将线程映射到其他处理器上”这类问题解决起来将会异常困难，甚至不可能完成。因而使用
用户线程实现的程序一般都比较复杂，除了以前在不支持多线程的操作系统中（如DOS）
的多线程程序与少数有特殊需求的程序外，现在使用用户线程的程序越来越少了，Java、
Ruby等语言都曾经使用过用户线程，最终又都放弃使用它

(此处所讲的“复杂”与“程序自己完成线程操作”，并不限制程序中必须编写了复杂的实现用
户线程的代码，使用用户线程的程序，很多都依赖特定的线程库来完成基本的线程操作，这
些复杂性都封装在线程库之中)

3. 使用用户线程加轻量级进程混合实现

线程除了依赖内核线程实现和完全由用户程序自己实现之外，还有一种将内核线程与用
户线程一起使用的实现方式。在这种混合实现下，既存在用户线程，也存在轻量级进程。用
户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，并
且可以支持大规模的用户线程并发。而操作系统提供支持的轻量级进程则作为用户线程和内
核线程之间的桥梁，这样可以使用内核提供的线程调度功能及处理器映射，并且用户线程的
系统调用要通过轻量级线程来完成，大大降低了整个进程被完全阻塞的风险。在这种混合模
式中，用户线程与轻量级进程的数量比是不定的，即为N：M的关系，如图12-5所示，这种
就是多对多的线程模型

许多UNIX系列的操作系统，如Solaris、HP-UX等都提供了N：M的线程模型实现

4. Java线程的实现

Java线程在JDK 1.2之前，是基于称为“绿色线程”（Green Threads）的用户线程实现的，
而在JDK 1.2中，线程模型替换为基于操作系统原生线程模型来实现。因此，在目前的JDK版
本中，操作系统支持怎样的线程模型，在很大程度上决定了Java虚拟机的线程是怎样映射
的，这点在不同的平台上没有办法达成一致，虚拟机规范中也并未限定Java线程需要使用哪
种线程模型来实现。线程模型只对线程的并发规模和操作成本产生影响，对Java程序的编码
和运行过程来说，这些差异都是透明的

对于Sun JDK来说，它的Windows版与Linux版都是使用一对一的线程模型实现的，一条
Java线程就映射到一条轻量级进程之中，因为Windows和Linux系统提供的线程模型就是一对
一的

(Windows下有纤程包（Fiber Package），Linux下也有NGPT（在2.4内核的年代）来实现
N：M模型，但是它们都没有成为主流)

###### 12.4.2 Java线程调度
线程调度是指系统为线程分配处理器使用权的过程，主要调度方式有两种，分别是协同
式线程调度（Cooperative Threads-Scheduling）和抢占式线程调度（Preemptive ThreadsScheduling）

如果使用协同式调度的多线程系统，线程的执行时间由线程本身来控制，线程把自己的
工作执行完了之后，要主动通知系统切换到另外一个线程上。协同式多线程的最大好处是实
现简单，而且由于线程要把自己的事情干完后才会进行线程切换，切换操作对线程自己是可
知的，所以没有什么线程同步的问题。Lua语言中的“协同例程”就是这类实现。它的坏处也
很明显：线程执行时间不可控制，甚至如果一个线程编写有问题，一直不告知系统进行线程
切换，那么程序就会一直阻塞在那里。很久以前的Windows 3.x系统就是使用协同式来实现
多进程多任务的，相当不稳定，一个进程坚持不让出CPU执行时间就可能会导致整个系统崩溃

如果使用抢占式调度的多线程系统，那么每个线程将由系统来分配执行时间，线程的切
换不由线程本身来决定（在Java中，Thread.yield()可以让出执行时间，但是要获取执行时
间的话，线程本身是没有什么办法的）。在这种实现线程调度的方式下，线程的执行时间是
系统可控的，也不会有一个线程导致整个进程阻塞的问题，Java使用的线程调度方式就是抢
占式调度。与前面所说的Windows 3.x的例子相对，在Windows 9x/NT内核中就是使用抢占
式来实现多进程的，当一个进程出了问题，我们还可以使用任务管理器把这个进程“杀掉”，
而不至于导致系统崩溃

(在JDK后续版本中有可能会提供协程（Coroutines）方式来进行多任务处理，相关资料可
参见：http://wikis.sun.com/display/mlvm/Coroutines)

虽然Java线程调度是系统自动完成的，但是我们还是可以“建议”系统给某些线程多分配
一点执行时间，另外的一些线程则可以少分配一点——这项操作可以通过设置线程优先级来
完成。Java语言一共设置了10个级别的线程优先级（Thread.MIN_PRIORITY至
Thread.MAX_PRIORITY），在两个线程同时处于Ready状态时，优先级越高的线程越容易被
系统选择执行

不过，线程优先级并不是太靠谱，原因是Java的线程是通过映射到系统的原生线程上来
实现的，所以线程调度最终还是取决于操作系统，虽然现在很多操作系统都提供线程优先级
的概念，但是并不见得能与Java线程的优先级一一对应，如Solaris中有2147483648（2^32）种
优先级，但Windows中就只有7种，比Java线程优先级多的系统还好说，中间留下一点空位就
可以了，但比Java线程优先级少的系统，就不得不出现几个优先级相同的情况了，表12-1显
示了Java线程优先级与Windows线程优先级之间的对应关系，Windows平台的JDK中使用了除
THREAD_PRIORITY_IDLE之外的其余6种线程优先级

上文说到“线程优先级并不是太靠谱”，不仅仅是说在一些平台上不同的优先级实际会变
得相同这一点，还有其他情况让我们不能太依赖优先级：优先级可能会被系统自行改变。例
如，在Windows系统中存在一个称为“优先级推进器”（Priority Boosting，当然它可以被关闭
掉）的功能，它的大致作用就是当系统发现一个线程执行得特别“勤奋努力”的话，可能会越
过线程优先级去为它分配执行时间。因此，我们不能在程序中通过优先级来完全准确地判断
一组状态都为Ready的线程将会先执行哪一个

###### 12.4.3 状态转换
Java语言定义了5种线程状态，在任意一个时间点，一个线程只能有且只有其中的一种
状态，这5种状态分别如下

新建（New）：创建后尚未启动的线程处于这种状态

运行（Runable）：Runable包括了操作系统线程状态中的Running和Ready，也就是处于此
状态的线程有可能正在执行，也有可能正在等待着CPU为它分配执行时间

无限期等待（Waiting）：处于这种状态的线程不会被分配CPU执行时间，它们要等待被
其他线程显式地唤醒。以下方法会让线程陷入无限期的等待状态：

- 没有设置Timeout参数的Object.wait()方法
- 没有设置Timeout参数的Thread.join()方法
- LockSupport.park()方法

限期等待（Timed Waiting）：处于这种状态的线程也不会被分配CPU执行时间，不过无
须等待被其他线程显式地唤醒，在一定时间之后它们会由系统自动唤醒。以下方法会让线程
进入限期等待状态：

Thread.sleep()方法
设置了Timeout参数的Object.wait()方法
设置了Timeout参数的Thread.join()方法
LockSupport.parkNanos()方法
LockSupport.parkUntil()方法

阻塞（Blocked）：线程被阻塞了，“阻塞状态”与“等待状态”的区别是：“阻塞状态”在等
待着获取到一个排他锁，这个事件将在另外一个线程放弃这个锁的时候发生；而“等待状
态”则是在等待一段时间，或者唤醒动作的发生。在程序等待进入同步区域的时候，线程将
进入这种状态

结束（Terminated）：已终止线程的线程状态，线程已经结束执行

上述5种状态在遇到特定事件发生的时候将会互相转换，它们的转换关系如图12-6所示

##### 12.5 本章小结
本章中，我们首先了解了虚拟机Java内存模型的结构及操作，然后讲解了原子性、可见
性、有序性在Java内存模型中的体现，最后介绍了先行发生原则的规则及使用。另外，我们
还了解了线程在Java语言之中是如何实现的

关于“高效并发”这个话题，在本章中主要介绍了虚拟机如何实现“并发”，在第13章中，
我们的主要关注点将是虚拟机如何实现“高效”，以及虚拟机对我们编写的并发代码提供了什
么样的优化手段

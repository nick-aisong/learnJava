#### 第7章 并发与多线程
目前CPU的运算速度已经达到百亿次每秒，甚至更高的量级，家用电脑即使维
持操作系统正常运行的进程也会有数十个，线程更是数以百计。所以，在现实场景中, 
为了提高生产率和高效地完成任务，处处均采用多线程和并发的运作方式

首先从并发(Concurrency)与并行(Parallelism)说起。并发是指在某个时间段
内，多任务交替处理的能力。所谓不患寡而患不均，每个CPU不可能只顾着执行某
个进程，让其他进程一直处于等待状态。所以，CPU把可执行时间均匀地分成若干份，
每个进程执行一段时间后，记录当前的工作状态，释放相关的执行资源并进入等待状
态，让其他进程抢占CPU资源。并行是指同时处理多任务的能力。目前，CPU已经
发展为多核，可以同时执行多个互不依赖的指令及执行块。并发与并行两个概念非常
容易混淆，它们的核心区别在于进程是否同时执行。以KTV唱歌为例，并行指的是
有多少人可以使用话筒同时唱歌；并发指的是同一个话筒被多个人轮流使用

并发与并行的目标都是尽可能快地执行完所有任务。以医生坐诊为例，某个科室
有两个专家同时出诊，这就是两个并行任务；其中一个医生，时而问诊，时而查看
化验单，然后继续问诊，突然又中断去处理病人的咨询，这就是并发。在并发环境下，
由于程序的封闭性被打破，出现了以下特点：

(1) 并发程序之间有相互制约的关系。直接制约体现为一个程序需要另一个程
序的计算结果；间接制约体现为多个程序竞争共享资源，如处理器、缓冲区等

(2) 并发程序的执行过程是断断续续的。程序需要记忆现场指令及执行点

(3) 当并发数设置合理并且CPU拥有足够的处理能力时，并发会提高程序的运
行效率

##### 7.1 线程安全
线程是CPU调度和分派的基本单位，为了更充分地利用CPU资源，一般都会使
用多线程进行处理。多线程的作用是提高任务的平均执行速度，但是会导致程序可理
解性变差，编程难度加大。例如，楼下有一车砖头需要工人搬到21楼，如果10个人
一起搬，速度一定比1个人搬要快，完成任务的总时间会极大减少。但是论单次的时
间成本，由于楼梯交会等因素10个人比1个人要慢。如果无限地增加人数，比如
10000人参与搬砖时，反而会因为楼道拥堵不堪变得更慢，所以合适的人数才会使工
作效率最大化。同理，合适的线程数才能让CPU资源被充分利用。如图7-1所示，
这是计算机的资源监视数据，红色箭头指向的PID就是进程ID，绿色箭头表示Java
进程运行着30个线程

线程可以拥有自己的操作栈、程序计数器、局部变量表等资源，它与同一进程
内的其他线程共享该进程的所有资源。线程在生命周期内存在多种状态。如图7-2所
示，有NEW(新建状态)、RUNNABLE(就绪状态)、RUNNING(运行状态)、
BLOCKED(阻塞状态)、DEAD( 终止状态)五种状态

(1) NEW，即新建状态，是线程被创建且未启动的状态。创建线程的方式有三种：
第一种是继承自Thread类，第二种是实现Runnable接口，第三种是实现Callable接
口。相比第一种，推荐第二种方式，因为继承自Thread类往往不符合里氏代换原则，
而实现Runnable接口可以使编程更加灵活，对外暴露的细节比较少，让使用者专注
于实现线程的run()方法上。第三种Callable接口的call()声明如下：
```java
    /**
     *Computes a result, or throws an exception if unable to do so.
     *@return computed result, V is generics value
     *@throws Exception if unable to compute a result
     */
    V call() throws Exception;
```
由此可知，Callable与Runnable有两点不同：第一，可以通过call()获得
返回值。前两种方式都有一个共同的缺陷，即在任务执行完成后，无法直接获
取执行结果，需要借助共享变量等获取，而Callable和Future则很好地解决了
这个问题，第二，call()可以抛出异常。而Runnable只有通过
setDefaultUncaughtExceptionHandler()的方式才能在主线程中捕捉到子线程异常

(2) RUNNABLE，即就绪状态，是调用start()之后运行之前的状态。线程的
start()不能被多次调用，否则会抛出IllegalStateException异常

(3) RUNNING，即运行状态，是run()正在执行时线程的状态。线程可能会由
于某些因素而退出RUNNING，如时间、异常、锁、调度等

(4) BLOCKED，即阻塞状态，进入此状态，有以下种情况

- 同步阻塞：锁被其他线程占用
- 主动阻塞：调用Thread的某些方法，主动让出CPU执行权，比如sleep()、join()等
- 等待阻塞：执行了wait()

(5) DEAD，即终止状态，是run()执行结束，或因异常退出后的状态，此状态
不可逆转

再用医生坐诊的例子说明，医生并发地处理多个病人的询问、开化验单、查看化
验结果、开药等工作，任何一个环节一旦出现数据混淆，都可能引发严重的医疗事故。
延伸到计算机的线程处理过程中，因为各个线程轮流占用CPU的计算资源，可能会
出现某个线程尚未执行完就不得不中断的情况，容易导致线程不安全。例如，在服务
端某个高并发业务共享某用户数据，首先A线程执行用户数据的查询任务，但数据
尚未返回就退出CPU时间片；然后B线程抢占了CPU资源执行并覆盖了该用户数据，
最后A线程返回到执行现场，直接将B线程处理过后的用户数据返回给前端，导致
页面显示数据错误。为保证线程安全，在多个线程并发地竞争共享资源时，通常采用
同步机制协调各个线程的执行，以确保得到正确的结果

线程安全问题只在多线程环境下才出现，单线程串行执行不存在此问题。保证高
并发场景下的线程安全，可以从以下四个维度考量：

(1) 数据单线程内可见。单线程总是安全的。通过限制数据仅在单线程内可见，
可以避免数据被其他线程篡改。最典型的就是线程局部变量，它存储在独立虛拟机栈
帧的局部变量表中，与其他线程毫无瓜葛。ThreadLocal就是采用这种方式来实现线
程安全的

(2) 只读对象。只读对象总是安全的。它的特性是允许复制、拒绝写入。最典
型的只读对象有String、Integer等。一个对象想要拒绝任何写入，必须要满足以下条件：
使用final关键字修饰类，避免被继承；使用private final关键字避免属性被中途修改；
没有任何更新方法；返回值不能以可变对象为引用

(3) 线程安全类。某些线程安全类的内部有非常明确的线程安全机制。比如
StringBuffer就是一个线程安全类，它采用synchronized关键字来修饰相关方法

(4) 同步与锁机制。如果想要对某个对象进行并发更新操作，但又不属于上述
三类，需要开发工程师在代码中实现安全的同步机制。虽然这个机制支持的并发场景
很有价值，但非常复杂且容易出现问题

线程安全的核心理念就是“要么只读，要么加锁”。合理利用好JDK提供的并发包，
往往能化腐朽为神奇。Java并发包( java.util.concurrent, JUC )中大多数类注释都写有：
@author Doug Lea。如果说Java是一本史书，那么Doug Lea绝对是开疆拓土的伟大
人物。Doug Lea在当大学老师时，专攻并发编程和并发数据结构设计，主导设计了
JUC并发包，提高了Java并发编程的易用性，大大推进了Java的商用进程。并发包
主要分成以下几个类族：

(1) 线程同步类。这些类使线程间的协调更加容易，支持了更加丰富的线程
协调场景，逐步淘汰了使用Object的wait()和notify()进行同步的方式。主要代表为
CountDownLatch、Semaphore、CyclicBarrier等

(2) 并发集合类。集合并发操作的要求是执行速度快，提取数据准。最著名的
类非ConcurrentHashMap莫属，它不断地优化，由刚开始的锁分段到后来的CAS，
不断地提升并发性能。其他还有ConcurrentSkipListMap、CopyOnWriteArrayList、
BlockingQueue等

(3) 线程管理类。虽然Thread和ThreadLocal在JDK1.0就已经引入，但是真
正把Thread发扬光大的是线程池。根据实际场景的需要，提供了多种创建线程池的
快捷方式，如使用Executors静态工厂或者使用ThreadPoolExecutor等。另外，通过
ScheduledExecutorService来执行定时任务

(4) 锁相关类。锁以Lock接口为核心，派生出在一些实际场景中进行互斥操
作的锁相关类。最有名的是ReentrantLock。锁的很多概念在弱化，是因为锁的实现
在各种场景中已经通过类库封装进去了

并发包中的类族有很多，差异比较微妙，开发工程师需要有很好的Java基础、
逻辑思维能力，还需要有一定的数据结构基础，才能够彻底分清各个类族的优点、缺
点及差异点

解决线程安全问题的能力是开发工程师进阶的重要能力之一。由于初创公司的业
务流量通常比较小，再加上其初级程序员缺乏线程安全意识。所以，即使出现了由高
并发导致的错误，往往也由于复现难度大、追踪困难而不了了之。但是在后期的系统
重构中，这些公司一定会为以上线程安全隐患买单

##### 7.2 什么是锁
从古代的门闩、铁锁到现代的密码锁、指纹锁、虹膜识别锁等，锁的便捷性和安
全性在不断提升，对于私有财产或领地的保护也更加高效和健全。在计算机信息世界
里，单机单线程时代没有锁的概念。自从出现了资源竞争，人们才意识到需要对部分
场景的执行现场加锁，昭告天下，表明自己的“短暂”拥有(其实对于任何有形或无
形的东西，拥有都不可能是永恒的)。计算机的锁也是从开始的悲观锁，发展到后来
的乐观锁、偏向锁、分段锁等。锁主要提供了两种特性：互斥性和不可见性。因为锁
的存在，某些操作对外界来说是黑箱进行的，只有锁的持有者才知道对变量进行了什
么修改

计算机的锁分类有很多，本书并不打算详细介绍每种锁，而是通过对
java.util.concurrent (JUC)包中基础类的解析来说明锁的本质和特性。Java中常用锁实现的方
式有两种

1. 用并发包中的锁类

并发包的类族中，Lock是JUC包的顶层接口，它的实现逻辑并未用到
synchronized，而是利用了volatile的可见性。先通过Lock来了解JUC包的一些基础类，
如图7-3所示

图7-3为Lock的继承类图，ReentrantLock对于Lock接口的实现主要依赖了
Sync，而Sync继承了AbstractQueuedSynchronizer (AQS)，它是JUC包实现同步的
基础工具。在AQS中，定义了一个volatile int state 变量作为共享资源，如果线程获
取资源失败，则进入同步FIFO队列中等待；如果成功获取资源就执行临界区代码。
执行完释放资源时，会通知同步队列中的等待线程来获取资源后出队并执行

AQS是抽象类，内置自旋锁实现的同步队列，封装入队和出队的操作，提供独
占、共享、中断等特性的方法。AQS的子类可以定义不同的资源实现不同性质的方
法。比如可重入锁ReentrantLock，定义state为0时可以获取资源并置为1。若已获
得资源，state不断加1，在释放资源时state减1，直至为0；CountDownLatch初始时
定义了资源总量state=count，countDown()不断将state减1，当state=0时才能获得锁，
释放后state就一直为0。所有线程调用await()都不会等待，所以CountDownLatch是
一次性的，用完后如果再想用就只能重新创建一个；如果希望循环使用，推荐使用基
于ReentrantLock实现的CyclicBarrier。Semaphore与CountDownLatch略有不同，同
样也是定义了资源总量state=permits，当state>0时就能获得锁，并将state减1，当
state=0时只能等待其他线程释放锁，当释放锁时state加1，其他等待线程又能获得
这个锁。当Semphore的permits定义为1时，就是互斥锁，当permits>1就是共享锁

JDK8提出了一个新的锁：StampedLock，改进了读写锁ReentrantReadWriteLock。
这些新增的锁相关类不断丰富了JUC包的内容，降低了并发编程的难度，提高了锁
的性能和安全性

2. 利用同步代码块

同步代码块一般使 用Java的synchronized关键字来实现，有两种方式对方法进行
加锁操作：第一，在方法签名处加synchronized关键字；第二，使用synchronized(对
象或类)进行同步。这里的原则是锁的范围尽可能小，锁的时间尽可能短，即能锁对象，
就不要锁类；能锁代码块，就不要锁方法

synchronized锁特性由JVM负责实现。在JDK的不断优化迭代中，synchronized
锁的性能得到极大提升，特别是偏向锁的实现，使得synchronized已经不是昔日那个
低性能且笨重的锁了。JVM底层是通过监视锁来实现synchronized同步的。监视锁
即monitor，是每个对象与生俱来的一个隐藏字段。使用synchronized时，JVM会根
据synchronized的当前使用环境，找到对应对象的monitor，再根据monitor的状态进
行加、解锁的判断。例如，线程在进入同步方法或代码块时，会获取该方法或代码块
所属对象的monitor，进行加锁判断。如果成功加锁就成为该monitor的唯一持有者。
monitor在被释放前，不能再被其他线程获取。下面通过字节码学习synchronized锁
是如何实现的：
```java
public void testSynchronized();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=2, args_size=1
         0: getstatic     #13
         // Field mutex:Ljava/lang/Object;
         3: dup
         4: astore_1
         5: monitorenter
         6: getstatic     #39
         // Field java/lang/System.out:Ljava/io/PrintStream;
         9: ldc           #45
         // String hello world
        11: invokevirtual #47
         // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        14: aload_1
        15: monitorexit
        16: goto          22
        19: aload_1
        20: monitorexit 
        21: athrow
        22: return 
    Exception table:
       from    to    target    type 
           6    16      19      any
          19    21      19      any
    LineNumberTable:
      line 26: 0
      line 27: 6
      line 26: 14
      line 29: 22
    LocalVariableTable:
      Start    Length    Slot    Name    Signature
          0        23       0    this    Ltest/Test;
```
方法元信息中会使用ACC_SYNCHRONIZED标识该方法是一个同步方法。同
步代码块中会使用monitorenter及monitorexit两个字节码指令获取和释放monihitor。
如果使用monitorenter进入时monitor为0，表示该线程可以持有monitor后续代码，
并将monitor加1；如果当前线程已经持有了monitor，那么monitor继续加1；如果
monitor非0，其他线程就会进入阻塞状态。JVM对synchronized的优化主要在于对
monitor的加锁、解锁上。JDK6后不断优化使得synchronized提供三种锁的实现，
包括偏向锁、轻量级锁、重量级锁，还提供自动的升级和降级机制。JVM就是利用
CAS在对象头上设置线程ID，表示这个对象偏向于当前线程，这就是偏向锁

偏向锁是为了在资源没有被多线程竞争的情况下尽量减少锁带来的性能开销。在
锁对象的对象头中有一个ThreadId字段，当第一个线程访问锁时，如果该锁没有被其
他线程访问过，即ThreadId字段为空，那么JVM让其持有偏向锁，并将ThreadId字
段的值设置为该线程的ID。当下一次获取锁时，会判断当前线程的ID是否与锁对象
的ThreadId一致。如果一致，那么该线程不会再重复获取锁，从而提高了程序的运行
效率。如果出现锁的竞争情况，那么偏向锁会被撤销并升级为轻量级锁。如果资源的
竞争非常激烈，会升级为重量级锁。偏向锁可以降低无竞争开销，它不是互斥锁，不
存在线程竞争的情况，省去再次同步判断的步骤，提升了性能

##### 7.3 线程同步
###### 7.3.1 同步是什么
资源共享的两个原因是资源紧缺和共建需求。线程共享CPU是从资源紧缺的维
度来考虑的，而多线程共享同一变量，通常是从共建需求的维度来考虑的。在多个线
程对同一变量进行写操作时，如果操作没有原子性，就可能产生脏数据。所谓原子性
是指不可分割的一系列操作指令，在执行完毕前不会被任何其他操作中断，要么全部
执行，要么全部不执行。如果每个线程的修改都是原子操作，就不存在线程同步问题。
有些看似非常简单的操作其实不具备原子性，典型的就是i++操作,它需要分为三步，
即ILOAD→INC→ISTORE。另一方面，更加复杂的CAS(Compare and Swap)操
作却具有原子性

线程同步现象在实际生活随处可见。比如乘客在火车站排队打车，每个人都是一
个线程，管理员每次放10个人进来，为了保证安全，等全部离开后，再放下一批人进来。
如果没有协调机制，场面一定是混乱不堪的，人们会一窝蜂地上去抢车，存在严重的
安全隐患。计算机的线程同步，就是线程之间按某种机制协调先后次序执行，当有一
个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线
程完成操作。实现线程同步的方式有很多，比如同步方法、锁、阻塞队列等

###### 7.3.2 volatile
先从happen before了解线程操作的可见性。把happen before定义为方法
hb(a,b)，表示a happen before b。如果hb(a,b)且hb(b,c)，能够推导出hb(a,c)。类似于
x>y且y>z，可以推导出x>z。这不就是一种放之四海而皆准的规律吗?但其实很多
场景并不符合这种规律，比如在2018年俄罗斯世界杯上，韩国队战胜德国队，德国
队战胜瑞典队，并不能推导出韩国队战胜了瑞典队

线程执行或线程切换都是纳秒级的，执行速度如此之快，直觉上会认为线程本地
缓存的必要性特别弱。做个类比，我们人类以年为计而宇宙以亿年为计，宇宙老人看
待人类的心态不正如我们看待CPU世界的心态吗?时间成本的巨大差异只要存在，
缓存策略自然就会产生。再比如，去学校图书馆仅需要10分钟，借一本书，无须缓存。
但如果去市图书馆，往返需要5个小时，一般为了减少路程开销而会考虑多借几本。
CPU访问内存远远比访问高速缓存L1和L2慢得多，对应借书的例子，应该得去国
外图书馆了

接着再谈指令优化。计算机并不会根据代码顺序按部就班地执行相关指令，再
回到借书例子，假如你刚好要去还书，然后再借一本， 你的室友恰好也让你帮他归还
Easy Coding这本书，然后再借一本《码出高效：Java开发手册》。这个过程有两件事：
你的事和他的事。先办完你的事，再办他的事，是一种单线程的死板行为。此时你会
潜意识地进行“指令优化”：把你要还的书和Easy Coding先一起归还，再一起借你
们要借的书，这相当于合并数据进行存取的操作过程。CPU在处理信息时也会进行
指令优化，分析哪些取数据动作可以合并进行，哪些存数据动作可以合并进行。CPU
拜访一趙遥远的内存，一定会到处看看，是否可以存取合并，以提高执行效率。指令
重排示例代码如下：
```java
@Override
public void run() {
    // (第1处)
    int X = 1;
    int y = 2;
    int z = 3;
    // (第2处)
    x = x + 1;
    // (第3处)
    int sum = x + y + z;
}
```
happen before是时钟顺序的先后，并不能保证线程交互的可见性。在第2处和第
3处都是写操作，不会进行指令重排，但是前三行是不互斥的，并且第1处的操作如
果放在z=3赋值操作之后，明显是效率最大化的处理方式。所以指令重排的最大可能
是把第1处和第2处串联依次执行。happen before并不能保证线程交互的可见性。那
么什么是可见性呢?可见性是指某线程修改共享变量的指令对其他线程来说都是可见
的，它反映的是指令执行的实时透明度

每个线程都有独占的内存区域，如操作栈、本地变量表等。线程本地内存保存了
引用变量在堆内存中的副本，线程对变量的所有操作都在本地内存区域中进行，执行
结束后再同步到堆内存中去。这里必然有一个时间差，在这个时间差内，该线程对副
本的操作，对于其他线程都是不可见的

volatile的英文本义是“挥发、不稳定的”，延伸意义为敏感的。当使用volatile
修饰变量时，意味着任何对此变量的操作都会在内存中进行，不会产生副本，以保证
共享变量的可见性，局部阻止了指令重排的发生。由此可知，在使用单例设计模式时，
即使用双检锁也不一定会拿到最新的数据

如下示例代码在高并发场景中会存在问题：
```java
class LazyInitDemo {
    private static TransactionService service = null;
    
    public static TransactionService getTransactionService() {
        if (service == null) {
            synchronized (this) {
                if (service == null) {
                    service = new TransactionService();
                }
            }
        }
        return service;
    }
    // other methods and fields... 
}
```
使用者在调用getTransactionService()时，有可能会得到初始化未完成的对
象。究其原因，与Java虚拟机的编译优化有关。对Java编译器而言，初始化
TransactionService实例和将对象地址写到service字段并非原子操作，且这两个阶段
的执行顺序是未定义的。假设某个线程执行new TransactionService()时，构造方法还
未被调用，编译器仅仅为该对象分配了内存空间并设为默认值，此时若另一个线程调
用getTransactionService()方法，由于service!=null，但是此时service对象还没有被赋
予真正有效的值，从而无法取到正确的service单例对象。这就是著名的双重检查锁
定(Double-checked Locking)问题，对象引用在没有同步的情况下进行读操作，导
致用户可能会获取未构造完成的对象。对于此问题，一种较为简单的解决方案是用
volatile关键字修饰目标属性(适用于JDK5及以上版本)，这样service就限制了编
译器对它的相关读写操作，对它的读写操作进行指令重排，确定对象实例化之后才返
回引用

锁也可以确保变量的可见性，但是实现方式和volatile略有不同。线程在得到锁
时读入副本，释放时写回内存，锁的操作尤其要符合happen before原则

volatile解决的是多线程共享变量的可见性问题，类似于synchronized，但不具备
synchronized的互斥性。所以对volatile变量的操作并非都具有原子性，这是一个容易
犯错误的地方。一个线程对共享变量进行10000次i++操作，另一个线程进行10000
次i--操作，如下示例代码：
```java
public class VolatileNotAtomic {
    private static volatile long count = 0L;
    private static final int NUMBER = 10000;
    
    public static void main(String[] args) {
        Thread subtractThread = new SubtractThread();
        subtractThread.start();
        
        for (int i = 0; i < NUMBER; i++) {
            count++;
        }
        
        // 等待减法线程结束
        while(subtractThread.isAlive()) {}
        
        System.out.println("count最后的值为: " + count);
    }
    
    private static class SubtractThread extends Thread {
        @Override
        public void run() {
            for(int i = 0; i < NUMBER; i++){
                count--;
            }
        }
    }
}
```
多次执行后，发现结果基本都不为0。如果在count++和count--两处都进行加锁
操作，才会得到预期是0的结果。这里对count的读取、加1操作的字节码如下：
```java
// 1. 读取count并压入操作栈顶
GETSTATIC com/alibaba/easy/coding/other/VolatileNotAtomic.count: I
// 2. 常量1压入操作栈顶
ICONST_1
// 3. 取出最顶部两个元素进行相加
IADD
// 4. 将刚才得到的和赋值给count
PUTSTATIC com/alibaba/easy/coding/other/VolatileNotAtomic.count: I
```
需要4步才能完成加1操作。在该过程中，其他线程有足够的时间覆盖变量的值，
如果想让示例代码最后的结果为零，需要对count++和count--加锁：
```java
for (int i = 0; i < MAX_VALUE; i++) {
    synchronized (VolatileNotAtomic.class) {
        // 在count--代码处也同样进行加锁处理
        count++;
    }
}
```
能实现count++原子操作的其他类有AtomicLong和LongAdder。JDK8推荐使用
LongAdder类，它比AtomicLong性能更好，有效地减少了乐观锁的重试次数

因此，“volatile 是轻量级的同步方式”这种说法是错误的。它只是轻量级的线程
操作可见方式，并非同步方式，如果是多写场景，一定会产生线程安全问题。如果是
一写多读的并发场景，使用volatile修饰变量则非常合适。volatile一写多读最典型的
应用是CopyOnWriteArrayList。它在修改数据时会把整个集合的数据全部复制出来，
对写操作加锁，修改完成后，再用setArray()把array指向新的集合。使用volatile可
以使读线程尽快地感知array的修改，不进行指令重排，操作后即对其他线程可见。
源码如下：
```java
pub1ic class CopyOnWriteArrayList<E> {
    // 集合真正存储元素的数组
    private transient volatile Object[] array;
    
    final void setArray(Object[] a) {
        array = a;
    }
}
```
在实际业务中，如何清晰地判断一写多读的场景显得尤为重要。如果不确定共享
变量是否会被多个线程并发写，保险的做法是使用同步代码块来实现线程同步。另外，
因为所有的操作都需要同步给内存变量，所以volatile一定会使线程的执行速度变慢，
故要审慎定义和使用volatile属性

###### 7.3.3 信号量同步




##### 7.4 线程池




###### 7.4.1 线程池的好处




###### 7.4.2 线程池源码详解




##### 7.5 ThreadLocal




###### 7.5.1 引用类型




###### 7.5.2 ThreadLocal价值




###### 7.5.3 ThreadLocal副作用






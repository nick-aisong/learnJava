#### 第7章 并发与多线程
目前CPU的运算速度已经达到百亿次每秒，甚至更高的量级，家用电脑即使维
持操作系统正常运行的进程也会有数十个，线程更是数以百计。所以，在现实场景中, 
为了提高生产率和高效地完成任务，处处均采用多线程和并发的运作方式

首先从并发(Concurrency)与并行(Parallelism)说起。并发是指在某个时间段
内，多任务交替处理的能力。所谓不患寡而患不均，每个CPU不可能只顾着执行某
个进程，让其他进程一直处于等待状态。所以，CPU把可执行时间均匀地分成若干份，
每个进程执行一段时间后，记录当前的工作状态，释放相关的执行资源并进入等待状
态，让其他进程抢占CPU资源。并行是指同时处理多任务的能力。目前，CPU已经
发展为多核，可以同时执行多个互不依赖的指令及执行块。并发与并行两个概念非常
容易混淆，它们的核心区别在于进程是否同时执行。以KTV唱歌为例，并行指的是
有多少人可以使用话筒同时唱歌；并发指的是同一个话筒被多个人轮流使用

并发与并行的目标都是尽可能快地执行完所有任务。以医生坐诊为例，某个科室
有两个专家同时出诊，这就是两个并行任务；其中一个医生，时而问诊，时而查看
化验单，然后继续问诊，突然又中断去处理病人的咨询，这就是并发。在并发环境下，
由于程序的封闭性被打破，出现了以下特点：

(1) 并发程序之间有相互制约的关系。直接制约体现为一个程序需要另一个程
序的计算结果；间接制约体现为多个程序竞争共享资源，如处理器、缓冲区等

(2) 并发程序的执行过程是断断续续的。程序需要记忆现场指令及执行点

(3) 当并发数设置合理并且CPU拥有足够的处理能力时，并发会提高程序的运
行效率

##### 7.1 线程安全
线程是CPU调度和分派的基本单位，为了更充分地利用CPU资源，一般都会使
用多线程进行处理。多线程的作用是提高任务的平均执行速度，但是会导致程序可理
解性变差，编程难度加大。例如，楼下有一车砖头需要工人搬到21楼，如果10个人
一起搬，速度一定比1个人搬要快，完成任务的总时间会极大减少。但是论单次的时
间成本，由于楼梯交会等因素10个人比1个人要慢。如果无限地增加人数，比如
10000人参与搬砖时，反而会因为楼道拥堵不堪变得更慢，所以合适的人数才会使工
作效率最大化。同理，合适的线程数才能让CPU资源被充分利用。如图7-1所示，
这是计算机的资源监视数据，红色箭头指向的PID就是进程ID，绿色箭头表示Java
进程运行着30个线程

线程可以拥有自己的操作栈、程序计数器、局部变量表等资源，它与同一进程
内的其他线程共享该进程的所有资源。线程在生命周期内存在多种状态。如图7-2所
示，有NEW(新建状态)、RUNNABLE(就绪状态)、RUNNING(运行状态)、
BLOCKED(阻塞状态)、DEAD( 终止状态)五种状态

(1) NEW，即新建状态，是线程被创建且未启动的状态。创建线程的方式有三种：
第一种是继承自Thread类，第二种是实现Runnable接口，第三种是实现Callable接
口。相比第一种，推荐第二种方式，因为继承自Thread类往往不符合里氏代换原则，
而实现Runnable接口可以使编程更加灵活，对外暴露的细节比较少，让使用者专注
于实现线程的run()方法上。第三种Callable接口的call()声明如下：
```java
    /**
     *Computes a result, or throws an exception if unable to do so.
     *@return computed result, V is generics value
     *@throws Exception if unable to compute a result
     */
    V call() throws Exception;
```
由此可知，Callable与Runnable有两点不同：第一，可以通过call()获得
返回值。前两种方式都有一个共同的缺陷，即在任务执行完成后，无法直接获
取执行结果，需要借助共享变量等获取，而Callable和Future则很好地解决了
这个问题，第二，call()可以抛出异常。而Runnable只有通过
setDefaultUncaughtExceptionHandler()的方式才能在主线程中捕捉到子线程异常

(2) RUNNABLE，即就绪状态，是调用start()之后运行之前的状态。线程的
start()不能被多次调用，否则会抛出IllegalStateException异常

(3) RUNNING，即运行状态，是run()正在执行时线程的状态。线程可能会由
于某些因素而退出RUNNING，如时间、异常、锁、调度等

(4) BLOCKED，即阻塞状态，进入此状态，有以下种情况

- 同步阻塞：锁被其他线程占用
- 主动阻塞：调用Thread的某些方法，主动让出CPU执行权，比如sleep()、join()等
- 等待阻塞：执行了wait()

(5) DEAD，即终止状态，是run()执行结束，或因异常退出后的状态，此状态
不可逆转

再用医生坐诊的例子说明，医生并发地处理多个病人的询问、开化验单、查看化
验结果、开药等工作，任何一个环节一旦出现数据混淆，都可能引发严重的医疗事故。
延伸到计算机的线程处理过程中，因为各个线程轮流占用CPU的计算资源，可能会
出现某个线程尚未执行完就不得不中断的情况，容易导致线程不安全。例如，在服务
端某个高并发业务共享某用户数据，首先A线程执行用户数据的查询任务，但数据
尚未返回就退出CPU时间片；然后B线程抢占了CPU资源执行并覆盖了该用户数据，
最后A线程返回到执行现场，直接将B线程处理过后的用户数据返回给前端，导致
页面显示数据错误。为保证线程安全，在多个线程并发地竞争共享资源时，通常采用
同步机制协调各个线程的执行，以确保得到正确的结果

线程安全问题只在多线程环境下才出现，单线程串行执行不存在此问题。保证高
并发场景下的线程安全，可以从以下四个维度考量：

(1) 数据单线程内可见。单线程总是安全的。通过限制数据仅在单线程内可见，
可以避免数据被其他线程篡改。最典型的就是线程局部变量，它存储在独立虛拟机栈
帧的局部变量表中，与其他线程毫无瓜葛。ThreadLocal就是采用这种方式来实现线
程安全的

(2) 只读对象。只读对象总是安全的。它的特性是允许复制、拒绝写入。最典
型的只读对象有String、Integer等。一个对象想要拒绝任何写入，必须要满足以下条件：
使用final关键字修饰类，避免被继承；使用private final关键字避免属性被中途修改；
没有任何更新方法；返回值不能以可变对象为引用

(3) 线程安全类。某些线程安全类的内部有非常明确的线程安全机制。比如
StringBuffer就是一个线程安全类，它采用synchronized关键字来修饰相关方法

(4) 同步与锁机制。如果想要对某个对象进行并发更新操作，但又不属于上述
三类，需要开发工程师在代码中实现安全的同步机制。虽然这个机制支持的并发场景
很有价值，但非常复杂且容易出现问题

线程安全的核心理念就是“要么只读，要么加锁”。合理利用好JDK提供的并发包，
往往能化腐朽为神奇。Java并发包( java.util.concurrent, JUC )中大多数类注释都写有：
@author Doug Lea。如果说Java是一本史书，那么Doug Lea绝对是开疆拓土的伟大
人物。Doug Lea在当大学老师时，专攻并发编程和并发数据结构设计，主导设计了
JUC并发包，提高了Java并发编程的易用性，大大推进了Java的商用进程。并发包
主要分成以下几个类族：

(1) 线程同步类。这些类使线程间的协调更加容易，支持了更加丰富的线程
协调场景，逐步淘汰了使用Object的wait()和notify()进行同步的方式。主要代表为
CountDownLatch、Semaphore、CyclicBarrier等

(2) 并发集合类。集合并发操作的要求是执行速度快，提取数据准。最著名的
类非ConcurrentHashMap莫属，它不断地优化，由刚开始的锁分段到后来的CAS，
不断地提升并发性能。其他还有ConcurrentSkipListMap、CopyOnWriteArrayList、
BlockingQueue等

(3) 线程管理类。虽然Thread和ThreadLocal在JDK1.0就已经引入，但是真
正把Thread发扬光大的是线程池。根据实际场景的需要，提供了多种创建线程池的
快捷方式，如使用Executors静态工厂或者使用ThreadPoolExecutor等。另外，通过
ScheduledExecutorService来执行定时任务

(4) 锁相关类。锁以Lock接口为核心，派生出在一些实际场景中进行互斥操
作的锁相关类。最有名的是ReentrantLock。锁的很多概念在弱化，是因为锁的实现
在各种场景中已经通过类库封装进去了

并发包中的类族有很多，差异比较微妙，开发工程师需要有很好的Java基础、
逻辑思维能力，还需要有一定的数据结构基础，才能够彻底分清各个类族的优点、缺
点及差异点

解决线程安全问题的能力是开发工程师进阶的重要能力之一。由于初创公司的业
务流量通常比较小，再加上其初级程序员缺乏线程安全意识。所以，即使出现了由高
并发导致的错误，往往也由于复现难度大、追踪困难而不了了之。但是在后期的系统
重构中，这些公司一定会为以上线程安全隐患买单

##### 7.2 什么是锁
从古代的门闩、铁锁到现代的密码锁、指纹锁、虹膜识别锁等，锁的便捷性和安
全性在不断提升，对于私有财产或领地的保护也更加高效和健全。在计算机信息世界
里，单机单线程时代没有锁的概念。自从出现了资源竞争，人们才意识到需要对部分
场景的执行现场加锁，昭告天下，表明自己的“短暂”拥有(其实对于任何有形或无
形的东西，拥有都不可能是永恒的)。计算机的锁也是从开始的悲观锁，发展到后来
的乐观锁、偏向锁、分段锁等。锁主要提供了两种特性：互斥性和不可见性。因为锁
的存在，某些操作对外界来说是黑箱进行的，只有锁的持有者才知道对变量进行了什
么修改

计算机的锁分类有很多，本书并不打算详细介绍每种锁，而是通过对
java.util.concurrent(JUC)包中基础类的解析来说明锁的本质和特性。Java中常用锁实现的方
式有两种

1. 用并发包中的锁类

并发包的类族中，Lock是JUC包的顶层接口，它的实现逻辑并未用到
synchronized，而是利用了volatile的可见性。先通过Lock来了解JUC包的一些基础类，
如图7-3所示

图7-3为Lock的继承类图，ReentrantLock对于Lock接口的实现主要依赖了
Sync，而Sync继承了AbstractQueuedSynchronizer(AQS)，它是JUC包实现同步的
基础工具。在AQS中，定义了一个volatile int state 变量作为共享资源，如果线程获
取资源失败，则进入同步FIFO队列中等待；如果成功获取资源就执行临界区代码。
执行完释放资源时，会通知同步队列中的等待线程来获取资源后出队并执行

AQS是抽象类，内置自旋锁实现的同步队列，封装入队和出队的操作，提供独
占、共享、中断等特性的方法。AQS的子类可以定义不同的资源实现不同性质的方
法。比如可重入锁ReentrantLock，定义state为0时可以获取资源并置为1。若已获
得资源，state不断加1，在释放资源时state减1，直至为0；CountDownLatch初始时
定义了资源总量state=count，countDown()不断将state减1，当state=0时才能获得锁，
释放后state就一直为0。所有线程调用await()都不会等待，所以CountDownLatch是
一次性的，用完后如果再想用就只能重新创建一个；如果希望循环使用，推荐使用基
于ReentrantLock实现的CyclicBarrier。Semaphore与CountDownLatch略有不同，同
样也是定义了资源总量state=permits，当state>0时就能获得锁，并将state减1，当
state=0时只能等待其他线程释放锁，当释放锁时state加1，其他等待线程又能获得
这个锁。当Semphore的permits定义为1时，就是互斥锁，当permits>1就是共享锁

JDK8提出了一个新的锁：StampedLock，改进了读写锁ReentrantReadWriteLock。
这些新增的锁相关类不断丰富了JUC包的内容，降低了并发编程的难度，提高了锁
的性能和安全性

2. 利用同步代码块

同步代码块一般使 用Java的synchronized关键字来实现，有两种方式对方法进行
加锁操作：第一，在方法签名处加synchronized关键字；第二，使用synchronized(对
象或类)进行同步。这里的原则是锁的范围尽可能小，锁的时间尽可能短，即能锁对象，
就不要锁类；能锁代码块，就不要锁方法

synchronized锁特性由JVM负责实现。在JDK的不断优化迭代中，synchronized
锁的性能得到极大提升，特别是偏向锁的实现，使得synchronized已经不是昔日那个
低性能且笨重的锁了。JVM底层是通过监视锁来实现synchronized同步的。监视锁
即monitor，是每个对象与生俱来的一个隐藏字段。使用synchronized时，JVM会根
据synchronized的当前使用环境，找到对应对象的monitor，再根据monitor的状态进
行加、解锁的判断。例如，线程在进入同步方法或代码块时，会获取该方法或代码块
所属对象的monitor，进行加锁判断。如果成功加锁就成为该monitor的唯一持有者。
monitor在被释放前，不能再被其他线程获取。下面通过字节码学习synchronized锁
是如何实现的：
```java
public void testSynchronized();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=2, args_size=1
         0: getstatic     #13
         // Field mutex:Ljava/lang/Object;
         3: dup
         4: astore_1
         5: monitorenter
         6: getstatic     #39
         // Field java/lang/System.out:Ljava/io/PrintStream;
         9: ldc           #45
         // String hello world
        11: invokevirtual #47
         // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        14: aload_1
        15: monitorexit
        16: goto          22
        19: aload_1
        20: monitorexit 
        21: athrow
        22: return 
    Exception table:
       from    to    target    type 
           6    16      19      any
          19    21      19      any
    LineNumberTable:
      line 26: 0
      line 27: 6
      line 26: 14
      line 29: 22
    LocalVariableTable:
      Start    Length    Slot    Name    Signature
          0        23       0    this    Ltest/Test;
```
方法元信息中会使用ACC_SYNCHRONIZED标识该方法是一个同步方法。同
步代码块中会使用monitorenter及monitorexit两个字节码指令获取和释放monihitor。
如果使用monitorenter进入时monitor为0，表示该线程可以持有monitor后续代码，
并将monitor加1；如果当前线程已经持有了monitor，那么monitor继续加1；如果
monitor非0，其他线程就会进入阻塞状态。JVM对synchronized的优化主要在于对
monitor的加锁、解锁上。JDK6后不断优化使得synchronized提供三种锁的实现，
包括偏向锁、轻量级锁、重量级锁，还提供自动的升级和降级机制。JVM就是利用
CAS在对象头上设置线程ID，表示这个对象偏向于当前线程，这就是偏向锁

偏向锁是为了在资源没有被多线程竞争的情况下尽量减少锁带来的性能开销。在
锁对象的对象头中有一个ThreadId字段，当第一个线程访问锁时，如果该锁没有被其
他线程访问过，即ThreadId字段为空，那么JVM让其持有偏向锁，并将ThreadId字
段的值设置为该线程的ID。当下一次获取锁时，会判断当前线程的ID是否与锁对象
的ThreadId一致。如果一致，那么该线程不会再重复获取锁，从而提高了程序的运行
效率。如果出现锁的竞争情况，那么偏向锁会被撤销并升级为轻量级锁。如果资源的
竞争非常激烈，会升级为重量级锁。偏向锁可以降低无竞争开销，它不是互斥锁，不
存在线程竞争的情况，省去再次同步判断的步骤，提升了性能

##### 7.3 线程同步
###### 7.3.1 同步是什么
资源共享的两个原因是资源紧缺和共建需求。线程共享CPU是从资源紧缺的维
度来考虑的，而多线程共享同一变量，通常是从共建需求的维度来考虑的。在多个线
程对同一变量进行写操作时，如果操作没有原子性，就可能产生脏数据。所谓原子性
是指不可分割的一系列操作指令，在执行完毕前不会被任何其他操作中断，要么全部
执行，要么全部不执行。如果每个线程的修改都是原子操作，就不存在线程同步问题。
有些看似非常简单的操作其实不具备原子性，典型的就是i++操作,它需要分为三步，
即ILOAD→INC→ISTORE。另一方面，更加复杂的CAS(Compare and Swap)操
作却具有原子性

线程同步现象在实际生活随处可见。比如乘客在火车站排队打车，每个人都是一
个线程，管理员每次放10个人进来，为了保证安全，等全部离开后，再放下一批人进来。
如果没有协调机制，场面一定是混乱不堪的，人们会一窝蜂地上去抢车，存在严重的
安全隐患。计算机的线程同步，就是线程之间按某种机制协调先后次序执行，当有一
个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线
程完成操作。实现线程同步的方式有很多，比如同步方法、锁、阻塞队列等

###### 7.3.2 volatile
先从happen before了解线程操作的可见性。把happen before定义为方法
hb(a,b)，表示a happen before b。如果hb(a,b)且hb(b,c)，能够推导出hb(a,c)。类似于
x>y且y>z，可以推导出x>z。这不就是一种放之四海而皆准的规律吗?但其实很多
场景并不符合这种规律，比如在2018年俄罗斯世界杯上，韩国队战胜德国队，德国
队战胜瑞典队，并不能推导出韩国队战胜了瑞典队

线程执行或线程切换都是纳秒级的，执行速度如此之快，直觉上会认为线程本地
缓存的必要性特别弱。做个类比，我们人类以年为计而宇宙以亿年为计，宇宙老人看
待人类的心态不正如我们看待CPU世界的心态吗?时间成本的巨大差异只要存在，
缓存策略自然就会产生。再比如，去学校图书馆仅需要10分钟，借一本书，无须缓存。
但如果去市图书馆，往返需要5个小时，一般为了减少路程开销而会考虑多借几本。
CPU访问内存远远比访问高速缓存L1和L2慢得多，对应借书的例子，应该得去国
外图书馆了

接着再谈指令优化。计算机并不会根据代码顺序按部就班地执行相关指令，再
回到借书例子，假如你刚好要去还书，然后再借一本， 你的室友恰好也让你帮他归还
Easy Coding这本书，然后再借一本《码出高效：Java开发手册》。这个过程有两件事：
你的事和他的事。先办完你的事，再办他的事，是一种单线程的死板行为。此时你会
潜意识地进行“指令优化”：把你要还的书和Easy Coding先一起归还，再一起借你
们要借的书，这相当于合并数据进行存取的操作过程。CPU在处理信息时也会进行
指令优化，分析哪些取数据动作可以合并进行，哪些存数据动作可以合并进行。CPU
拜访一趙遥远的内存，一定会到处看看，是否可以存取合并，以提高执行效率。指令
重排示例代码如下：
```java
@Override
public void run() {
    // (第1处)
    int X = 1;
    int y = 2;
    int z = 3;
    // (第2处)
    x = x + 1;
    // (第3处)
    int sum = x + y + z;
}
```
happen before是时钟顺序的先后，并不能保证线程交互的可见性。在第2处和第
3处都是写操作，不会进行指令重排，但是前三行是不互斥的，并且第1处的操作如
果放在z=3赋值操作之后，明显是效率最大化的处理方式。所以指令重排的最大可能
是把第1处和第2处串联依次执行。happen before并不能保证线程交互的可见性。那
么什么是可见性呢?可见性是指某线程修改共享变量的指令对其他线程来说都是可见
的，它反映的是指令执行的实时透明度

每个线程都有独占的内存区域，如操作栈、本地变量表等。线程本地内存保存了
引用变量在堆内存中的副本，线程对变量的所有操作都在本地内存区域中进行，执行
结束后再同步到堆内存中去。这里必然有一个时间差，在这个时间差内，该线程对副
本的操作，对于其他线程都是不可见的

volatile的英文本义是“挥发、不稳定的”，延伸意义为敏感的。当使用volatile
修饰变量时，意味着任何对此变量的操作都会在内存中进行，不会产生副本，以保证
共享变量的可见性，局部阻止了指令重排的发生。由此可知，在使用单例设计模式时，
即使用双检锁也不一定会拿到最新的数据

如下示例代码在高并发场景中会存在问题：
```java
class LazyInitDemo {
    private static TransactionService service = null;
    
    public static TransactionService getTransactionService() {
        if (service == null) {
            synchronized (this) {
                if (service == null) {
                    service = new TransactionService();
                }
            }
        }
        return service;
    }
    // other methods and fields... 
}
```
使用者在调用getTransactionService()时，有可能会得到初始化未完成的对
象。究其原因，与Java虚拟机的编译优化有关。对Java编译器而言，初始化
TransactionService实例和将对象地址写到service字段并非原子操作，且这两个阶段
的执行顺序是未定义的。假设某个线程执行new TransactionService()时，构造方法还
未被调用，编译器仅仅为该对象分配了内存空间并设为默认值，此时若另一个线程调
用getTransactionService()方法，由于service!=null，但是此时service对象还没有被赋
予真正有效的值，从而无法取到正确的service单例对象。这就是著名的双重检查锁
定(Double-checked Locking)问题，对象引用在没有同步的情况下进行读操作，导
致用户可能会获取未构造完成的对象。对于此问题，一种较为简单的解决方案是用
volatile关键字修饰目标属性(适用于JDK5及以上版本)，这样service就限制了编
译器对它的相关读写操作，对它的读写操作进行指令重排，确定对象实例化之后才返
回引用

锁也可以确保变量的可见性，但是实现方式和volatile略有不同。线程在得到锁
时读入副本，释放时写回内存，锁的操作尤其要符合happen before原则

volatile解决的是多线程共享变量的可见性问题，类似于synchronized，但不具备
synchronized的互斥性。所以对volatile变量的操作并非都具有原子性，这是一个容易
犯错误的地方。一个线程对共享变量进行10000次i++操作，另一个线程进行10000
次i--操作，如下示例代码：
```java
public class VolatileNotAtomic {
    private static volatile long count = 0L;
    private static final int NUMBER = 10000;
    
    public static void main(String[] args) {
        Thread subtractThread = new SubtractThread();
        subtractThread.start();
        
        for (int i = 0; i < NUMBER; i++) {
            count++;
        }
        
        // 等待减法线程结束
        while(subtractThread.isAlive()) {}
        
        System.out.println("count最后的值为: " + count);
    }
    
    private static class SubtractThread extends Thread {
        @Override
        public void run() {
            for(int i = 0; i < NUMBER; i++){
                count--;
            }
        }
    }
}
```
多次执行后，发现结果基本都不为0。如果在count++和count--两处都进行加锁
操作，才会得到预期是0的结果。这里对count的读取、加1操作的字节码如下：
```java
// 1. 读取count并压入操作栈顶
GETSTATIC com/alibaba/easy/coding/other/VolatileNotAtomic.count: I
// 2. 常量1压入操作栈顶
ICONST_1
// 3. 取出最顶部两个元素进行相加
IADD
// 4. 将刚才得到的和赋值给count
PUTSTATIC com/alibaba/easy/coding/other/VolatileNotAtomic.count: I
```
需要4步才能完成加1操作。在该过程中，其他线程有足够的时间覆盖变量的值，
如果想让示例代码最后的结果为零，需要对count++和count--加锁：
```java
for (int i = 0; i < MAX_VALUE; i++) {
    synchronized (VolatileNotAtomic.class) {
        // 在count--代码处也同样进行加锁处理
        count++;
    }
}
```
能实现count++原子操作的其他类有AtomicLong和LongAdder。JDK8推荐使用
LongAdder类，它比AtomicLong性能更好，有效地减少了乐观锁的重试次数

因此，“volatile 是轻量级的同步方式”这种说法是错误的。它只是轻量级的线程
操作可见方式，并非同步方式，如果是多写场景，一定会产生线程安全问题。如果是
一写多读的并发场景，使用volatile修饰变量则非常合适。volatile一写多读最典型的
应用是CopyOnWriteArrayList。它在修改数据时会把整个集合的数据全部复制出来，
对写操作加锁，修改完成后，再用setArray()把array指向新的集合。使用volatile可
以使读线程尽快地感知array的修改，不进行指令重排，操作后即对其他线程可见。
源码如下：
```java
pub1ic class CopyOnWriteArrayList<E> {
    // 集合真正存储元素的数组
    private transient volatile Object[] array;
    
    final void setArray(Object[] a) {
        array = a;
    }
}
```
在实际业务中，如何清晰地判断一写多读的场景显得尤为重要。如果不确定共享
变量是否会被多个线程并发写，保险的做法是使用同步代码块来实现线程同步。另外，
因为所有的操作都需要同步给内存变量，所以volatile一定会使线程的执行速度变慢，
故要审慎定义和使用volatile属性

###### 7.3.3 信号量同步
信号量同步是指在不同的线程之间，通过传递同步信号量来协调线程执行的
先后次序。这里重点分析基于时间维度和信号维度的两个类：CountDownLatch、
Semaphore

某国际化基础语言管理平台收到一个多语言翻译请求后，根据目标语种拆分成
多个子线程，对翻译引擎发起翻译请求。翻译完成后，同步返回给调用方，结果由于
countDown()抛出异常，导致发生故障，警示代码如下：
```java
public class CountDownLatchTest {
    public static void main(String[] args) {
        CountDownLatch count = new CountDownLatch(3);
        Thread thread1 = new TranslateThread("1st content", count);
        Thread thread2 = new TranslateThread("2nd content", count);
        Thread thread3 = new TranslateThread("3rd content", count);
        
        thread1.start();
        thread2.start();
        thread3.start();
        
        count.await(10, TimeUnit.SECONDS);
        System.out.println("所有线程执行完成");
        // 给调用端返回翻译结果
    }
}
class TranslateThread extends Thread {
    private String content;
    private final CountDownLatch count;
    
    public TranslateThread (String content, CountDownLatch count) {
        this.content = content;
        this.count = count; 
    }
    
    @Override
    public void run() {
        // 在某种情况下，执行翻译解析时，抛出异常    (第1处)
        if (Math.random() > 0.5) {
            throw new RuntimeException("原文存在非法字符");
        }
        System.out.println(content + " 的翻译已经完成，译文是...");
        count.countDown();
    }
}
```
代码中第1处抛出异常，且该异常没有被主线程try-catch到，最终该线程没有执
行countDown()方法。程序执行的时间较长，该问题难以定位，因为异常被吞得一干
二净。扩展说明一下，子线程异常可以通过线程方法setUncaughtExceptionHandler()
捕获

CountDownLatch是基于执行时间的同步类。在实际编码中，可能需要处理基于
空闲信号的同步情况。比如海关安检的场景，任何国家公民在出国时，都要走海关的
查验通道。假设某机场的海关通道共有3个窗口，一批需要出关的人排成长队，每个
人都是一个线程。当3个窗口中的任意一个出现空闲时，工作人员指示队列中第一个
人出队到该空闲窗口接受查验。对于上述场景，JDK中提供了一个Semaphore的信号
同步类，只有在调用Semaphore对象的acquire()成功后，才可以往下执行，完成后执
行release()释放持有的信号量，下一个线程就可以马上获取这个空闲信号量进入执行。
基于Semaphore的示例代码如下：
```java
public class CustomCheckWindow {
    public static void main(String[] args) {
        // 设定3个信号量，即3个服务窗口
        Semaphore semaphore = new Semaphore(3);
        
        // 这个队伍排了5个人
        for(int i = 1; i <= 5; i++) {
            new SecurityCheckThread(i, semaphore).start();
        }
    }
    
    private static class SecurityCheckThread extends Thread {
        private int seq;
        private Semaphore semaphore;
        
        public SecurityCheckThread(int seq, Semaphore semaphore) {
            this.seq = seq;
            this.semaphore = semaphore;
        }
        
        @Override
        public void run() {
            try {
                semaphore.acquire();
                System.out.println("No." + seq + "乘客，正在查验中");
                
                // 假设号码是整除2的人是身份可疑人员，需要花更长时间来安检
                if (seq % 2 == 0) {
                    Thread.sleep(1000);
                    System.out.println("No." + seq + "乘客，身份可疑，不能出国! ");
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                semaphore.release();
                System.out.println("No." + seq + "乘客已完成服务。");
            }
        }
    }
}
```
执行结果如下
```text
No.2乘客，正在查验中
No.3乘客，正在查验中
No.1乘客，正在查验中
No.1乘客已完成服务。
No.3乘客已完成服务。
No.4乘客，正在查验中
No.5乘客，正在查验中
No.5乘客已完成服务。
No.2乘客，身份可疑，不能出国!
No.2乘客已完成服务。
No.4乘客，身份可疑，不能出国!
No.4乘客已完成服务。
```
如果某个人身份可疑，需要确认更多的信息，这不会影响到其他窗口的安检速度。
只要其他线程能够拿到空闲信号量，都可以马上执行。如果Semaphore的窗口信号量
等于1，就是最典型的互斥锁

还有其他同步方式，如CyclicBarrier是基于同步到达某个点的信号量触发机制。
CyclicBarrier从命名上即可知道它是一个可以循环使用(Cyclic)的屏障式(Barrier)
多线程协作方式。采用这种方式进行刚才的安检服务，就是3个人同时进去，只有3
个人都完成安检，才会放下一批进来。这是一种非常低效的安检方式。但在某种场景
下就是非常正确的方式，假设在机场排队打车时，现场工作人员统一指挥，每次放3
辆车进来，坐满后开走，再放下一批车和人进来。通过CyclicBarrier的reset()来释放
线程资源

最后温馨提示，无论从性能还是安全性上考虑，我们尽量使用并发包中提供的信
号同步类，避免使用对象的wait()和notify()方式来进行同步

##### 7.4 线程池
###### 7.4.1 线程池的好处
线程使应用能够更加充分合理地协调利用CPU、内存、网络、I/O等系统资源。
线程的创建需要开辟虚拟机栈、本地方法栈、程序计数器等线程私有的内存空间。在
线程销毁时需要回收这些系统资源。频繁地创建和销毁线程会浪费大量的系统资源，
增加并发编程风险。另外，在服务器负载过大的时候，如何让新的线程等待或者友好
地拒绝服务?这些都是线程自身无法解决的。所以需要通过线程池协调多个线程，并
实现类似主次线程隔离、定时执行、周期执行等任务。线程池的作用包括：

- 利用线程池管理并复用线程、控制最大并发数等

- 实现任务线程队列缓存策略和拒绝机制

- 实现某些与时间相关的功能，如定时执行、周期执行等

- 隔离线程环境。比如，交易服务和搜索服务在同一台服务器上，分别开启两
个线程池，交易线程的资源消耗明显要大；因此，通过配置独立的线程池，
将较慢的交易服务与搜索服务隔离开，避免各服务线程相互影响

在了解线程池的基本作用后，我们学习一下线程池是如何创建线程的。
首先从ThreadPoolExecutor构造方法讲起，学习如何自定义ThreadFactory和
RejetedExecutionHandler，并编写一个最简单的线程池示例。然后，通过分析
ThreadPoolExecutor的execute和addWorker两个核心方法，学习如何把任务线程加入
到线程池中运行。ThreadPoolExecutor的构造方法如下：
```java
public ThreadPoolExecutor (
    int corePoolSize,                      // (第1个参数)
    int maximumPoolSize,                   // (第2个参数)
    long keepAliveTime,                    // (第3个参数)
    TimeUnit unit,                         // (第4个参数)
    BlockingQueue<runnable> workQueue,     // (第5个参数)
    ThreadFactory threadFactory,           // (第6个参数)
    RejectedExecutionHandler handler) {    // (第7个参数)
    if (corePoolSize < 0 ||
        // maximumPoolsize必须大于或等于1也要大于或等于corePoolSize    (第1处)
        maximumPoolSize <= 0 ||
        maximumPoolSize < corePoolSize ||
        keepAliveTime < 0)
        throw new IllegalArgumentException();
    //    (第2处)
    if (workQueue == null || threadFactory == null || handler == null)
        throw new NullPointerException();
    //其他代码
}
```
第1个参数：corePoolSize表示常驻核心线程数。如果等于0，则任务执行完之后，
没有任何请求进入时销毁线程池的线程；如果大于0，即使本地任务执行完毕，核心
线程也不会被销毁。这个值的设置非常关键，设置过大会浪费资源，设置过小会导致
线程频繁地创建或销毁

第2个参数：maximumPoolSize表示线程池能够容纳同时执行的最大线程数。从
上方示例代码中的第1处来看，必须大于或等于1。如果待执行的线程数大于此值，
需要借助第5个参数的帮助，缓存在队列中。如果maximumPoolSize与corePoolSize
相等，即是固定大小线程池

第3个参数：keepAliveTime表示线程池中的线程空闲时间，当空闲时间达
到keepAliveTime值时，线程会被销毁，直到只剩下corePoolSize个线程为止，避
免浪费内存和句柄资源。在默认情况下，当线程池的线程数大于corePoolSize时，
keepAliveTime才会起作用。但是当ThreadPoolExecutor的allowCoreThreadTimeOut
变量设置为true时，核心线程超时后也会被回收

第4个参数：TimeUnit表示时间单位。keepAliveTime的时间单位通常是
TimeUnit.SECONDS

第5个参数：workQueue表示缓存队列。当请求的线程数大于maximumPoolSize
时，线程进入BlockingQueue阻塞队列。后续示例代码中使用的LinkedBlockingQueue
是单向链表，使用锁来控制入队和出队的原子性，两个锁分别控制元素的添加和获取，
是一个生产消费模型队列

第6个参数：threadFactory表示线程工厂。它用来生产一组相同任务的线程。线
程池的命名是通过给这个factory增加组名前缀来实现的。在虚拟机栈分析时，就可
以知道线程任务是由哪个线程工厂产生的。

第7个参数：handler表示执行拒绝策略的对象。当超过第5个参数workQueue
的任务缓存区上限的时候，就可以通过该策略处理请求，这是一种简单的限流保护。
像某年双十一没有处理好访问流量过载时的拒绝策略，导致内部测试页面被展示出来，
使用户手足无措。友好的拒绝策略可以是如下三种：

(1) 保存到数据库进行削峰填谷。在空闲时再提取出来执行

(2) 转向某个提示页面

(3) 打印日志

从代码第2处来看，队列、线程工厂、拒绝处理服务都必须有实例对象，但在实
际编程中，很少有程序员对这三者进行实例化，而通过Executors这个线程池静态工
厂提供默认实现，那么Exceutors与ThreadPoolExecutor是什么关系呢?线程池相关
类图如图7-4所示

```java
/**
 * @param 线程任务
 * @throws RejectedExecutionException 如果无法创建任何状态的线程任务，
 */
void execute(Runnable command);
```
ExecutorService接口继承了Executor接口， 定义了管理线程任务的方法。
ExecutorService的抽象类AbstractExecutorService提供了submit()、invokeAll()等
部分方法的实现，但是核心方法Executor.execute()并没有在这里实现。因为所
有的任务都在这个方法里执行，不同实现会带来不同的执行策略，这一点在后
续的ThreadPoolExecutor解析时，会一步步地分析。通过Executors的静态工
厂方法可以创建三个线程池的包装对象：ForkJoinPool、ThreadPoolExecutor、
ScheduledThreadPoolExecutor。Executors核心的方法有五个：

- Executors.newWorkStealingPool：JDK8 引入，创建持有足够线程的线程池支
持给定的并行度，并通过使用多个队列减少竞争，此构造方法中把CPU数量
设置为默认的并行度：
```java
public static ExecutorService newWorkStealingPool() {
    // 返回ForkJoinPool (JDK7引入)对象，它也是AbstractExecutorService的子类
    return new ForkJoinPool(Runtime.getRuntime().availableProcessors()，
        ForkJoinPool.defaultForkJoinWorkerThreadFactory,
        null, true);
}
```
- Executors.newCachedThreadPool：maximumPoolSize最大可以至
Integer.MAX_VALUE，是高度可伸缩的线程池，如果达到这个上限，相信没有任何服务器
能够继续工作，肯定会抛出OOM异常。keepAliveTime默认为60秒，工作
线程处于空闲状态，则回收工作线程。如果任务数增加，再次创建出新线程
处理任务

- Executors.newSingleThreadExecutor：创建一个 单线程的线程池，相当于单线
程串行执行所有任务，保证按任务的提交顺序依次执行

- Executors.newFixedThreadPool：输入的参数即是固定线程数，既是核心线程
数也是最大线程数，不存在空闲线程，所以keepAliveTime等于0：
```java
public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads, 0L,
        TimeUnit.MILLISECONDS, new LinkedBlockingQueue<runnable>());
}
```
这里，输入的队列没有指明长度，下面介绍LinkedBlockingQueue的构造方法：
```java
public LinkedBlockingQueue() {
    this(Integer.MAX_VALUE);
}
```
使用这样的无界队列，如果瞬间请求非常大，会有OOM的风险。除
newWorkStealingPool外，其他四个创建方式都存在资源耗尽的风险

Executors中默认的线程工厂和拒绝策略过于简单，通常对用户不够友好。线程
工厂需要做创建前的准备工作，对线程池创建的线程必须明确标识，就像药品的生产
批号一样，为线程本身指定有意义的名称和相应的序列号。拒绝策略应该考虑到业务
场景，返回相应的提示或者友好地跳转。以下为简单的ThreadFactory 示例：
```java
public class UserThreadFactory implements ThreadFactory {
    private final String namePrefix;
    private final AtomicInteger nextId = new AtomicInteger(1);
    
    // 定义线程组名称，在使用jstack来排查线程问题时，非常有帮助
    UserThreadFactory (String whatFeatureOfGroup) {
        namePrefix = "UserThreadFactory's " + whatFeatureOfGroup + "-Worker-";
    }
    
    @Override
    public Thread newThread(Runnable task) {
        String name = namePrefix + nextId.getAndIncrement();
        Thread thread = new Thread(null, task, name, 0, false);
        System.out.println(thread.getName());
        return thread;
    }
}

// 任务执行体
class Task implements Runnable {
    private final AtomicLong count = new AtomicLong(0L);
    
    @Override
    public void run() {
        System.out.println("running_" + count.getAndIncrement());
    }
}
```
上述示例包括线程工厂和任务执行体的定义，通过newThread方法快速、统一地
创建线程任务，强调线程一定要有特定意义的名称，方便出错时回溯

如图7-5所示为排查底层公共缓存调用出错时的截图，绿色框采用自定义的线
程工厂，明显比蓝色框默认的线程厂创建的线程名称拥有更多的额外信息：如调
用来源、线程的业务含义，有助于快速定位到死锁、StackOverflowError等问题

下面再简单地实现一下RejectedExecutionHandler，实现了接口的rejectedExecution
方法，打印出当前线程池状态，源码如下：
```java
public class UserRejectHandler implements RejectedExecutionHandler {
    @Override
    public void rejectedExecution(Runnable task, ThreadPoolExecutor executor) {
        System.out.println("task rejected. " + executor.toString());
    }                       
}
```
在ThreadPoolExecutor中提供了四个公开的内部静态类：

- AbortPolicy (默认)：丢弃任务并拋出RejectedExecutionException异常
- DiscardPolicy：丢弃任务，但是不抛出异常，这是不推荐的做法
- DiscardOldestPolicy：拋弃队列中等待最久的任务，然后把当前任务加入队列中
- CallerRunsPolicy：调用任务的run()方法绕过线程池直接执行

根据之前实现的线程工厂和拒绝策略，线程池的相关代码实现如下：
```java
public class UserThreadPool {
    public static void main(String[] args) {
        // 缓存队列设置固定长度为2，为了快速触发rejectHandler
        BlockingQueue queue = new LinkedBlockingQueue(2);
        
        // 假设外部任务线程的来源由机房1和机房2的混合调用
        UserThreadFactory f1 = new UserThreadFactory("第1机房");
        UserThreadFactory f2 = new UserThreadFactory("第2机房");
        
        UserRejectHandler handler = new UserRejectHandler();
        
        // 核心线程为1，最大线程为2，为了保证触发rejectHandler 
        ThreadPoolExecutor threadPoolFirst
            = new ThreadPoolExecutor(1, 2, 60, 
                TimeUnit.SECONDS, queue, f1, handler);
        // 利用第二个线程工厂实例创建第二个线程池
        ThreadPoolExecutor threadPoolSecond
            = new ThreadPoolExecutor(1, 2, 60, 
                TimeUnit.SECONDS, queue, f2, handler);
        
        // 创建400个任务线程
        Runnable task = new Task();
        for(int i = 0; i < 200; i++) {
            threadPoolFirst.execute(task);
            threadPoolSecond.execute(task);
        }
    }
}
```
执行结果如下：
```text
From UserThreadFactory's 第1机房-Worker-1
From UserThreadFactory's 第2机房-Worker-1
From UserThreadFactory's 第1机房-Worker-2
From UserThreadFactory's 第2机房-Worker-2
running_2
running_3
running_4
running_5
running_0
running_1
your task is rejected. java.util.concurrent.ThreadPoolExecutor@13969fbe [Running, pool size = 2, active threads = 2, queued tasks = 2, completed tasks = 1]
```
当任务被拒绝的时候，拒绝策略会打印出当前线程池的大小已经达到了
maximumPoolSize=2， 且队列已满，完成的任务数提示已经有1个(最后一行)

###### 7.4.2 线程池源码详解
在ThreadPoolExecutor的属性定义中频繁地用位移运算来表示线程池状态，位
移运算是改变当前值的一种高效手段，包括左移与右移。下面从属性定义开始阅读
ThreadPoolExecutor的源码
```java
// Integer共有32位，最右边29位表示工作线程数，最左边3位表示线程池状态
// 注：简单地说，3个二进制位可以表示从0至7的8个不同的数值    (第1处)
private static final int COUNT_BITS = Integer.SIZE - 3;

// 000-11111111111111111111111111111，类似于子网掩码，用于位的与运算，
// 得到左边3位，还是右边29位
private static final int COUNT_MASK = (1 << COUNT_BITS) - 1 ;

// 用左边3位，实现5种线程池状态。(在左3位之后加入中画线有助于理解)
// 111-00000000000000000000000000000，十进制值：-536,870,912
// 此状态表示线程池能接受新任务
private static final int RUNNING = -1 << COUNT_BITS;

// 000-00000000000000000000000000000，十进制值：0
// 此状态不再接受新任务，但可以继续执行队列中的任务
private static final int SHUTDOWN = 0 << COUNT_BITS;

// 001-00000000000000000000000000000，十进制值：536,870,912
//此状态全面拒绝，并中断正在处理的任务
private static final int STOP = 1 << COUNT_BITS;

// 010-00000000000000000000000000000，十进制值：1,073,741,824
// 此状态表示所有任务已经被终止
private static final int TIDYING = 2 << COUNT_BITS;

// 011-00000000000000000000000000000，十进制值：1,610,612,736 
// 此状态表示已清理完现场
private static final int TERMINATED = 3 << COUNT_BITS;

// 与运算，比如001-00000000000000000000001000011，表示67个工作线程，
// 掩码取反： 111-00000000000000000000000000000，即得到左边3位001，
// 表示线程池当前处于STOP状态
private static int runStateOf (int c) { return c & ~COUNT_MASK; }

// 同理掩码000-11111111111111111111111111111，得到右边29位，即工作线程数
private static int workerCountOf(int c) { return c & COUNT_MASK; }

// 把左边3位与右边29位按或运算，合并成一个值
private static int ctlOf(int rs, int wc) { return rs | wc; }
```
第1处说明，线程池的状态用高3位表示，其中包括了符号位。五种状态的
十进制值按从小到大依次排序为：RUNNING < SHUTDOWN < STOP < TIDYING <
TERMINATED，这样设计的好处是可以通过比较值的大小来确定线程池的状态。例
如程序中经常会出现isRunning的判断：

```java
private static boolean isRunning(int c) {
    return c < SHUTDOWN;
}
```
我们都知道Executor接口有且只有一个方法execute，通过参数传入待执行线程
的对象。下面分析ThreadPoolExecutor关于execute方法的实现：

```java
public void execute(Runnable command){
    // 返回包含线程数及线程池状态的Integer类型数值
    int c = ctl.get();
    // 如果工作线程数小于核心线程数，则创建线程任务并执行
    if (workerCountOf(c) < corePoolSize) {
        // addWorker是另一个极为重要的方法，见下一段源码解析    (第1处)
        if (addWorker(command, true))
            return;
        // 如果创建失败，防止外部已经在线程池中加入新任务，重新获取一下
        c = ctl.get();
    }
    
    // 只有线程池处于RUNNING状态，才执行后半句：置入队列
    if (isRunning(c) && workQueue.offer(command)) {
        int recheck = ctl.get();
        // 如果线程池不是RUNNING状态，则将刚加入队列的任务移除
        if (!isRunning(recheck) && remove(command))
            reject(command); 
        // 如果之前的线程已被消费完，新建一个线程
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
        
    // 核心池和队列都已满，尝试创建一个新线程
    } else if (!addWorker(command, false))
        // 如果addWorker返回是false，即创建失败，则唤醒拒绝策略    (第2处)
        reject(command);
}
```
第1处：execute方法在不同的阶段有三次addWorker的尝试动作

第2处：发生拒绝的理由有两个：(1) 线程池状态为非RUNNING状态 (2) 等待队列已满

下面继续分析addWorker方法的源码：
```java
/**
 * 根据当前线程池状态，检查是否可以添加新的任务线程，如果可以则创建并启动任务
 * 如果一切正常则返回true。返回false的可能性如下：
 * 1.线程池没有处于RUNNING状态
 * 2.线程工厂创建新的任务线程失败
 *
 * firstTask：外部启动线程池时需要构造的第一个线程，它是线程的母体
 * core：新增工作线程时的判断指标，解释如下
 *    true表示新增工作线程时，需要判断当前RUNNING状态的线程是否少于corePoolsize
 *    false表示新增工作线程时，需要判断当前RUNNING状态的线程是否少于maximumPoolSize
 */
private boolean addWorker (Runnable firstTask, boolean core) {
    // 不需要任务预定义的语法标签，响应下文的continue retry，快速退出多层嵌套循环 (第1处)
    retry :
    for (int c = ctl.get();;) {
        // 参考之前的状态分析：如果RUNNING状态，则条件为假，不执行后面的判断
        // 如果是STOP及之上的状态，或者firstTask初始线程不为空，或者队列为空，
        // 都会直接返回创建失败    (第2处)
        if (runStateAtLeast(c, SHUTDOWN)
            && (runStateAtLeast(c, STOP) || firstTask != null
            || workQueue.isEmpty()))
            return false;
        
        for (;;) {
            // 如果超过最大允许线程数则不能再添加新的线程
            // 最大线程数不能超过2^29，否则影响左边3位的线程池状态值
            if (workerCountof(c)
                >= ((core?corePoolSize:maximumPoolSize)&COUNT_MASK))
            return false;
            
            // 将当前活动线程数+1    (第3处)
            if (compareAndIncrementWorkerCount(c))
                break retry;
            
            // 线程池状态和工作线程数是可变化的，需要经常提取这个最新值
            c = ctl.get();
            // 如果已经关闭，则再次从retry标签处进入，在第2处再做判断    (第4处)
            if (runStateAtLeast(c, SHUTDOWN))
                continue retry;
                // 如果线程还是处于RUNNING状态，那就在说明仅仅是第3处失败
                // 继续循环执行    (第5处)
        }
    }
    
    // 开始创建工作线程
    boolean workerStarted = false;
    boolean workerAdded = false;
    Worker w = null;
    try {
        // 利用Worker构造方法中的线程池工厂创建线程，并封装成工作线程Worker对象
        w = newThreadPoolExecutor.Worker(firstTask);
        // 注意这是Worker中的属性对象thread    (第6处)
        final Thread t = w.thread;
        if (t != null) {
            // 在进行ThreadPoolExecutor的敏感操作时
            // 都需要持有主锁，避免在添加和启动线程时被干扰
            final ReentrantLock mainLock = this.mainLock;
            mainLock.lock();
            try {
                int c = ctl.get();
                // 当线程池状态为RUNNING或SHUTDOWN
                // 且firstTask初始线程为空时
                if (isRunning(c) || (runStateLessThan(c, STOP)
                    && firstTask == null)) {
                    workers.add(w);
                    int s = workers.size();
                    // 整个线程池在运行期间的最大并发任务个数
                    if (s > largestPoolSize) largestPoolSize = s;
                    workerAdded = true;
                }
            } finally {
                mainLock.unlock();
            }
            if (workerAdded) {
                // 终于看到亲切的start方法
                // 注意，并非线程池的execute的command参数指向的线程
                t.start();
                workerStarted = true;
            }
        }
    } finally {
        if (!workerStarted)
            // 线程启动失败，把刚才第3处加上的工作线程计数再减回去
            addWorkerFailed(w);
    }
    return workerStarted;
}
```
这段代码晦涩难懂，部分地方甚至违反了代码规约，但其中蕴含的丰富的编码知
识点值得我们去学习，下面按序号来依次讲解

第1处，配合循环语句出现的label，类似于goto作用。label定义时，必须把标
签和冒号的组合语句紧紧相邻定义在循环体之前，否则会编译出错。目的是在实现多
重循环时能够快速退出到任何一层。这种做法的出发点似乎非常贴心，但是在大型软
件项目中，滥用标签行跳转的后果将是灾难性的。示例代码中，在retry下方有两个
无限循环，在workerCount加1成功后，直接退出两层循环

第2处，这样的表达式不利于代码阅读，应该改成：
```java
Boolean isNotAllowedToCreateTask
    = runStateAtLeast(c, SHUTDOWN) && (runStateAtLeast(c, STOP)
        || firstTask != null || workQueue.isEmpty());
     if (isNotAllowedToCreateTask) {
         // ...
}
```
第3处，与第1处的标签呼应，AtomicInteger对象的加1操作是原子性的。
break retry表示直接跳出与retry相邻的这个循环体

第4处，此continue跳转至标签处，继续执行循环。如果条件为假，则说明线程
池还处于运行状态，即继续在for(;;) 循环内执行

第5处，compareAndIncrementWorkerCount方法执行失败的概率非常低。即使失
败，再次执行时成功的概率也是极高的，类似于自旋锁原理。这里的处理逻辑是先加1，
创建失败再减1，这是轻量处理并发创建线程的方式。如果先创建线程，成功再加1，
当发现超出限制后再销毁线程，那么这样的处理方式明显比前者代价要大

第6处，Worker对象是工作线程的核心类实现，部分源码如下：
```java
/**
 * 它实现Runnable接口，并把本对象作为参数输入给run()方法中的runWorker(this)，
 * 所以内部属性线程thread在start的时候，即会调用runWorker方法
 */
private final class Worker 
        extends AbstractQueuedSynchronizer 
        implements Runnable {
        Worker(Runnable firstTask) {
            // 它是AbstractQueuedsynchronizer的方法
            // 在runWorker方法执行之前禁止线程被中断
            setState(-1);
            this.firstTask = firstTask;
            this.thread = getThreadFactory().newThread(this);
        }
        // 当thread被start()之后，执行runWorkder的方法
        public void run() {
            runWorker(this);
        }
    }
```
线程池的相关源码比较精炼，还包括线程池的销毁、任务提取和消费等，与线程
状态图一样，线程池也有自己独立的状态转化流程，本节不再展开。总结一下，使用
线程池要注意如下几点：

(1) 合理设置各类参数，应根据实际业务场景来设置合理的工作线程数

(2) 线程资源必须通过线程池提供，不允许在应用中自行显式创建线程

(3) 创建线程或线程池时请指定有意义的线程名称，方便出错时回溯

线程池不允许使用Executors，而是通过ThreadPoolExecutor的方式创建，这样的
处理方式能更加明确线程池的运行规则，规避资源耗尽的风险

(Executors大多数线程池是用的无界队列，还是用自定义容量的阻塞队列比较安全)

##### 7.5 ThreadLocal
“水能载舟，亦能覆舟。”用这句话来形容ThreadLocal最贴切不过。
ThreadLocal初衷是在线程并发时，解决变量共享问题，但由于过度设计，比如弱引
用和哈希碰撞，导致理解难度大、使用成本高，反而成为故障高发点，容易出现内存
泄漏、脏数据、共享对象更新等问题。单从ThreadLocal的命名看人们会认为只要用
它就对了，包治变量共享问题，然而并不是。本节以内存模型、弱引用、哈希算法为
铺垫，然后从CS真人游戏的示例代码入手，详细分析ThreadLocal源码。我们从中
可以学习到全新的编程思维方式，并认识到问题的来源，也能够帮助我们谙熟此类的
设计之道，扬长避短

###### 7.5.1 引用类型
前面介绍了内存布局和垃圾回收，对象在堆上创建之后所持有的引用其实是一种
变量类型，引用之间可以通过赋值构成一条引用链。从GC Roots开始遍历，判断引
用是否可达。引用的可达性是判断能否被垃圾回收的基本条件。JVM会据此自动管
理内存的分配与回收，不需要开发工程师干预。但在某些场景下，即使引用可达，也
希望能够根据语义的强弱进行有选择的回收，以保证系统的正常运行。根据引用类型
语义的强弱来决定垃圾回收的阶段，我们可以把引用分为强引用、软引用、弱引用和
虛引用四类。后三类引用，本质上是可以让开发工程师通过代码方式来决定对象的垃
圾回收时机。我们先简要了解一下这四类引用

强引用，即Strong Reference，最为常见。如Object object = new Object(); 这样的
变量声明和定义就会产生对该对象的强引用。只要对象有强引用指向，并且GC Roots
可达，那么Java内存回收时，即使濒临内存耗尽，也不会回收该对象

软引用，即Soft Reference，引用力度弱于“强引用”，是用在非必需对象的场景。
在即将OOM之前，垃圾回收器会把这些软引用指向的对象加入回收范围，以获得更
多的内存空间，让程序能够继续健康运行。主要用来缓存服务器中间计算结果及不需
要实时保存的用户行为等

弱引用，即Weak Reference，引用强度较前两者更弱，也是用来描述非必需对象
的。如果弱引用指向的对象只存在弱引用这一条线路， 则在下一次YGC时会被回收。
由于YGC时间的不确定性，弱引用何时被回收也具有不确定性。弱引用主要用于指
向某个易消失的对象，在强引用断开后，此引用不会劫持对象。调用
WeakReference.get()可能返回null，要注意空指针异常

虛引用，即Phantom Reference，是极弱的一种引用关系，定义完成后，就无法
通过该引用获取指向的对象。为一个对象设置虛引用的唯一目的就是希望能在这个对
象被回收时收到一个系统通知。虛引用必须与引用队列联合使用，当垃圾回收时，如
果发现存在虚引用，就会在回收对象内存前，把这个虚引用加入与之关联的引用队列中

对象的引用类型如图7-6所示

举个具体例子，在房产交易市场中，某个卖家有一套房子，成功出售给某个买
家后引用置为null。这里有4个买家使用4种不同的引用关系指向这套房子。买家
buyer1是强引用，如果把seller引用赋值给它，则永久有效，系统不会因为seller=null
就触发对这套房子的回收，这是房屋交易市场最常见的交付方式。买家buyer2是软
引用，只要不产生OOM，buyer2.get()就可以获取房子对象，就像房子是租来的一样。
买家buyer3是弱引用，一旦过户后，seller置为null，buyer3的房子持有时间估计只
有几秒钟，卖家只是给买家做了一张假的房产证，买家高兴了几秒钟后，发现房子已
经不是自己的了。buyer4是虛引用，定义完成后无法访问到房子对象，卖家只是虚构
了房源，是空手套白狼的诈骗术

强引用是最常用的，而虚引用在业务中几乎很难用到。本节重点介绍一下软
引用和弱引用。先来说明一下软引用的回收机制。首先设置JVM参数：-Xms20m
-Xmx20m，即只有20MB的堆内存空间。在下方的示例代码中不断地往集合里添加
House对象，而每个House有2000个Door成员变量，狭小的堆空间加上大对象的产
生，就是为了尽快触达内存耗尽的临界状态：
```java
public class SoftReferenceHouse {
    public static void main(String[] args) {
        // List<House> houses = new ArrayList<House>();    (第1处)
        List<SoftReference> houses = new ArrayList<SoftReference>();
        
        // 剧情反转注释处
        int i = 0;
        while (true) {
            // houses.add(new House());    (第2处)
            // 剧情反转注释处
            SoftReference<House> buyer2
                = new SoftReference<House>(new House());
            // 剧情反转注释处
            houses.add(buyer2);
            
            System.out.println("i=" + (++i));
        }
    }
}

class House {
    private static final Integer DOOR_NUMBER = 2000;
    public Door[] doors = new Door[DOOR_NUMBER];
    
    class Door { }
}
```
new House()是匿名对象，产生之后即赋值给软引用。正常运行一段时间后，内
存到达耗尽的临界状态，House$Door超过10MB左右，内存占比达到80.4%，如图7-7
所示

软引用的特性在数秒之后产生价值，House对象数从千数量级迅速降到百数量级，
内存容量迅速被释放出来，保证了程序的正常运行，如图7-8所示

软引用SoftReference的父类Reference的属性：private T referent，它指向new
House()对象，而SoftReference的get()，也是调用了super.get()来访问父类这个私有
属性。大量的House在内存即将耗尽前，成功地一次又一次被清理掉。对象buyer2
虽然是引用类型，但其本身还是占用一定内存空间的，它是被集合ArrayList强引用
劫持的。在不断循环执行houses.add()后，在i=360035时，终于产生了OOM。软引用、
弱引用、虚引用均存在带有队列的构造方法：
```java
public SoftReference(T referent, ReferenceQueue<? super T> q) {...}
```
可以在队列中检查哪个软引用的对象被回收了，从而把失去House的软引用对
象清理掉

反转一下剧情。在同一个类中，使用完全相同的运行环境和内存参数，把
SoftReference\<House\>中被注释掉的两句代码激活(即示例代码中的第1处和第2处)，
同时把在后边标记了“ 剧情反转注释处”的3句代码注释掉，再次运行。观察一下，
在没有软引用的情况下，这个循环能够撑多久?运行得到的结果在i=2404时，就产
生OOM异常。这个示例简单地证明了软引用在内存紧张情况下的回收能力。软引用
一般用于在同一服务器内缓存中间结果。如果命中缓存，则提取缓存结果，否则重新
计算或获取。但是，软引用肯定不是用来缓存高频数据的，万一服务器重启或者软引
用触发大规模回收，所有的访问将直接指向数据库，导致数据库的压力时大时小，甚
至崩溃

如果内存没有达到OOM，软引用持有的对象会被回收吗?下面用代码来验证一下：
```java
public class SoftReferenceWhenIdle {
    public static void main (String[] args) {
        House seller = new House();
        // (第1处)
        SoftReference<House> buyer2 = new SoftReference<House>(seller);
        seller = null;
        
        while (true) {
            // 下方两句代码建议JVM进行垃圾回收
            System.gc();
            System.runFinalization();
            
            if (buyer2.get() == null) {
                System.out.println("house is null.");
                break;
            } else {
                System.out.println("still there.");
            }
        }
    }
}
```
System.gc()方法建议垃圾收集器尽快进行垃圾收集，具体何时执行仍由JVM来
判断。System.runFinalization()方法的作用是强制调用已经失去引用对象的finalize()

在代码中同时调用这两者，有利于更快地执行垃圾回收。在相同的运行环境下，
一直输出still there，说明buyer2一直持有new House()的有效引用。如果在对方置为
null时仍能自动感知，并且主动断开引用指向的对象，这是哪种引用方式可以担负的
使命?答案是弱引用。事实上，把示例代码中第1处的两个红色SoftReference修改
为WeakReference即可实现回收。出于对WeakReference的尊重，摒弃刚才催促垃圾
回收的代码，让WeakReference自然地被YGC回收，使对象能够存活更长的时间。
我们可以在JVM启动参数加-XX:+PrintGCDetails(或高版本JDK使用-Xlog:gc)来
观察GC的触发情况：
```java
public class WeakReferenceWhenIdle {
    public static void main(String[] args) {
        House seller = new House();
        WeakReference<House> buyer3 = new WeakReference<House>(seller);
        seller = null;
        
        long start = System.nanoTime();
        int count = 0;
        while (true) {
            if (buyer3.get() == null) {
                long duration = (System.nanoTime() - start) / (1000 * 1000);
                System.out.println("house is null and exited time = "
                    + duration + "ms");
                break;
            } else {
                System.out.println("still there. count = " + (count++));
            }
        }
    }
}
```
执行结果如下：
```text
still there. count = 232639
[GC [PSYoungGen: 65536K->688K(76288K)] 65536K->696K(251392K), 0.0074719 secs]
[Times: user=0.01 sys=0.00, real=0.01 secs]
still there. count = 232640
house is null and exited time = 101 3ms
```
这个示例代码在YGC下，可以轻松地回收WeakReference指向的new House()对
象。WeakReference典型的应用是在WeakHashMap中。在刚才的房源案例中，卖家
的房子对应一系列的房源资料，如果卖家的房源已经售出，则中介也不需要一直保存
相关信息，自动回收存储空间即可，如下方示例代码：

```java
public class WeakHashMapTest {
    public static void main(String[] args) {
        House seller1 = new House("1号卖家房源");
        SellerInfo sellerInfo1 = new SellerInfo();
        
        House seller2 = new House("2号卖家房源");
        SellerInfo sellerInfo2 = new SellerInfo();
        
        // 如果换成HashMap，则Key是对House对象的强引用    (第1处)
        WeakHashMap<House, SellerInfo> weakHashMap
            = new WeakHashMap<House, SellerInfo>();
        
        weakHashMap.put(seller1, sellerInfo1);
        weakHashMap.put(seller2, sellerInfo2);
        
        System.out.println("weakHashMap before null, size= "
            + weakHashMap.size());
        
        seller1 = null;
        
        System.gc();
        System.runFinalization();
        
        // 如果换成HashMap，size依然等于2    (第2处)
        System.out.println("weakHashMap after null, size = "
            + weakHashMap.size());
        System.out.println(weakHashMap);
    }
}
```
执行结果如下：
```text
weakHashMap before null, size = 2
weakHashMap after null, size = 1
{2号卖家房源=com.alibaba.easy.coding.reference.SellerInfo@326de728}
```
说明一下第1处和第2处。如果是HashMap，Key就是强引用指向House对象，
即使seller1=null，也并不影响HashMap这个Key被置为null。如果是HashMap，
则最后的size依然等于2，而WeakHashMap就是1，回收seller1指向的引用。因而
WeakHashMap适用于缓存不敏感的临时信息的场景。例如，用户登录系统后的浏览
路径在关闭浏览器后可以自动清空

WeakReference这种特性也用在了ThreadLocal上。JDK中的设计原意是在
ThreadLocal对象消失后，线程对象再持有这个ThreadLocal对象是没有任何意义的，
应该进行回收，从而避免内存泄漏。这种设计的出发点很好，但在实际业务场景中却
并非如此，弱引用的设计方式反而增加了对ThreadLocal和Thread体系的理解难度

除强引用外，其他三种引用可以减少对象在生命周期中所占用的内存大小。如果
控制得当，垃圾回收就能够随意地释放这些对象。如果使用了这些引用，就应该像示
例中的seller一样，为避免强引用劫持，把强引用置为null，否则这三种引用就无法
发挥它们的价值。这三者的使用成本是偏大的，开发工程师应该多去考虑如何不造成
内存泄漏，如何提升性能，使方法快速执行完成后形成自然回收。如果这些引用在程
序中使用不当，就会造成更大的风险

###### 7.5.2 ThreadLocal价值
我们从真人CS游戏说起。游戏开始时，每个人能够领到一把电子枪，枪把上有
三个数字：子弹数、杀敌数、自己的命数，为其设置的初始值分别为1500、0、10。
假设战场上的每个人都是一个线程，那么这三个初始值写在哪里呢?如果每个线程
写死这三个值，万一将初始子弹数统一改成1000发呢?如果共享，那么线程之间的
并发修改会导致数据不准确。能不能构造这样一个对象， 将这个对象设置为共享变
量，统一设置初始值，但是每个线程对这个值的修改都是互相独立的。这个对象就是
ThreadLocal。注意不能将其翻译为线程本地化或本地线程，英语恰当的名称应该叫作：
CopyValueIntoEveryThread。具体示例代码如下：
```java

```




###### 7.5.3 ThreadLocal副作用






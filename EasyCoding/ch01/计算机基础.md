#### 第1章 计算机基础
追根究底是深度分析和解决问题、提升程序员素质的关键所在，有助于编写高质
的代码。基础知识的深度认知决定着知识上层建筑的延展性。试问对于如下的基
础知识，你的认知是否足够清晰呢？

- 位移运算可以快速地实现乘除运算，那位移时要注意什么？

- 浮点数的存储与计算为什么总会产生微小的误差？

- 乱码产生的根源是什么？

- 代码执行时，CPU是如何与内存配合完成程序使命的？

- 网络连接资源耗尽的问题本质是什么？

- 黑客攻击的通常套路是什么？如何有效地防止？

本章从编程的角度深度探讨计算机组成原理、计算机网络、信息安全等相关内容，
与具体编程语言无关。本章将不会讨论内部硬件的工作原理、网络世界的协议和底层
传输方式、 安全领域的攻防类型等内容

##### 1.1 走进0与1的世界
简单地说，计算机就是晶体管、电路板组装起来的电子设备，无论是图形图像的
渲染、网络远程共享，还是大数据计算， 归根结底都是0与1的信号处理。信息存储
和逻辑计算的元数据，只能是0与1，但是它们在不同介质里的物理表现方式却是不
一样的，如三极管的断电与通电、CPU的低电平与高电平、磁盘的电荷左右方向。
明确了0与1的物理表现方式后，设定基数为 2，进位规则是“逢二进一”，借位规
则是“借一当二”，所以称为二进制。那么如何表示日常生活中的十进制数值呢？二
进制数位从右往左， 每一位都是乘以 2，如下示例为二进制数与十进制数的对应关系，
阴影部分的数字为二进制数：

1=1, 10=2, 100=4, 1000=8, 11000=24, 即 2^0=1; 2^1=2; 2^2=4; 2^3=8; 2^4+2^3=24

设想有8条电路，每条电路有低电平和高电平两种状态。根据数学排列组合，有
8个2相乘，即2^8能够表示256种不同的信号。假设表示区间为 0～255，最大数
即为 2^8-1，那么 32 条电路能够表示的最大数为（2^32-1）=4,294 ,967,295 。 平时所说
的32位机器，就能够同时处理字长为 32 位的电路信号

如何表示负数呢？上面的8条电路，最左侧的条表示正负，0表示正数，1表
示负数，不参与数值表示。8条电路的最大值为01111111即127，表示范围因有正负 
之分而改变为-128 ～127，二进制整数最终都是以补码形式出现的。正数的补码与
原码、反码是一样的，而负数的补码是反码加1的结果。这样使减法运算可以使用加
法器实现，符号位也参与运算。比如 35 + (-35） 如图 1-1 ( a） 所示，35 -37 如图 1-1 ( b )
所示

加减法是高频运算，使用同一个运算器，可以减少中间变量存储的开销， 这样也
降低了CPU内部的设计复杂度，使内部结构更加精简，计算更加高效，无论对于指令、
寄存器，还是运算器都会减轻很大的负担

如图 1-1 ( c） 所示， 计算结果需要9条电路来表示，用8条电路来表达这个计算
结果即溢出，即在数值运算过程中，超出规定的表示范围。一旦溢出，计算结果就是
错误的。在各种编程语言中，均规定了不同数字类型的表示范围，有相应的最大值和
最小值

以上示例中的一条电路线在计算机中被称为1位，即1个bit，简写为b。8个
bit组成一个单位，称为一个字节，即1个 Byte，简写为B 。1024个Byte，简写为
KB，1024个KB，简写为MB；1024个MB，简写为GB，这些都是计算机中常用的
存储计量单位

除二进制的加减法外，还有一种大家既陌生又熟悉的操作：位移运算。陌生是指
不易理解且不常用，熟悉是指 “ 别人家的开发工程师 ” 在代码中经常使用这种方式进
行高低位的截取、哈希计算，甚至运用在乘除法运算中。向右移动1位近似表示除以
2（如表 1-1 所示），十进制的奇数转化为二进制数后，在向右移时，最右边的1将
被直接抹去，说明向右移对于奇数并非完全相当于除以2。在左移<<与右移>>两种
运算中，符号位均参与移动，除负数往右移动，高位补1之外，其他情况均在空位处 
补0，红色是原有数据的符号位，绿色仅是标记，便于识别移动方向

左移运算由于符号位参与向左移动，在移动后的结果中，最左位可能是1或者0,
即正数向左移动的结果可能是正，也可能是负，负数向左移动的结果同样可能是正，
也可能是负

对于三个大于号的>>> 无符号向右移动（注意不存在<<<无符号向左移动的运
算方式），当向右移动时，正负数高位均补 0，正数不断向右移动的最小值是 0，而
负数不断向右移动的最小值是 1 。无符号意即藐视符号位，符号位失去特权，必须像
其他平常的数字位一起向右移动，高位直接补0，根本不关心是正数还是负数。此运
算常用在高位转低位的场景中，如表 1-2 所示分别表示向右移动1～3位的结果，左
侧空位均补0

为何负数不断地无符号向右移动的最小值是1呢？在实际编程中，位移运算仅作
用于整型 （32 位）和长整型 （64 位）数上， 假如在整型数上移动的位数是 32 位，无
论是否带符号位以及移动方向，均为本身。因为移动的位数是个mod 32 的结果，
即 35>>1与35>>33 是一样的结果。如果是长整型，mod 64，即 35<<1 与 35<<65 的
结果是一样的。负数在无符号往右移动 63 位时，除最右边为1外，左边均为 0，达
到最小值 1，如果>>>64，则为其原数值本身

位运算的其他操作比较好理解，包括按位取反（符号为～）、按位与（符号为 ＆） 、
按位或（符号为|）、按位异或（符号为^）等运算。其中 ， 按位与（＆）运算典型的
场景是获取网段值， IP 地址与掩码 255.255.255.0 进行按位与运算得到高 24 位，即为
当前 IP 的网段。按位运算的左右两边都是整型数，true&false 这样的方式也是合法的，
因为 boolean 底层表示也是 0 与 1

按位与和逻辑与（符号为＆＆）运算都可以作用于条件表达式，但是后者有短路
功能 ，表达如下所示：
```java
boolean a = true;
boolean b = true;
boolean c = (a=(1==2)) && (b=(1==2));
```
因为＆＆前边的条件表达式，即如上的红色代码部分的结果为false，触发短路，
直接退出，最后 a 的值为 false，b 的值为 true。假如把＆＆修改为按位与＆，则执行
的结果为 a 与 b 都是 false

同样的逻辑，按位或对应的逻辑或运算（符号为||）也具有短路功能，当逻辑或
||之前的条件表达式 ，即如下的红色代码部分的结果为true时，直接退出：

```java
boolean e = false;
boolean f = false;
boolean g = (e=(1==1)) || (f=(1==1));
```
最后 e 的值为 true，f 的值为 false。假如把||修改为按位或符号| ，执行的结果为
e 与 f 都是true

逻辑或、逻辑与运算只能对布尔类型的条件表达式进行运算， 7&&8 这种运算表
达式是错误的

异或运算没有短路功能，符号在键盘的数字 6 上方，在哈希算法中用于离散
哈希值 ， 对应的位上不一样才是 1，一样的都是 0。比如，1^1=0 / 0^0=0 / 1^0=1 / 
true^true=false / true/\ false=true

基于 0 与1的信号处理为我们带来了缤纷多彩的计算机世界，随着基础材料和信
号处理技术的发展，未来计算机能够处理的基础信号将不仅仅是二进制信息。比如，
三进制（高电平、低电平、断电），甚至十进制信息，届时计算机世界又会迎来一次
全新的变革

##### 1.2 浮点数
计算机定义了两种小数，分别为定点数和浮点数。其中，定点数的小数点位置是
固定的，在确定字长的系统中一旦指定小数点的位置后，它的整数部分和小数部分也
随之确定。二者之间独立表示，互不干扰。由于小数点位置是固定的，所以定点数能
够表示的范围非常有限。考虑到定点数相对简单，本节不再展开。下面重点介绍应用
更广、更加复杂的浮点数。它是采用科学计数法来表示的，由符号位、有效数字、指
数三部分组成。使用浮点数存储和计算的场景无处不在，若使用不当则容易造成计算
值与理论值不一致，如下示例代码:
```java
float a = 1f;
float b = 0.9f;
// 结果为:0.100000024
float f = a - b;
```
执行结果显示计算结果与预期存在明显的误差，本节将通过深入剖析造成这个误
差的原因来介绍浮点数的构成与计算原理。由于浮点数是以科学计数法来表示的，所
以我们先从科学计数法讲起

###### 1.2.1 科学计数法
浮点数是计算机用来表示小数的一种数据类型。在数学中，采用科学计数法来近
似表示一个极大或极小且位数较多的数。如a X 10^n，其中a满足1 ≤ |a| < 10，10^n
是以10为底数，n为指数的幂运算表达式。a X 10^n还可以表示成aen，如图1-2(a)中计算
器的结果所示。-4.86e11等价于-4.86 X 10^11，它们都表示真实值-4800000000，
具体格式说明如图1-2 (b)所示

科学计数法的有效数字为从第1个非零数字开始的全部数字，指数决定小数点的
位置，符号表示该数的正与负。值得注意的是，十进制科学计数法要求有效数字的整
数部分必须在[1,9]区间内，即图1-2(b)中的“4”，满足这个要求的表示形式被称
为“规格化”。科学计数法可以唯一地表示任何一 个数，且所占用的存储空间会更少，
计算机就是利用这一特性表示极大或极小的数值。例如，长整型能表示的最大值约为
922亿亿，想要表示更大量级的数值，必须使用浮点数才可以做到

###### 1.2.2 浮点数表示
浮点数表示就是如何用二进制数表示符号、指数和有效数字。当前业界流行的浮
点数标准是IEEE754，该标准规定了4种浮点数类型：单精度、双精度、延伸单精度、
延伸双精度。前两种类型是最常用的，它们的取值范围如表1-3 所示

因为浮点数无法表示零值，所以取值范围分为两个区间：正数区间和负数区间。
下面将着重分析单精度浮点数，而双精度浮点数与其相比只是位数不同而已，完全可
以触类旁通，本节不再展开。以单精度类型为例，它被分配了4个字节，总共32位，
具体格式如图1-3所示

从数学世界的科学计数法映射到计算机世界的浮点数时，数制从十进制改为二进
制，还要考虑内存硬件设备的实现方式。在规格化表示上存在差异，称谓有所改变，
指数称为“阶码”，有效数字称为“尾数”，所以用于存储符号、阶码、尾数的二进
制位分别称为符号位、阶码位、尾数位，下面详细阐述三个部分的编码格式

1. 符号位
在最高二进制位.上分配1位表示浮点数的符号，0表示正数，1表示负数

2. 阶码位
在符号位右侧分配8位用来存储指数，IEEB754 标准规定阶码位存储的是指数对
应的移码，而不是指数的原码或补码。根据计算机组成原理中对移码的定义可知，移
码是将一个真值在数轴上正向平移一个偏移量之后得到的，即[x]<sub>移</sub>=x+2^n-1(n为x
的二进制位数，含符号位)。移码的几何意义是把真值映射到一个正数域，其特点是
可以直观地反映两个真值的大小，即移码大的真值也大。基于这个特点，对计算机来
说用移码比较两个真值的大小非常简单，只要高位对齐后逐个比较即可，不用考虑负
号的问题，这也是阶码会采用移码表示的原因所在

由于阶码实际存储的是指数的移码，所以指数与阶码之间的换算关系就是指数与
它的移码之间的换算关系。假设指数的真值为e，阶码为E，则有E=e+(2^n-1-1),其
中2^n-1-1是IEEE754标准规定的偏移量，n=8 是阶码的二进制位数

为什么偏移值为2^n-1-1而不是2^n-1呢?因为8个二进制位能表示指数的取值范
围为[-128,127]，现在将指数变成移码表示，即将区间[-128,127]正向平移到正数域，
区间里的每个数都需要加上128，从而得到阶码范围为[0,255]。 由于计算机规定阶码
全为0或全为1两种情况被当作特殊值处理(全0被认为是机器零，全1被认为是无
穷大)，去除这两个特殊值，阶码的取值范围变成了[1,254]。 如果偏移量不变仍为
128的话，则根据换算关系公式[x]<sub>阶</sub>=x+128得到指数的范围变成[-127,126],指
数最大只能取到126，显然会缩小浮点数能表示的取值范围。所以IEEE754标准规定
单精度的阶码偏移量为2^n-1-1 (即127)，这样能表示的指数范围为[-126,127]，
指数最大值能取到127

3. 尾数位

最右侧分配连续的23位用来存储有效数字，IEEE754标准规定尾数以原码表
示。正指数和有效数字的最大值决定了32位存储空间能够表示浮点数的十进制最
大值。指数最大值为2^127≈1.7 X 10^38，而有效数字部分最大值是二进制的1.11…1
(小数点后23个1)，是一个无限接近于2的数字，所以得到最大的十进制数为
2 X 1.7 X 10^38，再加上最左1位的符号，最终得到32位浮点数最大值为3.4e+38。
为了方便阅读，从右向左每4位用短横线断开:
<font color='red'>0</font> <font color='green'>111-1111-0</font> <font color='orange'>111-1111-1111-1111-1111-1111</font>  

- 红色部分为符号位，值为0，表示正数
- 绿色部分为阶码位即指数，值为2^(254-127)=2^127≈1.7 x 10^38
- 黄色部分为尾数位即有效数字，值为1.111111111111111

科学计数法进行规格化的目的是保证浮点数表示的唯一性。 如同十进制规格化的
要求1≤|a|<10，二进制数值规格化后的尾数形式为1.xyz, 满足1≤|a|<2。为了
节约存储空间，将符合规格化尾数的首个1省略，所以尾数表面上是23位，却表示
了24位二进制数，如图1-4所示

常用浮点数的规格化表示如表 1 -4 所示

###### 1.2.3 加减运算
在数学中，进行两个小数的加减运算时，首先要将小数点对齐，然后同位数进行
加减运算。对两个采用科学计数法表示的数做加减法运算时，为了让小数点对齐就需
要确保指数一样。当小数点对齐后，再将有效数字按照正常的数进行加减运算

(1)零值检测。检查参加运算的两个数中是否存在为0的数(0在浮点数是一
种规定，即阶码与尾数全为0)，因为浮点数运算过程比较复杂，如果其中一个数为0,
可以直接得出结果

(2)对阶操作。通过比较阶码的大小判断小数点位置是否对齐。当阶码不相等
时表示当前两个浮点数的小数点位置没有对齐，则需要通过移动尾数改变阶码的大小，
使二者最终相等，这个过程便称为对阶。尾数向右移动1位，则阶码值加1，反之减1。
在移动尾数时，部分二进制位将会被移出，但向左移会使高位被移出，对结果造成的
误差更大。所以，IEEE754 规定对阶的移动方向为向右移动，即选择阶码小的数进行
操作

(3)尾数求和。当对阶完成后，直接按位相加即可完成求和(如果是负数则需
要先转换成补码再进行运算)。这个道理与十进制数加法相同，例如9.8 X 10^38与
6.5 X 10^37进行求和，将指数小的进行升阶，即6.5 X 1037变成0.65 X 10^38， 然后求
和得到结果为10.45 x 10^38

(4)结果规格化。如果运算的结果仍然满足规格化形式，则无须处理，否则需
要通过尾数位的向左或右移动调整达到规格化形式。尾数位向右移动称为右规，反之
称为左规。如上面计算结果为10.45 X 10^38， 右规操作后为1.045 X 10^39

(5)结果舍入。在对阶过程或右规时，尾数需要右移，最右端被移出的位会
被丢弃，从而导致结果精度的损失。为了减少这种精度的损失，先将移出的这部分数
据保存起来，称为保护位，等到规格化后再根据保护位进行舍入处理

了解了浮点数的加减运算过程后可以发现，阶码在加减运算过程中只是用来比较
大小，从而决定是否需要进行对阶操作。所以，IEEE754 标准针对这一特性， 将阶码
采用移码表示，目的就是利用移码的特点来简化两个数的比较操作。下面针对前面例
子从对阶、按位减法的角度分析为什么1.0-0.9 结果为0.00000024,而不是理论值0.1。
1.0-0.9等价于1.0+(-0.9)，首先分析1.0与-0.9的二进制编码:

1.0的二进制为0011-1111-1000-0000-0000-0000000-0000

-0.9的二进制为1011-1111-01 10-0110-0110-01 10-0110-0110

从上可以得出二者的符号、阶码、尾数三部分数据，如表1-5所示

由于尾数位的最左端存在一个隐藏位，所以实际尾数二进制分别为： 1000-0000-
0000-0000-0000-0000和1110-0110-0110-0110-0110-0110，红色为隐藏位。下面运算都
是基于实际的尾数位进行的，具体过程如下：

(1)对阶。1.0的阶码为127， -0.9的阶码为126， 比较阶码大小后需要向右移
动-0.9尾数的补码，使其阶码变为127，同时高位需要补1,移动后的结果为1000-
1100-1100-1100-1100-1101，最左的1是高位补进的。注意，绿色只是为了方便与表格
右下方的数字进行对比

(2)尾数求和。因为尾数都转换成补码，所以可以直接按位相加，注意符号位
也要参与运算，如图1-5所示

其中最左端为符号位，计算结果为0，尾数位计算结果为0000-1100-1100-1100-
1100-1101

(3)规格化。上一步计算的结果并不符合要求，尾数的最高位必须是1，所
以需要将结果向左移动4位，同时阶码需要减4。移动后阶码等于123 (二进制为
1111011)，尾数为1100-1100-1100-1100-1101-0000。 再隐藏尾数的最高位，进而变为
100-1100-1100-1100-1101-0000

综上所述，得出运算后结果的符号为0、阶码为1111011、尾数为100-1100-1100-
1100-1101-0000，三部分组合起来就是1.0-0.9 的结果，对应的十进制值为0.100000024。
至此，在本节开始处的减法悬案真相大白

###### 1.2.4 浮点数使用
在使用浮点数时推荐使用双精度，使用单精度由于表示区间的限制，计算结果会
出现微小的误差，实例代码如下所示：
```java
float ff = 0.9f;
double dd = 0.9d;
// 0.8999999761581421
System.out.println(ff/1.0);
// 0.9
System.out.println(dd/1.0);
```
在要求绝对精确表示的业务场景下，比如金融行业的货币表示，推荐使用整型存
储其最小单位的值，展示时可以转换成该货币的常用单位，比如人民币使用分存储，
美元使用美分存储。在要求精确表示小数点n位的业务场景下，比如圆周率要求存储
小数点后1000位数字，使用单精度和双精度浮点数类型保存是难以做到的，这时推
荐采用数组保存小数部分的数据。在比较浮点数时，由于存在误差，往往会出现意料
之外的结果，所以禁止通过判断两个浮点数是否相等来控制某些业务流程。在数据库
中保存小数时，推荐使用decimal类型，禁止使用float类型和double类型。因为这
两种类型在存储的时候，存在精度损失的问题

综上所述，在要求绝对精度表示的业务场景中，在小数保存、计算、转型过程中
都需要谨慎对待

##### 1.3 字符集与乱码
理解0和1的物理信号来源及数值表示方式后，如何将0和1表示成我们看到的
文字呢?从26个英文字母说起，大小写共52个，加上10个数字达到62个，考虑到
还有特殊字符(如：! @ # $ % ^ & * { } | 等）和不可见的控制字符，必然超过64个，
这又该如何表示呢?注意这里特别提到了“64” ，因为它的特殊性，即2的6次方。
使用刚才的0与1组合，至少是7组连续的信号量。计算机在诞生之初对于存储和传
输介质实在没有什么信心，所以预留了一个bit(位)用于奇偶校验,这就是1个Byte(字
节)由8个bit组成的来历，也就是ASCII码。

在ASCII码中，有两个特殊的控制字符10和13，前者是LF即“\n”，后者是
CR即“\r”,在编码过程中，代码的换行虽然是默认不可见的，但在不同的操作系统中，
表示方式是不一样的。在UNIX系统中，换行使用换行符“\n” ;在Windows系统中，
换行使用“\r\n” ;在旧版macOS中，换行使用回车符“\r” ，在新版macOS中使用
与UNIX系统相同的换行方式。如图1-6所示，当前编码环境使用换行方式是LF,
这也是推荐的换行方式，避免出现源码在不同操作系统中换行显示不同的情况

再说汉字的字符集表示，首先汉字的个数远远超过英文字符的个数。毕竟ASCII
码先入为主，必须在它基础上继续编码，也必须想办法和它兼容。一个字节只能表示
128个字符，所以采用双字节进行编码。早期使用的标准GB2312收录了6763个常用
汉字。而GBK (K是拼音kuo的首字母，是扩展的意思)支持繁体，兼容GB2312。
而后来的GB18030是国家标准，在技术上是GBK的超集并与之兼容。1994 年正式
公布的Unicode，为每种语言中的每个字符都设定了唯一编码， 以满足跨语言的交流，
分为编码方式和实现方式。实现Unicode的编码格式有三种: UTF-8、 UTF-16、 UTF-
32，UTF ( Unicode Transformation Format)即Unicode字符集转换格式，可以理解为
对Unicode的压缩方式。根据二八原则，常用文字只占文字总数的20%左右。其中，
UTF-8是一种以字节为单位，针对Unicode的可变长度字符编码，用1 ~ 6个字节对
Unicode字符进行编码压缩，目的是用较少的字节表示最常用的字符。此规则能有效
地降低数据存储和传输成本

在日常开发中，字符集如果不兼容则会造成乱码。淘宝以前的系统都是GBK编码，
而国际站使用的是UTF-8，在互相查看源码时，使用UTF-8的IDE环境打开GBK源
码，中文注释基本上都是不可读的乱码。乱码的出现场景并不止于编码环境中，还有
网页展示、文本转换、文件读取等。数据流从底层数据库到应用层，到Web服务器，
再到客户端显示，每位开发工程师都会碰到字符乱码的问题，排查起来是一个比较长
的链路。数据库是存储字符之源，在不同层次上都能够设置独立的字符集，如服务器
级别、schema级别、表级别甚至列级别。为了减少麻烦，所有情况下的字符集设置
最好是一致的

##### 1.4 CPU与内存
CPU ( Central Processing Unit )是一块超大规模的集成电路板，是计算机的核心
部件，承载着计算机的主要运算和控制功能，是计算机指令的最终解释模块和执行模
块。硬件包括基板、核心、针脚，基板用来固定核心和针脚，针脚通过基板上的基座
连接电路信号，CPU核心的工艺极度精密，达到10纳米级别

和其他硬件设备相比，在实际代码的运行环境中，CPU与内存是密切相关的两
个硬件设备，本节对CPU和内存简单介绍一下。开发工程师在实际编程中，对这两
个部件有一定的掌控性，熟悉CPU和内存的脾气，让它们以自己期望的方式执行相
关指令。在CPU的世界里，没有缤纷多彩的图像、悦耳动听的音乐，只有日复一日
地对0与1电流信号的处理。但CPU内部的处理机制是十分精密而复杂的，总的来说，
就是由控制器和运算器组成的，内部寄存器使这两者协同更加高效。CPU的内部结
构如图1-7所示

1. 控制器
控制器由图1-7中所示的控制单元、指令译码器、指令寄存器组成。其中控制单
元是CPU的大脑，由时序控制和指令控制等组成；指令译码器是在控制单元的协调
下完成指令读取、分析并交由运算器执行等操作；指令寄存器是存储指令集，当前流
行的指令集包括X86、SSE、 MMX等。控制器有点像一个编程语言的编译器，输入
0与1的源码流，通过译码和控制单元对存储设备的数据进行读取，运算完成后，保
存回寄存器，甚至是内存

2. 运算器
运算器的核心是算术逻辑运算单元，即ALU，能够执行算术运算或逻辑运算等
各种命令，运算单元会从寄存器中提取或存储数据。相对控制单元来说，运算器是受
控的执行部件。任何编程语言诸如a+b的算术运算，无论字节码指令，还是汇编指令，
最后一定会以0与1的组合流方式在部件内完成最终计算，并保存到寄存器，最后送
出CPU。平时理解的栈与堆，在CPU眼里都是内存

3. 寄存器
最著名的寄存器是CPU的高速缓存L1、L2，缓存容量是在组装计算机时必问的
两个CPU性能问题之一。缓存结构和大小对CPU的运行速度影响非常大，毕竟CPU
的运行速度远大于内存的读写速度，更远大于硬盘。基于执行指令和热点数据的时间
局部性和空间局部性，CPU 缓存部分指令和数据，以提升性能。但由于CPU内部空
间狭小且结构复杂，高速缓存远小于内存空间。

CPU是一个高内聚的模块化组件，它对外部其他硬件设备的时序协调、指令控制、
存取动作，都需要通过操作系统进行统一管理和协调。所谓的CPU时间片切分，并
非CPU内部能够控制与管理。CPU部件是一个任劳任怨的好公民代表，只要有指令
就会马不停蹄地执行，高级语言提供的多线程技术和并发更多地依赖于操作系统的调
配，并行更多依赖于CPU多核技术。多核CPU即在同一块基板上封装了多个Core。
还有一种提升CPU性能的方式是超线程，即在一个Core上执行多个线程，如图1-8
所示为2个Core，但是有4个逻辑CPU，并有对应独立的性能监控数据。

CPU与内存的执行速度存在巨大的鸿沟，如图1-8所示的L2和L3分别是
256KB和4MB，它们是CPU和内存之间的缓冲区，但并非所有的处理器都有L3缓存

曾几何时，内存就是系统资源的代名词，它是其他硬件设备与CPU沟通的桥梁，
计算机中的所有程序都在内存中运行，它的容量与性能如果存在瓶颈，即使CPU再快，
也是枉然。内存物理结构由内存芯片、电路板、控制芯片、相关支持模块等组成，内
存芯片结构比较简单，核心是存储单元，支持模块是地址译码器和读写控制器，如图
1-9所示

从图1-9中可以看出，越往CPU核心靠近，存储越贵，速度越快。越往下，存
储越便宜、速度越慢，当然容量也会更大。云端存储使得应用程序无须关心是分布式
还是集中式，数据如何备份和容灾。在本地磁盘与CPU内部的缓存之间，内存是一
个非常关键的角色，但它很敏感，内存颗粒如果有问题无法存储，或控制模块出现地
址解析问题，或内存空间被占满，都会导致无法正常地执行其他应用程序，甚至是操
作系统程序。程序员们最害怕的OOM通常来源于由于不恰当的编码方式而导致内存
的资源耗尽，虽然现代内存的容量已经今非昔比，但仍然是可以在秒级内耗尽所有内
存资源的

图1-9中的存储单元都有一个十六进制的编号，在32位机器上是0x开始的8位
数字编号，就是内存存储单元的地址，相当于门牌号。以C和C++为代表的编程语
言可以直接操作内存地址，进行分配和释放。举个例子，要写一份数据到存储单元中，
就像快递一个包裹，需要到付并且当面签收，到了对应的住址，发现收件人不在，就
抛出异常。如图1-10所示的经典错误，估计很多人都遇到过，选择要调试程序，单击【取
消】按钮，并无反应，也不会出现调试界面。内存的抽象就是线性空间内的字节数组，
通过下标访问某个特定位置的数据，比如C语言使用malloc()进行内存的分配，然后
使用指针进行内存的读与写

而以Java为代表的编程语言，内存就交给JVM进行自动分配与释放，这个过程
称为垃圾回收机制。这就好像刚才的快递员并不直接访问内存单元，只是把包裹放在
叫JVM的老大爷家里。付出的代价是到货速度慢了，影响客户体验。毕竟老大爷并
不是实时立马转交的，而是要攒到一定的包裹量再挨家挨户地给收件人送过去。虽然
垃圾回收机制能为程序员减负，但如果不加节制的话，同样会耗尽内存资源

##### 1.5 TCP/IP
###### 1.5.1 网络协议
在计算机诞生后，从单机模式应用发展到将多台计算机连接起来，形成计算机网
络，使信息共享、多机协作、大规模计算等成为现实，历经了20多年的时间。计算
机网络需要解决的第一个问题是如何无障碍地发送和接收数据。而这个发送和接收数
据的过程需要相应的协议来支撑，按互相可以理解的方式进行数据的打包与解包，使
不同厂商的设备在不同类型的操作系统上实现顺畅的网络通信

TCP/IP ( Transmission Control Protocol / Internet Protocol) 中文译为传输控制协
议/因特网互联协议，这个大家族里的其他知名协议还有HTTP、HTTPS、 FTP、
SMTP、UDP、ARP、PP、IEEE 802.x等。TCP/IP是当前流行的网络传输协议框架，
从严格意义上讲它是一个协议族，因为TCP、IP 是其中最为核心的协议，所以就把
该协议族称为TCP/IP。而另一个是耳熟能详的ISO/OSI的七层传输协议，其中OSI
( Open System Interconnection)的出发点是想设计出计算机世界通用的网络通信基本
框架，它已经被淘汰，本节略过

TCP/IP是在不断解决实际问题中成长起来的协议族，是经过市场检验的事实标
准，已经很难被取代。就像即使键盘的布局不那么合理，比如字母A被设计在左手
小指位置，不利于敲击，但原来的键盘布局已经成为群体习惯的事实标准。TCP分层
框架图如图1-11所示，为了表示网络拓扑图在连接层面上的机器对等理念，故图1-11 
中采用A机器和B机器的说法，而不是服务器和客户端的说法

- 链路层：单个0、1是没有意义的，链路层以字节为单位把0与1进行分组，
定义数据帧，写入源和目标机器的物理地址、数据、校验位来传输数据。图1-12
所示是以太网的帧协议。

MAC地址长6个字节共48位，通常使用十六进制数表示。使用ifconfig -a命令
即可看到MAC地址。如图1-13 所示的f4:5c:89， 即前24位由管理机构统一分配，
后24位由厂商自己分配，保证网卡全球唯一。 网卡就像家庭地址一样，是计算机世
界范围内的唯一标识

- 网络层：根据IP定义网络地址，区分网段。子网内根据地址解析协议( ARP )
进行MAC寻址，子网外进行路由转发数据包，这个数据包即IP数据包

- 传输层：数据包通过网络层发送到目标计算机后，应用程序在传输层定义逻
辑端口，确认身份后，将数据包交给应用程序，实现端口到端口间通信。最
典型的传输层协议是UDP和TCP。UDP只是在IP数据包上增加端口等部分
信息，是面向无连接的，是不可靠传输，多用于视频通信、电话会议等(即
使少一帧数据也无妨)。与之相反，TCP是面向连接的。所谓面向连接，是
一种端到端间通过失败重传机制建立的可靠数据传输方式，给人感觉是有一
条固定的通路承载着数据的可靠传输

- 应用层：传输层的数据到达应用程序时，以某种统一规定的协议格式解读数
据。比如，E-mail 在各个公司的程序界面、操作、管理方式都不一样，但是
都能够读取邮件内容，是因为SMTP协议就像传统的书信格式一样，按规定
填写邮编及收信人信息

总结一下，程序在发送消息时，应用层按既定的协议打包数据，随后由传输层加
上双方的端口号，由网络层加上双方的IP地址，由链路层加上双方的MAC地址，并
将数据拆分成数据帧，经过多个路由器和网关后，到达目标机器。简而言之，就是按
“端口→IP地址→ MAC地址”这样的路径进行数据的封装和发送，解包的时候反过
来操作即可

###### 1.5.2 IP协议
IP是面向无连接、无状态的，没有额外的机制保证发送的包是否有序到达。IP
首先规定出IP地址格式，该地址相当于在逻辑意义上进行了网段的划分，给每台计
算机额外设置了一个唯一的详细地址。既然链路层可以通过唯一的MAC地址找到机
器，为什么还需要通过唯一的IP地址再来标识呢?简单地说，在世界范围内，不可
能通过广播的方式，从数以千万计的计算机里找到目标MAC地址的计算机而不超时。
在数据投递时就需要对地址进行分层管理。举个例子，一个重要快递从美国发出，要
发给中国浙江省台州市某小区的X先生。快递公司需要先确定中国的转运中心(如
浙江某转运中心)，然后再从转运中心逐级配送到各个下级转运点。当快递到达该小
区后，快递员大喊一声: "X先生领快递啦!”虽然小区里包括X先生在内的所有人
都听到了快递员的喊声，但只有X先生收取快递并当面打开确认，其他人确定不是
叫自己则不用理会。IP 地址如图1-14所示，即30.38.48.22，右边为物理层发送和接
收数据的统计

IP地址属于网络层，主要功能在WLAN内进行路由寻址，选择最佳路由。IP报
文格式如图1-15所示，共32位4个字节，通常用十进制数来表示。IP 地址的掩码
0xffffff00表示255.255.255.0，掩码相同，则在同一子网内。IP协议在IP报头中记录
源IP地址和目标IP地址，如图1-15所示

协议结构比较简单，重点说一下数据包的生存时间，即TTL，它是数据包可经
过的最多路由器总数。TTL初始值由源主机设置后，数据包在传输过程中每经过一
个路由器TTL值则减1，当该字段为0时，数据包被丢弃，并发送ICMP报文通知
源主机，以防止源主机无休止地发送报文。这里扩展说一下ICMP ( Internet Control
Message Protocol)，它是检测传输网络是否通畅、主机是否可达、路由是否可用等网
络运行状态的协议。ICMP 虽然并不传输用户数据，但是对评估网络健康状态非常重
要，经常使用的ping、tracert 命令就是基于ICMP检测网络状态的有力工具。图1-15
中TTL右侧是挂载协议标识，表示IP数据包里放置的子数据包协议类型，如6代表
TCP、17代表UDP等

IP报文在互联网上传输时，可能要经历多个物理网络，才能从源主机到达目标
主机。比如在手机上给某个PC端的朋友发送一个信息，经过无线网的IEEE 802.1x
认证，转到光纤通信上，然后进入内部企业网802.3，并最终到达目标PC。由于不同
硬件的物理特性不同，对数据帧的最大长度都有不同的限制，这个最大长度被称为最
大传输单元，即MTU ( Maximum Transmission Unit)。那么在不同的物理网之间就
可能需要对IP报文进行分片，这个工作通常由路由器负责完成

IP是TCP/IP的基石，几乎所有其他协议都建立在IP所提供的服务基础上进行传
输，其中包括在实际应用中用于传输稳定有序数据的TCP

###### 1.5.3 TCP建立连接
传输控制协议( Transmission Control Protocol, TCP)，是一种面向连接、确保
数据在端到端间可靠传输的协议。面向连接是指在发送数据前，需要先建立一条虚拟
的链路，然后让数据在这条链路上“流动”完成传输。为了确保数据的可靠传输，不
仅需要对发出的每一个字节进行编号确认，校验每一个数据包的有效性，在出现超时
情况时进行重传，还需要通过实现滑动窗口和拥塞控制等机制，避免网络状况恶化而
最终影响数据传输的极端情形。每个TCP数据包是封装在IP包中的，每一个IP头的
后面紧接着的是TCP头，TCP报文格式如图1-16所示

协议第一行的两个端口号各占两个字节，分别表示了源机器和目标机器的端口号。
这两个端口号与IP报头中的源IP地址和目标IP地址所组成的四元组可唯一标识一条
TCP连接。由于TCP是面向连接的，因此有服务端和客户端之分。需要服务端先在
相应的端口上进行监听，准备好接收客户端发起的建立连接请求。当客户端发起第一
个请求建立连接的TCP包时，目标机器端口就是服务端所监听的端口号。比如一些
由国际组织定义的广为人知端口号一代表HTTP服务的80端口、代表SSH服务的
22端口、代表HTTPS服务的443端口。可通过netstat命令列出机器上已建立的连接
信息，其中包含唯一标识一条连接的四元组，以及各连接的状态等内容，如图1-17所示，
图中的红框代表端口号

协议第二行和第三行是序列号，各占4个字节。前者是指所发送数据包中数据部
分第一个字节的序号，后者是指期望收到来自对方的下一个数据包中数据部分第一个
字节的序号

由于TCP报头中存在一些扩展字段，所以需要通过长度为4个bit的头部长度字
段表示TCP报头的大小，这样接收方才能准确地计算出包中数据部分的开始位置

TCP的FLAG位由6个bit组成，分别代表ACK、SYN、FIN、URG、PSH、
RST，都以置1表示有效。我们重点关注SYN、ACK 和FIN。SYN ( Synchronize
Sequence Numbers )用作建立连接时的同步信号； ACK ( Acknowledgement)用于对
收到的数据进行确认，所确认的数据由确认序列号表示；FIN ( Finish)表示后面没有
数据需要发送，通常意味着所建立的连接需要关闭了

TCP报头中的其他字段可以阅读RFC793来掌握，本书在此不加赘述。接下来重
点分析TCP中连接建立的原理。图1-18展示了正常情形下通过三次握手建立连接的
过程。显然，B机器是服务端角色，A机器是客户端角色，前者需要在后者发起连接
建立请求时先打开某个端口等待数据传输，否则将无法正常建立连接。三次握手指的
是建立连接的三个步骤：

- A机器发出一个数据包并将SYN置1，表示希望建立连接。这个包中的序列
号假设是x

- B机器收到A机器发过来的数据包后，通过SYN得知这是一个建立连接的
请求，于是发送一个响应包并将SYN和ACK标记都置1。假设这个包中的
序列号是y，而确认序列号必须是x+1，表示收到了A发过来的SYN。在
TCP中，SYN被当作数据部分的一个字节

- A收到B的响应包后需进行确认，确认包中将ACK置1，并将确认序列号
设置为y+1，表示收到了来自B的SYN

这里为什么需要第3次握手?它有两个主要目的：信息对等和防止超时。先从信
息对等角度来看，如表1-6所示，双方只有确定4类信息，才能建立连接。在第2次
握手后，从B机器视角看还有两个红色的NO信息无法确认。在第3次握手后，B机
器才能确认自己的发报能力和对方的收报能力是正常的。

连接三次握手也是防止出现请求超时导致脏连接。TTL网络报文的生存时间往
往都会超过TCP请求超时时间，如果两次握手就可以创建连接，传输数据并释放连
接后，第一个超时的连接请求才到达B机器的话，B机器会以为是A创建新连接的
请求，然后确认同意创建连接。因为A机器的状态不是SYN_SENT，所以直接丢弃
了B的确认数据，以致最后只是B机器单方面创建连接完毕，简要示意图如图1-19
所示

如果是三次握手，则B机器收到连接请求后，同样会向A机器确认同意创建连接，
但因为A机器不是SYN_SENT状态，所以会直接丢弃，B机器由于长时间没有收到
确认信息，最终超时导致连接创建失败，因而不会出现脏连接。根据抓包分析，呈现
出三次握手请求过程，SYN+ACK 的应答，告诉A机器期望下一个数据包的第一个字
节序号为1，如图1-20所示

从编程的角度，TCP连接的建立是通过文件描述符( File Descriptor, fd )完成的。
通过创建套接字获得一个fd，然后服务端和客户端需要基于所获得的fd调用不同
的函数分别进入监听状态和发起连接请求。由于fd 的数量将决定服务端进程所能建
立连接的数量，对于大规模分布式服务来说，当fd不足时就会出现“open too many
files”错误而使得无法建立更多的连接。为此，需要注意调整服务端进程和操作系统
所支持的最大文件句柄数。通过使用ulimit -n命令来查看单个进程可以打开文件句柄
的数量。如果想查看当前系统各个进程产生了多少句柄，可以使用如”下的命令：
```shell
lsof -n | awk '{print $2}' | sort | uniq -c | sort -nr | more
```
执行结果如图1-21所示，左侧列是句柄数，右侧列是进程号。lsof 命令用于查
看当前系统所打开fd的数量。在Linux系统中，很多资源都是以fd的形式进行读写的，
除了提到的文件和TCP连接，UDP数据报、输入输出设备等都被抽象成了fd

想知道具体的PID对应的具体应用程序是谁，使用如下命令即可：
```shell
ps -ax | grep 32764
```
Java进程示例如图1-22所示

TCP在协议层面支持KeepAlive功能，即隔段时间通过向对方发送数据表示连
接处于健康状态。不少服务将确保连接健康的行为放到了应用层，通过定期发送心跳
包检查连接的健康度。一旦心跳包出现异常不仅会主动关闭连接，还会回收与连接相
关的其他用于提供服务的资源，确保系统资源最大限度地被有效利用。

###### 1.5.4 TCP断开连接
TCP是全双工通信，双方都能作为数据的发送方和接收方，但TCP连接也会有
断开的时候。所谓相爱容易分手难，建立连接只有三次，而挥手断开则需要四次，如
图1-23所示。A机器想要关闭连接，则待本方数据发送完毕后，传递FIN信号给B
机器。B机器应答ACK，告诉A机器可以断开，但是需要等B机器处理完数据，再
主动给A机器发送FIN信号。这时，A机器处于半关闭状态( FIN_WAIT_2)，无法
再发送新的数据。B机器做好连接关闭前的准备工作后，发送FIN给A机器，此时
B机器也进入半关闭状态( CLOSE_WAIT)。 A机器发送针对B机器FIN的ACK后，
进入TIME-WAIT状态，经过2MSL ( Maximum Segment Lifetime)后，没有收到B
机器传来的报文，则确定B机器已经收到A机器最后发送的ACK指令，此时TCP
连接正式释放。具体释放步骤如图1-23所示

通过抓包分析，如图1-24 所示红色箭头表示B机器已经清理好现场，并发送
FIN+ACK。注意，B机器主动发送的两次ACK应答的都是81，第一次进入CLOSE_WAIT
状态，第二次应答进入LAST_ACK状态，表示可以断开连接，在绿色箭头处，
A机器应答的就是Seq=81

四次挥手断开连接用通俗的说法可以形象化地这样描述
```text
男生:我们分手吧
女姓:好的，我的东西收拾完，发信息给你。( 此时男生不能再拥抱女生了。)
(1个小时后)
女生:我收拾好了，分手吧。( 此时，女生也不能再拥抱男生了。)
男生:好的。( 此时，双方约定经过2个月的过渡期，双方才可以分别找新的
对象。)
```
图1-23中的红色字体所示的TIME_WAIT和CLOSE_WAIT分别表示主动关闭和
被动关闭产生的阶段性状态，如果在线上服务器大量出现这两种状态，就会加重机器
负载，也会影响有效连接的创建，因此需要进行有针对性的调优处理

- TIME_WAIT：主动要求关闭的机器表示收到了对方的FIN报文，并发送出
了ACK 报文，进入TIME_WAIT状态， 等2MSL 后即可进入到CLOSED状
态。如果FIN_WAIT_1状态下，同时收到带FIN标志和ACK标志的报文时，
可以直接进入TIME_WAIT状态，而无须经过FIN_WAIT_2状态

- CLOSE_WAIT：被动要求关闭的机器收到对方请求关闭连接的FIN报文，
在第一次ACK应答后，马上进入CLOSE_WAIT状态。这种状态其实表示在
等待关闭，并且通知应用程序发送剩余数据，处理现场信息，关闭相关资源

在TIME_WAIT 等待的2MSL是报文在网络上生存的最长时间，超过阈值便将报
文丢弃。一般来说，MSL大于TTL衰减至0的时间。在RFC793中规定MSL为2分
钟。但是在当前的高速网络中，2分钟的等待时间会造成资源的极大浪费，在高并发
服务器上通常会使用更小的值。既然TIME_WAIT貌似是百害而无一利的，为何不直
接关闭，进入CLOSED状态呢?原因有如下几点

第一，确认被动关闭方能够顺利进入CLOSED状态。如图1-23 所示，假如最
后一个ACK由于网络原因导致无法到达B机器，处于LAST_ACK的B机器通常
“自信”地以为对方没有收到自己的FIN+ACK报文，所以会重发。A机器收到第二
次的FIN+ACK报文，会重发一次 ACK，并且重新计时。如果A机器收到B机器的
FIN+ACK报文后，发送一个ACK给B机器，就“自私”地立马进入CLOSED状态，
可能会导致B机器无法确保收到最后的ACK指令，也无法进入CLOSED状态。这是
A机器不负责任的表现

第二，防止失效请求。这样做是为了防止已失效连接的请求数据包与正常连接的
请求数据包混淆而发生异常

因为TIME_WAIT状态无法真正释放句柄资源，在此期间，Socket 中使用的本地
端口在默认情况下不能再被使用。该限制对于客户端机器来说是无所谓的，但对于高
并发服务器来说，会极大地限制有效连接的创建数量，成为性能瓶颈。所以，建议将
高并发服务器TIME_WAIT超时时间调小

在服务器上通过变更/etc/sysctl.conf文件来修改该省略值(秒)：
net.ipv4.tcp_fin_timeout=30 (建议小于30秒为宜)

修改完之后执行/sbin/sysctl -p让参数生效即可。可以通过如下命令:
```shell
netstat -n | awk '/^tcp/ {++S[$NF]} END {for (a in S) print a, S[a]}' 
```
查看各连接状态的计数情况，为了使数据快速生效，2MSL从240秒更改为5秒。参
数生效后如图1-25所示，TIME_WAIT很快从75个降为1个

在sysctl.conf中还有其他连接参数也用来不断地调优服务器TCP连接能力，以
提升服务器的有效利用率。毕竟现代网络和路由处理能力越来越强，跨国时延通常也
在1秒钟以内，丢包率极低。如何快速地使连接资源被释放和复用，参数的优化往往
可以取得事半功倍的效果。记得某大公司在大型购物节时，系统宕机，老总下令要加
一倍服务器来解决问题。事实上，如果是参数配置错误导致的系统宕机，即使增加硬
件资源，也无法达到好的效果。硬件的增加与性能的提升绝对不是线性相关的，更多
的时候是对数曲线关系

TIME_WAIT是挥手四次断开连接的尾声，如果此状态连接过多，则可以通过
优化服务器参数得到解决。如果不是对方连接的异常，一般不会出现连接无法关闭
的情况。但是CLOSE_WAIT过多很可能是程序自身的问题，比如在对方关闭连接
后，程序没有检测到，或者忘记自己关闭连接。在某次故障中，外部请求出现超时
的情况，当时的Apache服务器使用的是默认的配置方式，通过命令： netstat -antlgrep
-i "443"|grep CLOSE_WAIT|wc -l发现在HTTPS的443端口上堆积了2.1万个左右的
CLOSE_WAIT状态。经排查发现，原来是某程序处理完业务逻辑之后没有释放流操作，
但程序一直运行正常，直到运营活动时才大量触发该业务逻辑，最终导致故障的产生。

###### 1.5.5 连接池
我们使用连接来进行系统间的交互，如何管理成千，上万的连接呢?服务器可以快
速创建和断开连接，但对于高并发的后台服务器而言，连接的频繁创建与断开，是非
常重的负担。就好像我们正在紧急处理线上故障，给同事打电话一起定位问题时，一
般情况下都不会挂断电话，直到问题解决。在时间极度紧张的情况下，频繁地拨打和
接听电话会降低处理问题的效率。在客户端与服务端之间可以事先创建若干连接并提
前放置在连接池中，需要时可以从连接池直接获取，数据传输完成后，将连接归还至
连接池中，从而减少频繁创建和释放连接所造成的开销。例如，RPC服务集群的注册
中心与服务提供方、消费方之间，消息服务集群的缓存服务器和消费者服务器之间，
应用后台服务器和数据库之间，都会使用连接池来提升性能

重点提一下数据库连接池，连接资源在数据库端是一种非常关键且有限的系统
资源。连接过多往往会严重影响数据库性能。数据库连接池负责分配、管理和释放连
接，这是一种以内存空间换取时间的策略，能够明显地提升数据库操作的性能。但如
果数据库连接管理不善，也会影响到整个应用集群的吞吐量。连接池配置错误加上慢
SQL，就像屋漏偏逢连夜雨，可以瞬间让一个系统进入服务超时假死宕机状态

如何合理地创建、管理、断开连接呢?以Druid为例，Druid 是阿里巴巴的一个
数据库连接池开源框架，准确来说它不仅仅包括数据库连接池，还提供了强大的监控
和扩展功能。当应用启动时，连接池初始化最小连接数( MIN) ;当外部请求到达时，
直接使用空闲连接即可。假如并发数达到最大(MAX)，则需要等待，直到超时。
如果一直未拿到连接，就会抛出异常

如果MIN过小，可能会出现过多请求排队等待获取连接;如果MIN过大，会
造成资源浪费。如果MAX过小，则峰值情况下仍有很多请求处于等待状态；如果
MAX过大，可能导致数据库连接被占满，大量请求超时，进而影响其他应用，引发
服务器连环雪崩。在实际业务中，假如数据库配置的MAX是100，一个请求10ms,
则最大能够处理1000QPS。增大连接数，有可能会超过单台服务器的正常负载能力。
另外，连接数的创建是受到服务器操作系统的fd (文件描述符)数量限制的。创建更
多的活跃连接，就需要消耗更多的fd,系统默认单个进程可同时拥有1024个fd，该
值虽然可以适当调整，但如果无限制地增加，会导致服务器在fd的维护和切换上消
耗过多的精力，从而降低应用吞吐量

懒惰是人的天性，有时候开发工程师为了图省事还会不依不饶地要求调长
Timeout时间，如果这个数值过大，对于调用端来说也是不可接受的。如果应用服务
器超时，前台已经失败返回，但是后台仍然在没有意义地重试，并且还有新的处理请
求不断堆积，最终导致服务器崩溃。这明显是不合理的。所以在双十一的场景里，应
用服务器的全链路上不论是连接池的峰值处理，还是应用之间的调用频率，都会有相
关的限流措施和降级预案

图1-26所示的是某连接池的监控图。图中连接池最小的连接数是2，一个线程
就是一个活跃连接。一般可以把连接池的最大连接数设置在30个左右，理论上还可
以设置更大的值，但是DBA一般不会允许，因为往往只有出现了慢SQL，才需要使
用更多的连接数。这时候通常需要优化应用层逻辑或者创建数据库索引，而不是一味
地采用加大连接数这种治标不治本的做法。极端情况下甚至会导致数据库服务不响应，
进而影响其他业务

从经验上来看，在数据库层面的请求应答时间必须在100ms以内，秒级的SQL
查询通常存在巨大的性能提升空间，有如下应对方案：

(1)建立高效且合适的索引。索引谁都可以建，但要想建好难度极大。因为索
引既有数据特征，又有业务特征，数据量的变化会影响索引的选择，业务特点不一样，
索引的优化思路也不一样。通常某个字段平时不用，但是某种触发场景下命中“索引
缺失”的字段会导致查询瞬间变慢。所以，要事先明确业务场景，建立合适的索引

(2)排查连接资源未显式关闭的情形。要特别注意在ThreadLocal或流式计算
中使用数据库连接的地方

(3)合并短的请求。根据CPU的空间局部性原理，对于相近的数据，CPU会
一起提取到内存中。 另外，合并请求也可以有效减少连接的次数

(4)合理拆分多个表join的SQL， 若是超过三个表则禁止join。 如果表结构建
得不合理，应用逻辑处理不当，业务模型抽象有问题，那么三表join的数据量由于笛
卡儿积操作会呈几何级数增加，所以不推荐这样的做法。另外，对于需要join的字段，
数据类型应保持绝对一致。多表关联查询时，应确保被关联的字段要有索引

(5)使用临时表。某种情况下，该方法是一种比较好的选择。曾经遇到一个场
景不使用临时表需要执行1个多小时，使用临时表可以降低至2分钟以内。因为在不
断的嵌套查询中，已经无法很好地利用现有的索引提升查询效率，所以把中间结果保
存到临时表，然后重建索引，再通过临时表进行后续的数据操作

(6)应用层优化。包括进行数据结构优化、并发多线程改造等

( 7)改用其他数据库。因为不同数据库针对的业务场景是不同的，比如
Cassandra、MongoDB

##### 1.6 信息安全
###### 1.6.1 黑客与安全
黑客是音译词，译自Hacker。黑客的攻击手段十分多样，大体可分为非破坏性
攻击和破坏性攻击。非破坏性攻击一般是为了扰乱系统的运行，使之暂时失去正常对
外提供服务的能力，比如DDoS攻击等。破坏性攻击主要会造成两种后果：系统数据
受损或者信息被窃取，比如CSRF攻击等。黑客使用的攻击手段有病毒式、洪水式、
系统漏洞式等。黑客是计算机世界里永恒的存在，攻与守如同太极阴阳平衡的道家之
道，不可能有一天黑客会彻底消失

现代黑客攻击的特点是分布式、高流量、深度匿名。由于国外大量“肉鸡”没有登记，
所以国外的服务器遭遇DDoS攻击时，无法有效地防御。现今云端提供商的优势在于
能提供一套完整的安全解决方案。离开云端提供商，一个小企业要从头到尾地搭建一
套安全防御体系，技术成本和资源成本将是难以承受的。所以互联网企业都要建立一
套完整的信息安全体系，遵循CIA原则，即保密性( Confidentiality )完整性( Integrity )
可用性( Availability )

- 保密性。对需要保护的数据(比如用户的私人信息等)进行保密操作，无论
是存储还是传输，都要保证用户数据及相关资源的安全。比如，在存储文件
时会进行加密，在数据传输中也会通过各种编码方式对数据进行加密等。在
实际编程中，通常使用加密等手段保证数据的安全。黑客不只是外部的，有
可能从内部窃取数据，所以现在大多数企业的用户敏感信息都不是以明文存
储的，避免数据管理员在某些利益的驱动下，直接拖库下载。数据泄露可能
导致黑客进一步利用这些数据进行网站攻击，造成企业的巨大损失

- 完整性。访问的数据需要是完整的，而不是缺失的或者被篡改的，不然用户
访问的数据就是不正确的。比如，在商场看中一个型号为NB的手机，但售
货员在包装的时候被其他人换成了更便宜的型号为LB的手机，这就是我们
所说的资源被替换了，也就是不满足完整性的地方。在实际编写代码中，一
定要保证数据的完整性，通常的做法是对数据进行签名和校验(比如MD5
和数字签名等)

- 可用性。服务需要是可用的。如果连服务都不可用，也就没有安全这一说了。
比如还是去商场买东西，如果有人恶意破坏商场，故意雇用大量水军在商场
的收银台排队，既不结账也不走，导致其他人无法付款，这就是服务已经不
可用的表现。这个例子和常见的服务拒绝(DoS)攻击十分相似。对于这种情况，
通常使用访问控制、限流等手段解决

以上三点是安全中最基本的三个要素，后面谈到的Web安全问题，都是围绕这
三点来展开的

###### 1.6.2 SQL注入
SQL注入是注入式攻击中的常见类型。SQL注入式攻击是未将代码与数据进行
严格的隔离，导致在读取用户数据的时候，错误地把数据作为代码的一部分执行，从
而导致一些安全问题。SQL注入自诞生以来以其巨大的杀伤力闻名。典型的SQL注
入的例子是当对SQL语句进行字符串拼接操作时，直接使用未加转义的用户输入内
容作为变量，比如：
```sql
var testCondition;
testCondition = Request.from("testCondition")
var sql = "select * from TableA where id = '" + testCondition + "'";
```
在上面的例子中，如果用户输入的ID只是一个数字是没有问题的，可以执行正
常的查询语句。但如果直接用";” 隔开，在testCondition里插入其他SQL语句，则
会带来意想不到的结果，比如输入drop、delete 等

曾经在某业务中，用户在修改签名时，非常偶然地输入"# -- !#(@这样的内容用
来表达心情，单击保存后触发数据库更新。由于该业务未对危险字符串“#--” 进行
转义，导致where后边的信息被注释掉，执行语句变成：
```sql
update table set memo=""# -- !#(@ " where user_id=12345;
```
该SQL语句的执行导致全库的memo字段都被更新。所以，SQL注入的危害不
必赘述，注入的原理也非常简单。应该如何预防呢?这里主要从下面几个方面考虑：

(1)过滤用户输入参数中的特殊字符，从而降低被SQL注入的风险

(2)禁止通过字符串拼接的SQL语句，严格使用参数绑定传入的SQL参数

(3)合理使用数据库访问框架提供的防注入机制。比如MyBatis提供的#{}绑
定参数，从而防止SQL注入。同时谨慎使用${}，${} 相当于使用字符串拼接SQL。
拒绝拼接的SQL语句，使用参数化的语句

总之，一定要建立对注入式攻击的风险意识，正确使用参数化绑定SQL变量，
这样才能有效地避免SQL注入。实际上，其他的注入方式也是类似的思路，身为一
个开发工程师，我们一定要时刻保持对注入攻击的高度警惕

###### 1.6.3 XSS与CSRF
XSS与CSRF两个名词虽然都比较熟悉，但也容易混淆。跨站脚本攻击，即
Cross-Site Scripting，为了不和前端开发中层叠样式表(CSS)的名字冲突，简称为
XSS。XSS是指黑客通过技术手段，向正常用户请求的HTML页面中插入恶意脚本，
从而可以执行任意脚本。XSS主要分为反射型XSS、存储型XSS和DOM型XSS。
XSS主要用于信息窃取、破坏等目的。比如发生在2011年左右的微博XSS蠕虫攻击
事件，攻击者就利用了微博发布功能中未对action-data漏洞做有效的过滤，在发布微
博信息的时候带上了包含攻击脚本的URL。用户访问该微博时便加载了恶意脚本，
该脚本会让用户以自己的账号自动转发同一条微博，通过这种方式疯狂扩散，导致微
博大量用户被攻击

从技术原理上，后端Java开发人员、前端开发人员都有可能造成XSS漏洞，比
如下面的模板文件就可能导致反射型XSS：
```html
<div>
<h3>反射型XSS示例</h3>
<br>用户: <%= request.getParameter("userName") %>
<br>系统错误信息: <%= request.getParameter("errorMessage") %>
</div>
```
上面的代码从HTTP请求中取了userName和errorMesage两个参数，并直接输
出到HTML中用于展示，当黑客构造如下的URL时就出现了反射型XSS，用户浏览
器就可以执行黑客的JavaScript脚本
```text
http://xss.demo/self-xss.jsp?userName=张三<script>alert("张三")</script>
&errorMessage=XSS示例<script src=http://hacker.demo/xss-script.js />
```
在防范XSS上，主要通过对用户输入数据做过滤或者转义。比如Java开发人
员可以使用Jsoup框架对用户输入字符串做XSS过滤，或者使用框架提供的工具
类对用户输入的字符串做HTML转义，例如Spring框架提供的HtmlUtils。 前端在
浏览器展示数据时，也需要使用安全的API展示数据，比如使用innerText而不是
innerHTML。所以需要前、后端开发人员一同配合才能有效防范XSS漏洞

除了开发人员造成的漏洞，近年来出现了一种Self-XSS的攻击方式。Self-XSS
是利用部分非开发人员不懂技术，黑客通过红包、奖品或者优惠券等形式，诱导用户
复制攻击者提供的恶意代码，并粘贴到浏览器的Console中运行，从而导致XSS。由
于Self-XSS属于社会工程学攻击，技术上目前尚无有效防范机制，因此只能通过在
Console中展示提醒文案来阻止用户执行未知代码

###### 1.6.4 CSRF
跨站请求伪造( Cross-Site Request Forgery)，简称CSRF,也被称为One-click
Attack，即在用户并不知情的情况下，冒充用户发起请求，在当前已经登录的Web应
用程序上执行恶意操作，如恶意发帖、修改密码、发邮件等

CSRF有别于XSS，从攻击效果上，两者有重合的地方。从技术原理上两者有
本质的不同，XSS是在正常用户请求的HTML页面中执行了黑客提供的恶意代码;
CSRF是黑客直接盗用用户浏览器中的登录信息，冒充用户去执行黑客指定的操作。
XSS问题出在用户数据没有过滤、转义; CSRF问题出在HTTP接口没有防范不受信
任的调用。很多工程师会混淆这两个概念，甚至认为这两个攻击是一样的

比如某用户A登录了网上银行，这时黑客发给他一个链接，URL如下：
```text
https://net-bank.demo/transfer.do?targetAccount=12345&amount=100
```
如果用户A在打开了网银的浏览器中点开了黑客发送的URL，那么就有可能在.
用户A不知情的情况下从他的账户转100元人民币到其他账户。当然网上银行不会
有这么明显的漏洞

防范CSRF漏洞主要通过以下方式：

(1)CSRF Token验证，利用浏览器的同源限制，在HTTP接口执行前验证页面
或者Cookie中设置的Token，只有验证通过才继续执行请求

(2)人机交互，比如在调用上述网上银行转账接口时校验短信验证码

###### 1.6.5 HTTPS
在谍战剧里，情报如何不被截获，不被破译，几乎是全剧的主线剧情之一。某电
台通过某个频道发送一串数字，然后潜伏人员一般会拿密码本，译码后得到原文。这
个密码本就是对称加密中的密钥，发送方和接收方按照密码本分别进行加密和解密工
作。如果密码本被敌人截获，则后果极为严重，通常能够做的也就是更换密码本

早期计算机都是单机状态，保证数据的安全依赖于加密算法的可靠性。如果加密
算法可靠，即使存储介质被窃取，对方想通过密文恢复明文也是十分困难的。DES加
密算法是一种对称加密算法，它几乎让破解者无法找到规律，即使暴力破解也很难还
原出明文

发展到网络时代，整个网络中最频繁、最重要的操作就是网络中各终端之间的通
信。在传输层本身不会做任何的加密，这就好比一辆满载黄金的马车在驿道奔驰，很
难不让网络上的黑客视而不见。如何保证通信之间数据传输的安全性，成为了计算机
网络时代最重要的安全课题。说到对网络传输数据的加密，必须要先说安全套接字层
( Secure Socket Layer, SSL) 。SSL 协议工作于传输层与应用层之间，为应用提供数
据的加密传输。而HTTPS的全称是HTTP over SSL，简单的理解就是在之前的HTTP
传输上增加了SSL协议的加密能力

我们可以通过对称加密算法对数据进行加密，比如DES，即一个主站与用户之
间可以使用相同的密钥对传输内容进行加解密。是否可以认为这样就完全没有风险
呢?答案显然是否定的。因为密钥几乎没有什么保密性可言，如果与每一个用户之间
都约定一个独立的密钥，如何把密钥传输给对方，又是一个安全难题。在互联网上，
IP报文好比官道上运送粮草、黄金、物资的载体，很容易被人盯上，密钥本身如果被
盗，那么再复杂的密钥也是摆设。自然的想法是在密钥之上再加密，这就是递归的穷
举问题了

有没有一种方式，使报文被截取之后，黑客依然无计可施呢? 一种全新的算法
RSA出现了。它把密码革命性地分成公钥和私钥，由于两个密钥并不相同，所以称
为非对称加密。私钥是用来对公钥加密的信息进行解密的，是需要严格保密的。公钥
是对信息进行加密，任何人都可以知道，包括黑客

非对称加密的安全性是基于大质数分解的困难性，在非对称的加密中公钥和私钥
是一对大质数函数。计算两个大质数的乘积是简单的，但是这个过程的逆运算(即将
这个乘积分解为两个质数)是非常困难的。而在RSA的算法中，从一个公钥和密文
中解密出明文的难度等同于分解两个大质数的难度。因此在实际传输中，可以把公钥
发给对方。一方发送信息时，使用另一方的公钥进行加密生成密文。收到密文的一方
再用私钥进行解密，这样一来，传输就相对安全了

但是非对称加密并不是完美的，它有一个很明显的缺点是加密和解密耗时长，只
适合对少量数据进行处理。回到前面的例子中，我们担心对称加密中的密钥安全问题，
那么将密钥的传输使用非对称加密就完美地解决了这个问题。实际上，HTTPS也正
是通过这样一种方式来建立安全的SSL连接的。按照上述逻辑，用户甲与用户乙进
行非对称加密传输的过程如下：
```text
(1)甲告诉乙，使用RSA算法进行加密。乙说，好的
(2)甲和乙分别根据RSA生成一对密钥，互相发送公钥
(3)甲使用乙的公钥给乙加密报文信息
(4)乙收到信息，并用自己的密钥进行解密
(5)乙使用同样方式给甲发送信息，甲使用相同方式进行解密
```
这个过程，看起来似乎无懈可击，但是在TCP/IP里，端到端的通信，路途遥远，
夜长梦多。在(2)中，如果甲的送信使者中途被强盗截住，在严刑拷打之下，强盗
知道使者是去送公钥的，虽然没有办法破解甲的加密信息，但是可以把这个使者关起
来，自己生成一对密钥，然后冒充甲的使者到乙家，把自己的公钥给乙。乙信了，把
银行卡密码、存款金额统统告诉了中间的强盗。

所以，在解决了加密危机之后又产生了信任危机。如何解决信任问题呢?如
果有一个具有公信力的组织来证明身份，这个问题就得到了解决。CA (Certificate
Authority)就是颁发HTTPS证书的组织。HTTPS是当前网站的主流文本传输协议，
在基于HTTPS进行连接时，就需要数字证书。如图1-27所示，可以看到协议版本、
签名方案、签发的组织是GlobalSign，这个证书的有效期至2018年10月31日

访问一个HTTPS的网站的大致流程如下：
```text
(1)浏览器向服务器发送请求，请求中包括浏览器支持的协议，并附带一个随机数
(2)服务器收到请求后，选择某种非对称加密算法，把数字证书签名公钥、身
份信息发送给浏览器，同时也附带一个随机数
(3)浏览器收到后，验证证书的真实性, 用服务器的公钥发送握手信息给服务器
(4)服务器解密后，使用之前的随机数计算出一个对称加密的密钥，以此作为
加密信息并发送
(5)后续所有的信息发送都是以对称加密方式进行的
```
我们注意到在证书的信息中出现了传输层安全协议( Transport Layer Security,
TLS)的概念。这里先解释TLS和SSL的区别。TLS可以理解成SSL协议3.0版本
的升级，所以TLS的1.0 版本也被标识为SSL3.1版本。但对于大的协议栈而言，
SSL和TLS并没有太大的区别，因此在Wireshark里，分层依然用的是安全套接字层
(SSL)标识

在整个HTTPS的传输过程中，主要分为两部分:首先是HTTPS的握手，然后
是数据的传输。前者是建立一个HTTPS的通道，并确定连接使用的加密套件及数据
传输使用的密钥。而后者主要使用密钥对数据加密并传输

首先来看HTTPS是如何进行握手的，如图1-28所示是一个完整的SSL数据流
和简单流程

- 第一，客户端发送了一个Client Hello协议的请求：在Client Hello中最重要的信
息是Cipher Suites字段，这里客户端会告诉服务端自己支持哪些加密的套件。比如在
这次SSL连接中，客户端支持的加密套件协议如图1-29 所示

- 第二，服务端在收到客户端发来的Client Hello的请求后，会返回一系列的协议
数据，并以一个没有数据内容的Server Hello Done作为结束。这些协议数据有的是单
独发送，有的则是合并发送，这里分别解释下几个比较重要的协议，如图1-30 所示

  - (1) Server Hello协议。主要告知客户端后续协议中要使用的TLS协议版本，
这个版本主要和客户端与服务端支持的最高版本有关。比如本次确认后续的TLS协
议版本是TLSv1.2，并为本次连接分配一个会话ID ( Session ID)。此外，还会确
认后续采用的加密套件( Cipher Suite)，这里确认使用的加密套件为
TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256。该加密套件的基本含义为：使用非对称协议
加密(RSA)进行对称协议加密( AES )密钥的加密，并使用对称加密协议( AES )
进行信息的加密

  - (2) Certificate协议。主要传输服务端的证书内容

  - (3) Server Key Exchange。如果在Certificate协议中未给出客户端足够的信息，
则会在Server Key Exchange进行补充，如图1-31所示。比如在本次连接中Certificate
未给出证书的公钥(Public Key)，这个公钥的信息将会通过Server Key Exchange发
送给客户端

  - (4) Cerificate Request。 这个协议是一个可选项，当服务端需要对客户端进行
证书验证的时候，才会向客户端发送一个证书请求(Crtificate Request)

  - (5) 最后以Server Hello Done作为结束信息，告知客户端整个Server Hello过
程结束

- 第三，客户端在收到服务端的握手信息后，根据服务端的请求，也会发送一系列
的协议

  - (1) Certificate。 它是可选项。因为上文中服务端发送了Certificate Request需要
对客户端进行证书验证，所以客户端要发送自己的证书信息

  - (2 ) Client Key Exchange。 它与上文中Server Key Exchange类似，是对客户端
Certificate信息的补充，在本次请求中同样是补充了客户端证书的公钥信息， 如图1-32
所示

  - (3) Crification Verity。对服务端发送的证书信息进行确认

  - (4) Change Cipher Spec。该协议不同于其他握手协议(Handshake Protocol)，
而是作为一个独立协议告知服务端，客户端已经接收之前服务端确认的加密套件，并
会在后续通信中使用该加密套件进行加密

  - (5) Encrypted Handshake Message。 用于客户端给服务端加密套件加密一段
Finish的数据，用以验证这条建立起来的加解密通道的正确性

- 第四，服务端在接收客户端的确认信息及验证信息后，会对客户端发送的数据进
行确认，这里也分为几个协议进行回复

  - (1) Change Cipher Spec。 通过使用私钥对客户端发送的数据进行解密，并告知
后续将使用协商好的加密套件进行加密传输数据

  - (2) Encrypted Handshake Message。与客户端的操作相同，发送一段Finish的加
密数据验证：加密通道的正确性

- 最后，如果客户端和服务端都确认加解密无误后，各自按照之前约定的Session
Secret对Application Data进行加密传输

##### 1.7 编程语言的发展
编程语言以既定的语法规则，使用一组自定义的特定标记字符流或关键字，实现
基本的顺序、条件、循环处理，这样的逻辑通过编译或解释形成计算机底层硬件可以
执行的一系列指令，来自动化执行某种逻辑计算或实现某种需求。计算机语言诞生的
历史虽然很短，可是已经产生了上千种编程语言。为什么编程语言如此之多?其实这
反映了一种生物多样化的自然属性。随着时代的进步，编程语言就像一棵树， 树根是
0与1，越往上生长树枝越多，这些树枝快速产生的原因和计算机技术应用的快速蓬
勃发展有关。计算机从单机时代，到网络时代、移动时代、云计算，直至目前的AI
时代，总有一批编程语言随着大潮退去，又有一批新的语言随着浪潮诞生。从编程语
言类型的角度，可划分为三个编程语言时代：

- 第一代，机器语言时代。机器语言的编程就是单纯的0与1的二进制流输入。机
器语言的优点是可以直接对芯片进行指令操作，最大的问题也来源于此。换一套不同
的硬件环境，机器语言几乎100%卡壳。另外，指令不利于记忆，语言的生产率非常低。
汇编语言本质上与机器语言处于同一个时代，只是在与机器指令对应的字符编程方式，
以及助记符之上增加了编译功能

- 第二代，高级语言时代。高级语言正是当前百花齐放的时代。正因为机器语言面
向机器编程，理解度差，复用度低。无论是面向过程，还是面向对象，都是面向问题编程，
不是描述计算机具体应该执行什么样的分步操作，而是更倾向于描述需要解决的问题
本身。面向过程更多描述的是解决问题的步骤，在实际步骤中协调各个参与方达成最
后的目标；面向对象是抽象问题各方的参与者，包括领域对象、问题域、运行环境等，
然后定义各个参与者的属性与行为，最后合力解决问题。高级语言时代，尤其是C、
C++、Java、Python等这些工业级语言的诞生和发展，使计算机行业得到极大的发展，
推动了互联网和人工智能的快速发展

- 第三代，自然语言时代。自然语言编程是面向思维或模糊语义的编程方式，软件
生产只是思考问题本身的存在性和合理性，而不是定义问题的解决方式和解决步骤。
这个时代很遥远，但很唯美。相信随着AI科技的不断进步，一定会实现

存在即是合理，本节并非讨论编程语言的高低优劣；对编程语言历史的回顾，只
是让我们更加热爱从事的编程事业，了解那些大师们的伟大，体验语言背后的魅力与
时代特征

早在1936年，图灵在《论数字计算在决断难题中的应用》论文中提出了图灵机
的设想。图灵机假想有一条无限长的纸带，纸带上有一系列带有某种信息的方格，机
器会根据当前状态和控制规则，处理当前方格上的信息，然后纸带移动或跳转一格。
编写这个纸带的过程就是最初的编程雏形，形成的规则来操控图灵机进行顺序读取，
或者直接跳至某个方格，在另一条纸带上写入某些信息

冯.诺依曼被称为“计算机之父”，从世界上第一台计算机ENIAC到现在的服务器、
笔记本、手机，基本上沿用了他的计算机结构设计理念。它根据电子元件双稳工作的
特点，从简化机器逻辑线路的角度出发，明确提出了二进制理论，采用0与1代表十
进制数值；提出计算机的基本工作原理是存储数据、处理数据、相关控制，定义出新
一代机器的雏形，即分成五个部分，运算器、控制器、存储器、输入设备和输出设备。
任何程序要想运行都需要加载到内部存储器(内存)中，在内存中才有资格和运算器、
控制器进行对话，执行逻辑运算和数据处理，计算机雏形如图1-33 所示

1946年，按此设想的第一台计算机诞生，从此自动化处理的场景越来越多。计
算机能够自动化处理的事情是需要以它可以理解的方式进行设计并录入的，这个过程
称为编码。计算机只能消化两种信息录入：0或1。在机器语言编程的时代，编码就
是这样枯燥的0与1的数据流录入。汇编语言以方便记忆的代号表示0与1的指令流，
在执行时，再反向转成0或1的二进制流，这个过程称为编程。不再直接编写0或1
的机器码指令，而是以一定的方式组织成程序。至此，可以阅读的代码开始出现。到
了20 世纪70年代，丹尼斯·里奇设计的C语言在BCPL语言基础上诞生。UNIX和
Linux系统成功推动了C语言的普及，至今C语言仍然是TOP的主流语言，在操作系统、
底层编译、硬件设备上依然发挥着不可替代的价值。C语言是高级语言时代中的低级
语言，低级的意思是更加贴近于硬件底层。这类低级语言使编程者有机会深入了解底
层硬件，后续的众多高级语言的编译器本身就是由C语言编写的

后来出现的一种高级语言，火了一个岛屿和一种饮料：爪哇岛和咖啡，即Java
语言。它的校验首字段即为十六进制的cafe babe，诉说着与咖啡的不解之缘，这是第
一个真正面向对象的语言

据不完全统计，当前编程语言超过1000种，优秀的程序员至少需要掌握3门语言，
这有助于知晓不同语言的各自特性，更重要的是洞悉语言的共性和编程语言思想，跨
越语言的抽象思维和架构掌控力。但是掌握不等于精通，真正的大师，需要醉心在某
种语言，不断研究、不断打磨、不断回炉，才能达到炉火纯青、登峰造极的境界。我
们写的每一行代码都是站在巨 人的肩膀上，使我们看得更远。虽然任何编程语言的结
构都是顺序、条件、循环，任何编程语言的本质都是输入与输出，但是0与1的世界
一定会因为 编程而变得更加智能、更加美好
#### 第1章 计算机基础
追根究底是深度分析和解决问题、提升程序员素质的关键所在，有助于编写高质
的代码。基础知识的深度认知决定着知识上层建筑的延展性。试问对于如下的基
础知识，你的认知是否足够清晰呢？

- 位移运算可以快速地实现乘除运算，那位移时要注意什么？

- 浮点数的存储与计算为什么总会产生微小的误差？

- 乱码产生的根源是什么？

- 代码执行时，CPU是如何与内存配合完成程序使命的？

- 网络连接资源耗尽的问题本质是什么？

- 黑客攻击的通常套路是什么？如何有效地防止？

本章从编程的角度深度探讨计算机组成原理、计算机网络、信息安全等相关内容，
与具体编程语言无关。本章将不会讨论内部硬件的工作原理、网络世界的协议和底层
传输方式、 安全领域的攻防类型等内容

##### 1.1 走进0与1的世界
简单地说，计算机就是晶体管、电路板组装起来的电子设备，无论是图形图像的
渲染、网络远程共享，还是大数据计算， 归根结底都是0与1的信号处理。信息存储
和逻辑计算的元数据，只能是0与1，但是它们在不同介质里的物理表现方式却是不
一样的，如三极管的断电与通电、CPU的低电平与高电平、磁盘的电荷左右方向。
明确了0与1的物理表现方式后，设定基数为 2，进位规则是“逢二进一”，借位规
则是“借一当二”，所以称为二进制。那么如何表示日常生活中的十进制数值呢？二
进制数位从右往左， 每一位都是乘以 2，如下示例为二进制数与十进制数的对应关系，
阴影部分的数字为二进制数：

1=1, 10=2, 100=4, 1000=8, 11000=24, 即 2^0=1; 2^1=2; 2^2=4; 2^3=8; 2^4+2^3=24

设想有8条电路，每条电路有低电平和高电平两种状态。根据数学排列组合，有
8个2相乘，即2^8能够表示256种不同的信号。假设表示区间为 0～255，最大数
即为 2^8-1，那么 32 条电路能够表示的最大数为（2^32-1）=4,294 ,967,295 。 平时所说
的32位机器，就能够同时处理字长为 32 位的电路信号

如何表示负数呢？上面的8条电路，最左侧的条表示正负，0表示正数，1表
示负数，不参与数值表示。8条电路的最大值为01111111即127，表示范围因有正负 
之分而改变为-128 ～127，二进制整数最终都是以补码形式出现的。正数的补码与
原码、反码是一样的，而负数的补码是反码加1的结果。这样使减法运算可以使用加
法器实现，符号位也参与运算。比如 35 + (-35） 如图 1-1 ( a） 所示，35 -37 如图 1-1 ( b )
所示

加减法是高频运算，使用同一个运算器，可以减少中间变量存储的开销， 这样也
降低了CPU内部的设计复杂度，使内部结构更加精简，计算更加高效，无论对于指令、
寄存器，还是运算器都会减轻很大的负担

如图 1-1 ( c） 所示， 计算结果需要9条电路来表示，用8条电路来表达这个计算
结果即溢出，即在数值运算过程中，超出规定的表示范围。一旦溢出，计算结果就是
错误的。在各种编程语言中，均规定了不同数字类型的表示范围，有相应的最大值和
最小值

以上示例中的一条电路线在计算机中被称为1位，即1个bit，简写为b。8个
bit组成一个单位，称为一个字节，即1个 Byte，简写为B 。1024个Byte，简写为
KB，1024个KB，简写为MB；1024个MB，简写为GB，这些都是计算机中常用的
存储计量单位

除二进制的加减法外，还有一种大家既陌生又熟悉的操作：位移运算。陌生是指
不易理解且不常用，熟悉是指 “ 别人家的开发工程师 ” 在代码中经常使用这种方式进
行高低位的截取、哈希计算，甚至运用在乘除法运算中。向右移动1位近似表示除以
2（如表 1-1 所示），十进制的奇数转化为二进制数后，在向右移时，最右边的1将
被直接抹去，说明向右移对于奇数并非完全相当于除以2。在左移<<与右移>>两种
运算中，符号位均参与移动，除负数往右移动，高位补1之外，其他情况均在空位处 
补0，红色是原有数据的符号位，绿色仅是标记，便于识别移动方向

左移运算由于符号位参与向左移动，在移动后的结果中，最左位可能是1或者0,
即正数向左移动的结果可能是正，也可能是负，负数向左移动的结果同样可能是正，
也可能是负

对于三个大于号的>>> 无符号向右移动（注意不存在<<<无符号向左移动的运
算方式），当向右移动时，正负数高位均补 0，正数不断向右移动的最小值是 0，而
负数不断向右移动的最小值是 1 。无符号意即藐视符号位，符号位失去特权，必须像
其他平常的数字位一起向右移动，高位直接补0，根本不关心是正数还是负数。此运
算常用在高位转低位的场景中，如表 1-2 所示分别表示向右移动1～3位的结果，左
侧空位均补0

为何负数不断地无符号向右移动的最小值是1呢？在实际编程中，位移运算仅作
用于整型 （32 位）和长整型 （64 位）数上， 假如在整型数上移动的位数是 32 位，无
论是否带符号位以及移动方向，均为本身。因为移动的位数是个mod 32 的结果，
即 35>>1与35>>33 是一样的结果。如果是长整型，mod 64，即 35<<1 与 35<<65 的
结果是一样的。负数在无符号往右移动 63 位时，除最右边为1外，左边均为 0，达
到最小值 1，如果>>>64，则为其原数值本身

位运算的其他操作比较好理解，包括按位取反（符号为～）、按位与（符号为 ＆） 、
按位或（符号为|）、按位异或（符号为^）等运算。其中 ， 按位与（＆）运算典型的
场景是获取网段值， IP 地址与掩码 255.255.255.0 进行按位与运算得到高 24 位，即为
当前 IP 的网段。按位运算的左右两边都是整型数，true&false 这样的方式也是合法的，
因为 boolean 底层表示也是 0 与 1

按位与和逻辑与（符号为＆＆）运算都可以作用于条件表达式，但是后者有短路
功能 ，表达如下所示：
```java
boolean a = true;
boolean b = true;
boolean c = (a=(1==2)) && (b=(1==2));
```
因为＆＆前边的条件表达式，即如上的红色代码部分的结果为false，触发短路，
直接退出，最后 a 的值为 false，b 的值为 true。假如把＆＆修改为按位与＆，则执行
的结果为 a 与 b 都是 false

同样的逻辑，按位或对应的逻辑或运算（符号为||）也具有短路功能，当逻辑或
||之前的条件表达式 ，即如下的红色代码部分的结果为true时，直接退出：

```java
boolean e = false;
boolean f = false;
boolean g = (e=(1==1)) || (f=(1==1));
```
最后 e 的值为 true，f 的值为 false。假如把||修改为按位或符号| ，执行的结果为
e 与 f 都是true

逻辑或、逻辑与运算只能对布尔类型的条件表达式进行运算， 7&&8 这种运算表
达式是错误的

异或运算没有短路功能，符号在键盘的数字 6 上方，在哈希算法中用于离散
哈希值 ， 对应的位上不一样才是 1，一样的都是 0。比如，1^1=0 / 0^0=0 / 1^0=1 / 
true^true=false / true/\ false=true

基于 0 与1的信号处理为我们带来了缤纷多彩的计算机世界，随着基础材料和信
号处理技术的发展，未来计算机能够处理的基础信号将不仅仅是二进制信息。比如，
三进制（高电平、低电平、断电），甚至十进制信息，届时计算机世界又会迎来一次
全新的变革

##### 1.2 浮点数
计算机定义了两种小数，分别为定点数和浮点数。其中，定点数的小数点位置是
固定的，在确定字长的系统中一旦指定小数点的位置后，它的整数部分和小数部分也
随之确定。二者之间独立表示，互不干扰。由于小数点位置是固定的，所以定点数能
够表示的范围非常有限。考虑到定点数相对简单，本节不再展开。下面重点介绍应用
更广、更加复杂的浮点数。它是采用科学计数法来表示的，由符号位、有效数字、指
数三部分组成。使用浮点数存储和计算的场景无处不在，若使用不当则容易造成计算
值与理论值不一致，如下示例代码:
```java
float a = 1f;
float b = 0.9f;
// 结果为:0.100000024
float f = a - b;
```
执行结果显示计算结果与预期存在明显的误差，本节将通过深入剖析造成这个误
差的原因来介绍浮点数的构成与计算原理。由于浮点数是以科学计数法来表示的，所
以我们先从科学计数法讲起

###### 1.2.1 科学计数法
浮点数是计算机用来表示小数的一种数据类型。在数学中，采用科学计数法来近
似表示一个极大或极小且位数较多的数。如a X 10^n，其中a满足1 ≤ |a| < 10，10^n
是以10为底数，n为指数的幂运算表达式。a X 10^n还可以表示成aen，如图1-2(a)中计算
器的结果所示。-4.86e11等价于-4.86 X 10^11，它们都表示真实值-4800000000，
具体格式说明如图1-2 (b)所示

科学计数法的有效数字为从第1个非零数字开始的全部数字，指数决定小数点的
位置，符号表示该数的正与负。值得注意的是，十进制科学计数法要求有效数字的整
数部分必须在[1,9]区间内，即图1-2(b)中的“4”，满足这个要求的表示形式被称
为“规格化”。科学计数法可以唯一地表示任何一 个数，且所占用的存储空间会更少，
计算机就是利用这一特性表示极大或极小的数值。例如，长整型能表示的最大值约为
922亿亿，想要表示更大量级的数值，必须使用浮点数才可以做到

###### 1.2.2 浮点数表示
浮点数表示就是如何用二进制数表示符号、指数和有效数字。当前业界流行的浮
点数标准是IEEE754，该标准规定了4种浮点数类型：单精度、双精度、延伸单精度、
延伸双精度。前两种类型是最常用的，它们的取值范围如表1-3 所示

因为浮点数无法表示零值，所以取值范围分为两个区间：正数区间和负数区间。
下面将着重分析单精度浮点数，而双精度浮点数与其相比只是位数不同而已，完全可
以触类旁通，本节不再展开。以单精度类型为例，它被分配了4个字节，总共32位，
具体格式如图1-3所示

从数学世界的科学计数法映射到计算机世界的浮点数时，数制从十进制改为二进
制，还要考虑内存硬件设备的实现方式。在规格化表示上存在差异，称谓有所改变，
指数称为“阶码”，有效数字称为“尾数”，所以用于存储符号、阶码、尾数的二进
制位分别称为符号位、阶码位、尾数位，下面详细阐述三个部分的编码格式

1. 符号位
在最高二进制位.上分配1位表示浮点数的符号，0表示正数，1表示负数

2. 阶码位
在符号位右侧分配8位用来存储指数，IEEB754 标准规定阶码位存储的是指数对
应的移码，而不是指数的原码或补码。根据计算机组成原理中对移码的定义可知，移
码是将一个真值在数轴上正向平移一个偏移量之后得到的，即[x]<sub>移</sub>=x+2^n-1(n为x
的二进制位数，含符号位)。移码的几何意义是把真值映射到一个正数域，其特点是
可以直观地反映两个真值的大小，即移码大的真值也大。基于这个特点，对计算机来
说用移码比较两个真值的大小非常简单，只要高位对齐后逐个比较即可，不用考虑负
号的问题，这也是阶码会采用移码表示的原因所在

由于阶码实际存储的是指数的移码，所以指数与阶码之间的换算关系就是指数与
它的移码之间的换算关系。假设指数的真值为e，阶码为E，则有E=e+(2^n-1-1),其
中2^n-1-1是IEEE754标准规定的偏移量，n=8 是阶码的二进制位数

为什么偏移值为2^n-1-1而不是2^n-1呢?因为8个二进制位能表示指数的取值范
围为[-128,127]，现在将指数变成移码表示，即将区间[-128,127]正向平移到正数域，
区间里的每个数都需要加上128，从而得到阶码范围为[0,255]。 由于计算机规定阶码
全为0或全为1两种情况被当作特殊值处理(全0被认为是机器零，全1被认为是无
穷大)，去除这两个特殊值，阶码的取值范围变成了[1,254]。 如果偏移量不变仍为
128的话，则根据换算关系公式[x]<sub>阶</sub>=x+128得到指数的范围变成[-127,126],指
数最大只能取到126，显然会缩小浮点数能表示的取值范围。所以IEEE754标准规定
单精度的阶码偏移量为2^n-1-1 (即127)，这样能表示的指数范围为[-126,127]，
指数最大值能取到127

3. 尾数位

最右侧分配连续的23位用来存储有效数字，IEEE754标准规定尾数以原码表
示。正指数和有效数字的最大值决定了32位存储空间能够表示浮点数的十进制最
大值。指数最大值为2^127≈1.7 X 10^38，而有效数字部分最大值是二进制的1.11…1
(小数点后23个1)，是一个无限接近于2的数字，所以得到最大的十进制数为
2 X 1.7 X 10^38，再加上最左1位的符号，最终得到32位浮点数最大值为3.4e+38。
为了方便阅读，从右向左每4位用短横线断开:
<font color='red'>0</font> <font color='green'>111-1111-0</font> <font color='orange'>111-1111-1111-1111-1111-1111</font>  

- 红色部分为符号位，值为0，表示正数
- 绿色部分为阶码位即指数，值为2^(254-127)=2^127≈1.7 x 10^38
- 黄色部分为尾数位即有效数字，值为1.111111111111111

科学计数法进行规格化的目的是保证浮点数表示的唯一性。 如同十进制规格化的
要求1≤|a|<10，二进制数值规格化后的尾数形式为1.xyz, 满足1≤|a|<2。为了
节约存储空间，将符合规格化尾数的首个1省略，所以尾数表面上是23位，却表示
了24位二进制数，如图1-4所示

常用浮点数的规格化表示如表 1 -4 所示

###### 1.2.3 加减运算
在数学中，进行两个小数的加减运算时，首先要将小数点对齐，然后同位数进行
加减运算。对两个采用科学计数法表示的数做加减法运算时，为了让小数点对齐就需
要确保指数一样。当小数点对齐后，再将有效数字按照正常的数进行加减运算

(1)零值检测。检查参加运算的两个数中是否存在为0的数(0在浮点数是一
种规定，即阶码与尾数全为0)，因为浮点数运算过程比较复杂，如果其中一个数为0,
可以直接得出结果

(2)对阶操作。通过比较阶码的大小判断小数点位置是否对齐。当阶码不相等
时表示当前两个浮点数的小数点位置没有对齐，则需要通过移动尾数改变阶码的大小，
使二者最终相等，这个过程便称为对阶。尾数向右移动1位，则阶码值加1，反之减1。
在移动尾数时，部分二进制位将会被移出，但向左移会使高位被移出，对结果造成的
误差更大。所以，IEEE754 规定对阶的移动方向为向右移动，即选择阶码小的数进行
操作

(3)尾数求和。当对阶完成后，直接按位相加即可完成求和(如果是负数则需
要先转换成补码再进行运算)。这个道理与十进制数加法相同，例如9.8 X 10^38与
6.5 X 10^37进行求和，将指数小的进行升阶，即6.5 X 1037变成0.65 X 10^38， 然后求
和得到结果为10.45 x 10^38

(4)结果规格化。如果运算的结果仍然满足规格化形式，则无须处理，否则需
要通过尾数位的向左或右移动调整达到规格化形式。尾数位向右移动称为右规，反之
称为左规。如上面计算结果为10.45 X 10^38， 右规操作后为1.045 X 10^39

(5)结果舍入。在对阶过程或右规时，尾数需要右移，最右端被移出的位会
被丢弃，从而导致结果精度的损失。为了减少这种精度的损失，先将移出的这部分数
据保存起来，称为保护位，等到规格化后再根据保护位进行舍入处理

了解了浮点数的加减运算过程后可以发现，阶码在加减运算过程中只是用来比较
大小，从而决定是否需要进行对阶操作。所以，IEEE754 标准针对这一特性， 将阶码
采用移码表示，目的就是利用移码的特点来简化两个数的比较操作。下面针对前面例
子从对阶、按位减法的角度分析为什么1.0-0.9 结果为0.00000024,而不是理论值0.1。
1.0-0.9等价于1.0+(-0.9)，首先分析1.0与-0.9的二进制编码:

1.0的二进制为0011-1111-1000-0000-0000-0000000-0000

-0.9的二进制为1011-1111-01 10-0110-0110-01 10-0110-0110

从上可以得出二者的符号、阶码、尾数三部分数据，如表1-5所示

由于尾数位的最左端存在一个隐藏位，所以实际尾数二进制分别为： 1000-0000-
0000-0000-0000-0000和1110-0110-0110-0110-0110-0110，红色为隐藏位。下面运算都
是基于实际的尾数位进行的，具体过程如下：

(1)对阶。1.0的阶码为127， -0.9的阶码为126， 比较阶码大小后需要向右移
动-0.9尾数的补码，使其阶码变为127，同时高位需要补1,移动后的结果为1000-
1100-1100-1100-1100-1101，最左的1是高位补进的。注意，绿色只是为了方便与表格
右下方的数字进行对比

(2)尾数求和。因为尾数都转换成补码，所以可以直接按位相加，注意符号位
也要参与运算，如图1-5所示

其中最左端为符号位，计算结果为0，尾数位计算结果为0000-1100-1100-1100-
1100-1101

(3)规格化。上一步计算的结果并不符合要求，尾数的最高位必须是1，所
以需要将结果向左移动4位，同时阶码需要减4。移动后阶码等于123 (二进制为
1111011)，尾数为1100-1100-1100-1100-1101-0000。 再隐藏尾数的最高位，进而变为
100-1100-1100-1100-1101-0000

综上所述，得出运算后结果的符号为0、阶码为1111011、尾数为100-1100-1100-
1100-1101-0000，三部分组合起来就是1.0-0.9 的结果，对应的十进制值为0.100000024。
至此，在本节开始处的减法悬案真相大白

###### 1.2.4 浮点数使用
在使用浮点数时推荐使用双精度，使用单精度由于表示区间的限制，计算结果会
出现微小的误差，实例代码如下所示：
```java
float ff = 0.9f;
double dd = 0.9d;
// 0.8999999761581421
System.out.println(ff/1.0);
// 0.9
System.out.println(dd/1.0);
```
在要求绝对精确表示的业务场景下，比如金融行业的货币表示，推荐使用整型存
储其最小单位的值，展示时可以转换成该货币的常用单位，比如人民币使用分存储，
美元使用美分存储。在要求精确表示小数点n位的业务场景下，比如圆周率要求存储
小数点后1000位数字，使用单精度和双精度浮点数类型保存是难以做到的，这时推
荐采用数组保存小数部分的数据。在比较浮点数时，由于存在误差，往往会出现意料
之外的结果，所以禁止通过判断两个浮点数是否相等来控制某些业务流程。在数据库
中保存小数时，推荐使用decimal类型，禁止使用float类型和double类型。因为这
两种类型在存储的时候，存在精度损失的问题

综上所述，在要求绝对精度表示的业务场景中，在小数保存、计算、转型过程中
都需要谨慎对待

##### 1.3 字符集与乱码
理解0和1的物理信号来源及数值表示方式后，如何将0和1表示成我们看到的
文字呢?从26个英文字母说起，大小写共52个，加上10个数字达到62个，考虑到
还有特殊字符(如：! @ # $ % ^ & * { } | 等）和不可见的控制字符，必然超过64个，
这又该如何表示呢?注意这里特别提到了“64” ，因为它的特殊性，即2的6次方。
使用刚才的0与1组合，至少是7组连续的信号量。计算机在诞生之初对于存储和传
输介质实在没有什么信心，所以预留了一个bit(位)用于奇偶校验,这就是1个Byte(字
节)由8个bit组成的来历，也就是ASCII码。

在ASCII码中，有两个特殊的控制字符10和13，前者是LF即“\n”，后者是
CR即“\r”,在编码过程中，代码的换行虽然是默认不可见的，但在不同的操作系统中，
表示方式是不一样的。在UNIX系统中，换行使用换行符“\n” ;在Windows系统中，
换行使用“\r\n” ;在旧版macOS中，换行使用回车符“\r” ，在新版macOS中使用
与UNIX系统相同的换行方式。如图1-6所示，当前编码环境使用换行方式是LF,
这也是推荐的换行方式，避免出现源码在不同操作系统中换行显示不同的情况

再说汉字的字符集表示，首先汉字的个数远远超过英文字符的个数。毕竟ASCII
码先入为主，必须在它基础上继续编码，也必须想办法和它兼容。一个字节只能表示
128个字符，所以采用双字节进行编码。早期使用的标准GB2312收录了6763个常用
汉字。而GBK (K是拼音kuo的首字母，是扩展的意思)支持繁体，兼容GB2312。
而后来的GB18030是国家标准，在技术上是GBK的超集并与之兼容。1994 年正式
公布的Unicode，为每种语言中的每个字符都设定了唯一编码， 以满足跨语言的交流，
分为编码方式和实现方式。实现Unicode的编码格式有三种: UTF-8、 UTF-16、 UTF-
32，UTF ( Unicode Transformation Format)即Unicode字符集转换格式，可以理解为
对Unicode的压缩方式。根据二八原则，常用文字只占文字总数的20%左右。其中，
UTF-8是一种以字节为单位，针对Unicode的可变长度字符编码，用1 ~ 6个字节对
Unicode字符进行编码压缩，目的是用较少的字节表示最常用的字符。此规则能有效
地降低数据存储和传输成本

在日常开发中，字符集如果不兼容则会造成乱码。淘宝以前的系统都是GBK编码，
而国际站使用的是UTF-8，在互相查看源码时，使用UTF-8的IDE环境打开GBK源
码，中文注释基本上都是不可读的乱码。乱码的出现场景并不止于编码环境中，还有
网页展示、文本转换、文件读取等。数据流从底层数据库到应用层，到Web服务器，
再到客户端显示，每位开发工程师都会碰到字符乱码的问题，排查起来是一个比较长
的链路。数据库是存储字符之源，在不同层次上都能够设置独立的字符集，如服务器
级别、schema级别、表级别甚至列级别。为了减少麻烦，所有情况下的字符集设置
最好是一致的

##### 1.4 CPU与内存
CPU ( Central Processing Unit )是一块超大规模的集成电路板，是计算机的核心
部件，承载着计算机的主要运算和控制功能，是计算机指令的最终解释模块和执行模
块。硬件包括基板、核心、针脚，基板用来固定核心和针脚，针脚通过基板上的基座
连接电路信号，CPU核心的工艺极度精密，达到10纳米级别

和其他硬件设备相比，在实际代码的运行环境中，CPU与内存是密切相关的两
个硬件设备，本节对CPU和内存简单介绍一下。开发工程师在实际编程中，对这两
个部件有一定的掌控性，熟悉CPU和内存的脾气，让它们以自己期望的方式执行相
关指令。在CPU的世界里，没有缤纷多彩的图像、悦耳动听的音乐，只有日复一日
地对0与1电流信号的处理。但CPU内部的处理机制是十分精密而复杂的，总的来说，
就是由控制器和运算器组成的，内部寄存器使这两者协同更加高效。CPU的内部结
构如图1-7所示

1. 控制器
控制器由图1-7中所示的控制单元、指令译码器、指令寄存器组成。其中控制单
元是CPU的大脑，由时序控制和指令控制等组成；指令译码器是在控制单元的协调
下完成指令读取、分析并交由运算器执行等操作；指令寄存器是存储指令集，当前流
行的指令集包括X86、SSE、 MMX等。控制器有点像一个编程语言的编译器，输入
0与1的源码流，通过译码和控制单元对存储设备的数据进行读取，运算完成后，保
存回寄存器，甚至是内存

2. 运算器
运算器的核心是算术逻辑运算单元，即ALU，能够执行算术运算或逻辑运算等
各种命令，运算单元会从寄存器中提取或存储数据。相对控制单元来说，运算器是受
控的执行部件。任何编程语言诸如a+b的算术运算，无论字节码指令，还是汇编指令，
最后一定会以0与1的组合流方式在部件内完成最终计算，并保存到寄存器，最后送
出CPU。平时理解的栈与堆，在CPU眼里都是内存

3. 寄存器
最著名的寄存器是CPU的高速缓存L1、L2，缓存容量是在组装计算机时必问的
两个CPU性能问题之一。缓存结构和大小对CPU的运行速度影响非常大，毕竟CPU
的运行速度远大于内存的读写速度，更远大于硬盘。基于执行指令和热点数据的时间
局部性和空间局部性，CPU 缓存部分指令和数据，以提升性能。但由于CPU内部空
间狭小且结构复杂，高速缓存远小于内存空间。

CPU是一个高内聚的模块化组件，它对外部其他硬件设备的时序协调、指令控制、
存取动作，都需要通过操作系统进行统一管理和协调。所谓的CPU时间片切分，并
非CPU内部能够控制与管理。CPU部件是一个任劳任怨的好公民代表，只要有指令
就会马不停蹄地执行，高级语言提供的多线程技术和并发更多地依赖于操作系统的调
配，并行更多依赖于CPU多核技术。多核CPU即在同一块基板上封装了多个Core。
还有一种提升CPU性能的方式是超线程，即在一个Core上执行多个线程，如图1-8
所示为2个Core，但是有4个逻辑CPU，并有对应独立的性能监控数据。

CPU与内存的执行速度存在巨大的鸿沟，如图1-8所示的L2和L3分别是
256KB和4MB，它们是CPU和内存之间的缓冲区，但并非所有的处理器都有L3缓存

曾几何时，内存就是系统资源的代名词，它是其他硬件设备与CPU沟通的桥梁，
计算机中的所有程序都在内存中运行，它的容量与性能如果存在瓶颈，即使CPU再快，
也是枉然。内存物理结构由内存芯片、电路板、控制芯片、相关支持模块等组成，内
存芯片结构比较简单，核心是存储单元，支持模块是地址译码器和读写控制器，如图
1-9所示

从图1-9中可以看出，越往CPU核心靠近，存储越贵，速度越快。越往下，存
储越便宜、速度越慢，当然容量也会更大。云端存储使得应用程序无须关心是分布式
还是集中式，数据如何备份和容灾。在本地磁盘与CPU内部的缓存之间，内存是一
个非常关键的角色，但它很敏感，内存颗粒如果有问题无法存储，或控制模块出现地
址解析问题，或内存空间被占满，都会导致无法正常地执行其他应用程序，甚至是操
作系统程序。程序员们最害怕的OOM通常来源于由于不恰当的编码方式而导致内存
的资源耗尽，虽然现代内存的容量已经今非昔比，但仍然是可以在秒级内耗尽所有内
存资源的

图1-9中的存储单元都有一个十六进制的编号，在32位机器上是0x开始的8位
数字编号，就是内存存储单元的地址，相当于门牌号。以C和C++为代表的编程语
言可以直接操作内存地址，进行分配和释放。举个例子，要写一份数据到存储单元中，
就像快递一个包裹，需要到付并且当面签收，到了对应的住址，发现收件人不在，就
抛出异常。如图1-10所示的经典错误，估计很多人都遇到过，选择要调试程序，单击【取
消】按钮，并无反应，也不会出现调试界面。内存的抽象就是线性空间内的字节数组，
通过下标访问某个特定位置的数据，比如C语言使用malloc()进行内存的分配，然后
使用指针进行内存的读与写

而以Java为代表的编程语言，内存就交给JVM进行自动分配与释放，这个过程
称为垃圾回收机制。这就好像刚才的快递员并不直接访问内存单元，只是把包裹放在
叫JVM的老大爷家里。付出的代价是到货速度慢了，影响客户体验。毕竟老大爷并
不是实时立马转交的，而是要攒到一定的包裹量再挨家挨户地给收件人送过去。虽然
垃圾回收机制能为程序员减负，但如果不加节制的话，同样会耗尽内存资源

##### 1.5 TCP/IP
###### 1.5.1 网络协议
在计算机诞生后，从单机模式应用发展到将多台计算机连接起来，形成计算机网
络，使信息共享、多机协作、大规模计算等成为现实，历经了20多年的时间。计算
机网络需要解决的第一个问题是如何无障碍地发送和接收数据。而这个发送和接收数
据的过程需要相应的协议来支撑，按互相可以理解的方式进行数据的打包与解包，使
不同厂商的设备在不同类型的操作系统上实现顺畅的网络通信

TCP/IP ( Transmission Control Protocol / Internet Protocol) 中文译为传输控制协
议/因特网互联协议，这个大家族里的其他知名协议还有HTTP、HTTPS、 FTP、
SMTP、UDP、ARP、PP、IEEE 802.x等。TCP/IP是当前流行的网络传输协议框架，
从严格意义上讲它是一个协议族，因为TCP、IP 是其中最为核心的协议，所以就把
该协议族称为TCP/IP。而另一个是耳熟能详的ISO/OSI的七层传输协议，其中OSI
( Open System Interconnection)的出发点是想设计出计算机世界通用的网络通信基本
框架，它已经被淘汰，本节略过

TCP/IP是在不断解决实际问题中成长起来的协议族，是经过市场检验的事实标
准，已经很难被取代。就像即使键盘的布局不那么合理，比如字母A被设计在左手
小指位置，不利于敲击，但原来的键盘布局已经成为群体习惯的事实标准。TCP分层
框架图如图1-11所示，为了表示网络拓扑图在连接层面上的机器对等理念，故图1-11 
中采用A机器和B机器的说法，而不是服务器和客户端的说法

- 链路层：单个0、1是没有意义的，链路层以字节为单位把0与1进行分组，
定义数据帧，写入源和目标机器的物理地址、数据、校验位来传输数据。图1-12
所示是以太网的帧协议。

MAC地址长6个字节共48位，通常使用十六进制数表示。使用ifconfig -a命令
即可看到MAC地址。如图1-13 所示的f4:5c:89， 即前24位由管理机构统一分配，
后24位由厂商自己分配，保证网卡全球唯一。 网卡就像家庭地址一样，是计算机世
界范围内的唯一标识

- 网络层：根据IP定义网络地址，区分网段。子网内根据地址解析协议( ARP )
进行MAC寻址，子网外进行路由转发数据包，这个数据包即IP数据包

- 传输层：数据包通过网络层发送到目标计算机后，应用程序在传输层定义逻
辑端口，确认身份后，将数据包交给应用程序，实现端口到端口间通信。最
典型的传输层协议是UDP和TCP。UDP只是在IP数据包上增加端口等部分
信息，是面向无连接的，是不可靠传输，多用于视频通信、电话会议等(即
使少一帧数据也无妨)。与之相反，TCP是面向连接的。所谓面向连接，是
一种端到端间通过失败重传机制建立的可靠数据传输方式，给人感觉是有一
条固定的通路承载着数据的可靠传输

- 应用层：传输层的数据到达应用程序时，以某种统一规定的协议格式解读数
据。比如，E-mail 在各个公司的程序界面、操作、管理方式都不一样，但是
都能够读取邮件内容，是因为SMTP协议就像传统的书信格式一样，按规定
填写邮编及收信人信息

总结一下，程序在发送消息时，应用层按既定的协议打包数据，随后由传输层加
上双方的端口号，由网络层加上双方的IP地址，由链路层加上双方的MAC地址，并
将数据拆分成数据帧，经过多个路由器和网关后，到达目标机器。简而言之，就是按
“端口→IP地址→ MAC地址”这样的路径进行数据的封装和发送，解包的时候反过
来操作即可

###### 1.5.2 IP协议
IP是面向无连接、无状态的，没有额外的机制保证发送的包是否有序到达。IP
首先规定出IP地址格式，该地址相当于在逻辑意义上进行了网段的划分，给每台计
算机额外设置了一个唯一的详细地址。既然链路层可以通过唯一的MAC地址找到机
器，为什么还需要通过唯一的IP地址再来标识呢?简单地说，在世界范围内，不可
能通过广播的方式，从数以千万计的计算机里找到目标MAC地址的计算机而不超时。
在数据投递时就需要对地址进行分层管理。举个例子，一个重要快递从美国发出，要
发给中国浙江省台州市某小区的X先生。快递公司需要先确定中国的转运中心(如
浙江某转运中心)，然后再从转运中心逐级配送到各个下级转运点。当快递到达该小
区后，快递员大喊一声: "X先生领快递啦!”虽然小区里包括X先生在内的所有人
都听到了快递员的喊声，但只有X先生收取快递并当面打开确认，其他人确定不是
叫自己则不用理会。IP 地址如图1-14所示，即30.38.48.22，右边为物理层发送和接
收数据的统计

IP地址属于网络层，主要功能在WLAN内进行路由寻址，选择最佳路由。IP报
文格式如图1-15所示，共32位4个字节，通常用十进制数来表示。IP 地址的掩码
0xffffff00表示255.255.255.0，掩码相同，则在同一子网内。IP协议在IP报头中记录
源IP地址和目标IP地址，如图1-15所示

协议结构比较简单，重点说一下数据包的生存时间，即TTL，它是数据包可经
过的最多路由器总数。TTL初始值由源主机设置后，数据包在传输过程中每经过一
个路由器TTL值则减1，当该字段为0时，数据包被丢弃，并发送ICMP报文通知
源主机，以防止源主机无休止地发送报文。这里扩展说一下ICMP ( Internet Control
Message Protocol)，它是检测传输网络是否通畅、主机是否可达、路由是否可用等网
络运行状态的协议。ICMP 虽然并不传输用户数据，但是对评估网络健康状态非常重
要，经常使用的ping、tracert 命令就是基于ICMP检测网络状态的有力工具。图1-15
中TTL右侧是挂载协议标识，表示IP数据包里放置的子数据包协议类型，如6代表
TCP、17代表UDP等

IP报文在互联网上传输时，可能要经历多个物理网络，才能从源主机到达目标
主机。比如在手机上给某个PC端的朋友发送一个信息，经过无线网的IEEE 802.1x
认证，转到光纤通信上，然后进入内部企业网802.3，并最终到达目标PC。由于不同
硬件的物理特性不同，对数据帧的最大长度都有不同的限制，这个最大长度被称为最
大传输单元，即MTU ( Maximum Transmission Unit)。那么在不同的物理网之间就
可能需要对IP报文进行分片，这个工作通常由路由器负责完成

IP是TCP/IP的基石，几乎所有其他协议都建立在IP所提供的服务基础上进行传
输，其中包括在实际应用中用于传输稳定有序数据的TCP

###### 1.5.3 TCP建立连接
传输控制协议( Transmission Control Protocol, TCP)，是一种面向连接、确保
数据在端到端间可靠传输的协议。面向连接是指在发送数据前，需要先建立一条虚拟
的链路，然后让数据在这条链路上“流动”完成传输。为了确保数据的可靠传输，不
仅需要对发出的每一个字节进行编号确认，校验每一个数据包的有效性，在出现超时
情况时进行重传，还需要通过实现滑动窗口和拥塞控制等机制，避免网络状况恶化而
最终影响数据传输的极端情形。每个TCP数据包是封装在IP包中的，每一个IP头的
后面紧接着的是TCP头，TCP报文格式如图1-16所示

协议第一行的两个端口号各占两个字节，分别表示了源机器和目标机器的端口号。
这两个端口号与IP报头中的源IP地址和目标IP地址所组成的四元组可唯一标识一条
TCP连接。由于TCP是面向连接的，因此有服务端和客户端之分。需要服务端先在
相应的端口上进行监听，准备好接收客户端发起的建立连接请求。当客户端发起第一
个请求建立连接的TCP包时，目标机器端口就是服务端所监听的端口号。比如一些
由国际组织定义的广为人知端口号一代表HTTP服务的80端口、代表SSH服务的
22端口、代表HTTPS服务的443端口。可通过netstat命令列出机器上已建立的连接
信息，其中包含唯一标识一条连接的四元组，以及各连接的状态等内容，如图1-17所示，
图中的红框代表端口号

协议第二行和第三行是序列号，各占4个字节。前者是指所发送数据包中数据部
分第一个字节的序号，后者是指期望收到来自对方的下一个数据包中数据部分第一个
字节的序号

由于TCP报头中存在一些扩展字段，所以需要通过长度为4个bit的头部长度字
段表示TCP报头的大小，这样接收方才能准确地计算出包中数据部分的开始位置

TCP的FLAG位由6个bit组成，分别代表ACK、SYN、FIN、URG、PSH、
RST，都以置1表示有效。我们重点关注SYN、ACK 和FIN。SYN ( Synchronize
Sequence Numbers )用作建立连接时的同步信号； ACK ( Acknowledgement)用于对
收到的数据进行确认，所确认的数据由确认序列号表示；FIN ( Finish)表示后面没有
数据需要发送，通常意味着所建立的连接需要关闭了

TCP报头中的其他字段可以阅读RFC793来掌握，本书在此不加赘述。接下来重
点分析TCP中连接建立的原理。图1-18展示了正常情形下通过三次握手建立连接的
过程。显然，B机器是服务端角色，A机器是客户端角色，前者需要在后者发起连接
建立请求时先打开某个端口等待数据传输，否则将无法正常建立连接。三次握手指的
是建立连接的三个步骤：

- A机器发出一个数据包并将SYN置1，表示希望建立连接。这个包中的序列
号假设是x

- B机器收到A机器发过来的数据包后，通过SYN得知这是一个建立连接的
请求，于是发送一个响应包并将SYN和ACK标记都置1。假设这个包中的
序列号是y，而确认序列号必须是x+1，表示收到了A发过来的SYN。在
TCP中，SYN被当作数据部分的一个字节

- A收到B的响应包后需进行确认，确认包中将ACK置1，并将确认序列号
设置为y+1，表示收到了来自B的SYN

这里为什么需要第3次握手?它有两个主要目的：信息对等和防止超时。先从信
息对等角度来看，如表1-6所示，双方只有确定4类信息，才能建立连接。在第2次
握手后，从B机器视角看还有两个红色的NO信息无法确认。在第3次握手后，B机
器才能确认自己的发报能力和对方的收报能力是正常的。

连接三次握手也是防止出现请求超时导致脏连接。TTL网络报文的生存时间往
往都会超过TCP请求超时时间，如果两次握手就可以创建连接，传输数据并释放连
接后，第一个超时的连接请求才到达B机器的话，B机器会以为是A创建新连接的
请求，然后确认同意创建连接。因为A机器的状态不是SYN_SENT，所以直接丢弃
了B的确认数据，以致最后只是B机器单方面创建连接完毕，简要示意图如图1-19
所示

如果是三次握手，则B机器收到连接请求后，同样会向A机器确认同意创建连接，
但因为A机器不是SYN_SENT状态，所以会直接丢弃，B机器由于长时间没有收到
确认信息，最终超时导致连接创建失败，因而不会出现脏连接。根据抓包分析，呈现
出三次握手请求过程，SYN+ACK 的应答，告诉A机器期望下一个数据包的第一个字
节序号为1，如图1-20所示

从编程的角度，TCP连接的建立是通过文件描述符( File Descriptor, fd )完成的。
通过创建套接字获得一个fd，然后服务端和客户端需要基于所获得的fd调用不同
的函数分别进入监听状态和发起连接请求。由于fd 的数量将决定服务端进程所能建
立连接的数量，对于大规模分布式服务来说，当fd不足时就会出现“open too many
files”错误而使得无法建立更多的连接。为此，需要注意调整服务端进程和操作系统
所支持的最大文件句柄数。通过使用ulimit -n命令来查看单个进程可以打开文件句柄
的数量。如果想查看当前系统各个进程产生了多少句柄，可以使用如”下的命令：
```shell
lsof -n | awk '{print $2}' | sort | uniq -c | sort -nr | more
```
执行结果如图1-21所示，左侧列是句柄数，右侧列是进程号。lsof 命令用于查
看当前系统所打开fd的数量。在Linux系统中，很多资源都是以fd的形式进行读写的，
除了提到的文件和TCP连接，UDP数据报、输入输出设备等都被抽象成了fd

想知道具体的PID对应的具体应用程序是谁，使用如下命令即可：
```shell
ps -ax | grep 32764
```
Java进程示例如图1-22所示

TCP在协议层面支持KeepAlive功能，即隔段时间通过向对方发送数据表示连
接处于健康状态。不少服务将确保连接健康的行为放到了应用层，通过定期发送心跳
包检查连接的健康度。一旦心跳包出现异常不仅会主动关闭连接，还会回收与连接相
关的其他用于提供服务的资源，确保系统资源最大限度地被有效利用。

###### 1.5.4 TCP断开连接
TCP是全双工通信，双方都能作为数据的发送方和接收方，但TCP连接也会有
断开的时候。所谓相爱容易分手难，建立连接只有三次，而挥手断开则需要四次，如
图1-23所示。A机器想要关闭连接，则待本方数据发送完毕后，传递FIN信号给B
机器。B机器应答ACK，告诉A机器可以断开，但是需要等B机器处理完数据，再
主动给A机器发送FIN信号。这时，A机器处于半关闭状态( FIN_WAIT_2)，无法
再发送新的数据。B机器做好连接关闭前的准备工作后，发送FIN给A机器，此时
B机器也进入半关闭状态( CLOSE_WAIT)。 A机器发送针对B机器FIN的ACK后，
进入TIME-WAIT状态，经过2MSL ( Maximum Segment Lifetime)后，没有收到B
机器传来的报文，则确定B机器已经收到A机器最后发送的ACK指令，此时TCP
连接正式释放。具体释放步骤如图1-23所示

通过抓包分析，如图1-24 所示红色箭头表示B机器已经清理好现场，并发送
FIN+ACK。注意，B机器主动发送的两次ACK应答的都是81，第一次进入CLOSE_WAIT
状态，第二次应答进入LAST_ACK状态，表示可以断开连接，在绿色箭头处，
A机器应答的就是Seq=81

四次挥手断开连接用通俗的说法可以形象化地这样描述
```text
男生:我们分手吧
女姓:好的，我的东西收拾完，发信息给你。( 此时男生不能再拥抱女生了。)
(1个小时后)
女生:我收拾好了，分手吧。( 此时，女生也不能再拥抱男生了。)
男生:好的。( 此时，双方约定经过2个月的过渡期，双方才可以分别找新的
对象。)
```
图1-23中的红色字体所示的TIME_WAIT和CLOSE_WAIT分别表示主动关闭和
被动关闭产生的阶段性状态，如果在线上服务器大量出现这两种状态，就会加重机器
负载，也会影响有效连接的创建，因此需要进行有针对性的调优处理

- TIME_WAIT：主动要求关闭的机器表示收到了对方的FIN报文，并发送出
了ACK 报文，进入TIME_WAIT状态， 等2MSL 后即可进入到CLOSED状
态。如果FIN_WAIT_1状态下，同时收到带FIN标志和ACK标志的报文时，
可以直接进入TIME_WAIT状态，而无须经过FIN_WAIT_2状态

- CLOSE_WAIT：被动要求关闭的机器收到对方请求关闭连接的FIN报文，
在第一次ACK应答后，马上进入CLOSE_WAIT状态。这种状态其实表示在
等待关闭，并且通知应用程序发送剩余数据，处理现场信息，关闭相关资源

在TIME_WAIT 等待的2MSL是报文在网络上生存的最长时间，超过阈值便将报
文丢弃。一般来说，MSL大于TTL衰减至0的时间。在RFC793中规定MSL为2分
钟。但是在当前的高速网络中，2分钟的等待时间会造成资源的极大浪费，在高并发
服务器上通常会使用更小的值。既然TIME_WAIT貌似是百害而无一利的，为何不直
接关闭，进入CLOSED状态呢?原因有如下几点

第一，确认被动关闭方能够顺利进入CLOSED状态。如图1-23 所示，假如最
后一个ACK由于网络原因导致无法到达B机器，处于LAST_ACK的B机器通常
“自信”地以为对方没有收到自己的FIN+ACK报文，所以会重发。A机器收到第二
次的FIN+ACK报文，会重发一次 ACK，并且重新计时。如果A机器收到B机器的
FIN+ACK报文后，发送一个ACK给B机器，就“自私”地立马进入CLOSED状态，
可能会导致B机器无法确保收到最后的ACK指令，也无法进入CLOSED状态。这是
A机器不负责任的表现

第二，防止失效请求。这样做是为了防止已失效连接的请求数据包与正常连接的
请求数据包混淆而发生异常

因为TIME_WAIT状态无法真正释放句柄资源，在此期间，Socket 中使用的本地
端口在默认情况下不能再被使用。该限制对于客户端机器来说是无所谓的，但对于高
并发服务器来说，会极大地限制有效连接的创建数量，成为性能瓶颈。所以，建议将
高并发服务器TIME_WAIT超时时间调小

在服务器上通过变更/etc/sysctl.conf文件来修改该省略值(秒)：
net.ipv4.tcp_fin_timeout=30 (建议小于30秒为宜)

修改完之后执行/sbin/sysctl -p让参数生效即可。可以通过如下命令:
```shell
netstat -n | awk '/^tcp/ {++S[$NF]} END {for (a in S) print a, S[a]}' 
```
查看各连接状态的计数情况，为了使数据快速生效，2MSL从240秒更改为5秒。参
数生效后如图1-25所示，TIME_WAIT很快从75个降为1个

在sysctl.conf中还有其他连接参数也用来不断地调优服务器TCP连接能力，以
提升服务器的有效利用率。毕竟现代网络和路由处理能力越来越强，跨国时延通常也
在1秒钟以内，丢包率极低。如何快速地使连接资源被释放和复用，参数的优化往往
可以取得事半功倍的效果。记得某大公司在大型购物节时，系统宕机，老总下令要加
一倍服务器来解决问题。事实上，如果是参数配置错误导致的系统宕机，即使增加硬
件资源，也无法达到好的效果。硬件的增加与性能的提升绝对不是线性相关的，更多
的时候是对数曲线关系

TIME_WAIT是挥手四次断开连接的尾声，如果此状态连接过多，则可以通过
优化服务器参数得到解决。如果不是对方连接的异常，一般不会出现连接无法关闭
的情况。但是CLOSE_WAIT过多很可能是程序自身的问题，比如在对方关闭连接
后，程序没有检测到，或者忘记自己关闭连接。在某次故障中，外部请求出现超时
的情况，当时的Apache服务器使用的是默认的配置方式，通过命令： netstat -antlgrep
-i "443"|grep CLOSE_WAIT|wc -l发现在HTTPS的443端口上堆积了2.1万个左右的
CLOSE_WAIT状态。经排查发现，原来是某程序处理完业务逻辑之后没有释放流操作，
但程序一直运行正常，直到运营活动时才大量触发该业务逻辑，最终导致故障的产生。

###### 1.5.5 连接池
我们使用连接来进行系统间的交互，如何管理成千，上万的连接呢?服务器可以快
速创建和断开连接，但对于高并发的后台服务器而言，连接的频繁创建与断开，是非
常重的负担。就好像我们正在紧急处理线上故障，给同事打电话一起定位问题时，一
般情况下都不会挂断电话，直到问题解决。在时间极度紧张的情况下，频繁地拨打和
接听电话会降低处理问题的效率。在客户端与服务端之间可以事先创建若干连接并提
前放置在连接池中，需要时可以从连接池直接获取，数据传输完成后，将连接归还至
连接池中，从而减少频繁创建和释放连接所造成的开销。例如，RPC服务集群的注册
中心与服务提供方、消费方之间，消息服务集群的缓存服务器和消费者服务器之间，
应用后台服务器和数据库之间，都会使用连接池来提升性能

重点提一下数据库连接池，连接资源在数据库端是一种非常关键且有限的系统
资源。连接过多往往会严重影响数据库性能。数据库连接池负责分配、管理和释放连
接，这是一种以内存空间换取时间的策略，能够明显地提升数据库操作的性能。但如
果数据库连接管理不善，也会影响到整个应用集群的吞吐量。连接池配置错误加上慢
SQL，就像屋漏偏逢连夜雨，可以瞬间让一个系统进入服务超时假死宕机状态

如何合理地创建、管理、断开连接呢?以Druid为例，Druid 是阿里巴巴的一个
数据库连接池开源框架，准确来说它不仅仅包括数据库连接池，还提供了强大的监控
和扩展功能。当应用启动时，连接池初始化最小连接数( MIN) ;当外部请求到达时，
直接使用空闲连接即可。假如并发数达到最大(MAX)，则需要等待，直到超时。
如果一直未拿到连接，就会抛出异常

如果MIN过小，可能会出现过多请求排队等待获取连接;如果MIN过大，会
造成资源浪费。如果MAX过小，则峰值情况下仍有很多请求处于等待状态；如果
MAX过大，可能导致数据库连接被占满，大量请求超时，进而影响其他应用，引发
服务器连环雪崩。在实际业务中，假如数据库配置的MAX是100，一个请求10ms,
则最大能够处理1000QPS。增大连接数，有可能会超过单台服务器的正常负载能力。
另外，连接数的创建是受到服务器操作系统的fd (文件描述符)数量限制的。创建更
多的活跃连接，就需要消耗更多的fd,系统默认单个进程可同时拥有1024个fd，该
值虽然可以适当调整，但如果无限制地增加，会导致服务器在fd的维护和切换上消
耗过多的精力，从而降低应用吞吐量

懒惰是人的天性，有时候开发工程师为了图省事还会不依不饶地要求调长
Timeout时间，如果这个数值过大，对于调用端来说也是不可接受的。如果应用服务
器超时，前台已经失败返回，但是后台仍然在没有意义地重试，并且还有新的处理请
求不断堆积，最终导致服务器崩溃。这明显是不合理的。所以在双十一的场景里，应
用服务器的全链路上不论是连接池的峰值处理，还是应用之间的调用频率，都会有相
关的限流措施和降级预案

图1-26所示的是某连接池的监控图。图中连接池最小的连接数是2，一个线程
就是一个活跃连接。一般可以把连接池的最大连接数设置在30个左右，理论上还可
以设置更大的值，但是DBA一般不会允许，因为往往只有出现了慢SQL，才需要使
用更多的连接数。这时候通常需要优化应用层逻辑或者创建数据库索引，而不是一味
地采用加大连接数这种治标不治本的做法。极端情况下甚至会导致数据库服务不响应，
进而影响其他业务

从经验上来看，在数据库层面的请求应答时间必须在100ms以内，秒级的SQL
查询通常存在巨大的性能提升空间，有如下应对方案：

(1)建立高效且合适的索引。索引谁都可以建，但要想建好难度极大。因为索
引既有数据特征，又有业务特征，数据量的变化会影响索引的选择，业务特点不一样，
索引的优化思路也不一样。通常某个字段平时不用，但是某种触发场景下命中“索引
缺失”的字段会导致查询瞬间变慢。所以，要事先明确业务场景，建立合适的索引

(2)排查连接资源未显式关闭的情形。要特别注意在ThreadLocal或流式计算
中使用数据库连接的地方

(3)合并短的请求。根据CPU的空间局部性原理，对于相近的数据，CPU会
一起提取到内存中。 另外，合并请求也可以有效减少连接的次数

(4)合理拆分多个表join的SQL， 若是超过三个表则禁止join。 如果表结构建
得不合理，应用逻辑处理不当，业务模型抽象有问题，那么三表join的数据量由于笛
卡儿积操作会呈几何级数增加，所以不推荐这样的做法。另外，对于需要join的字段，
数据类型应保持绝对一致。多表关联查询时，应确保被关联的字段要有索引

(5)使用临时表。某种情况下，该方法是一种比较好的选择。曾经遇到一个场
景不使用临时表需要执行1个多小时，使用临时表可以降低至2分钟以内。因为在不
断的嵌套查询中，已经无法很好地利用现有的索引提升查询效率，所以把中间结果保
存到临时表，然后重建索引，再通过临时表进行后续的数据操作

(6)应用层优化。包括进行数据结构优化、并发多线程改造等

( 7)改用其他数据库。因为不同数据库针对的业务场景是不同的，比如
Cassandra、MongoDB

##### 1.6 信息安全
###### 1.6.1 黑客与安全







###### 1.6.2 SQL注入





###### 1.6.3 XSS与CSRF






###### 1.6.4 CSRF






###### 1.6.5 HTTPS






##### 1.7 编程语言的发展





